{"ANKIConfig":{"GIT_URL":"https://github.com/myshell-ai/OpenVoice/blob/main/"},"openvoice__utils__split_sentence":{"label":"split_sentence","systemPath":"C:/Users/sanju/Desktop/projects/explore/OpenVoice\\openvoice\\utils.py:78","relativePath":"openvoice/utils.py","lineNo":"78","emgithubIframeLink":"https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2Fmyshell-ai%2FOpenVoice%2Fblob%2Fmain%2Fopenvoice%2Futils.py%23L78-L128&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on","description":"[Quick summary]\n\nThis function, `split_sentence`, splits a text into sentences considering the language. It checks the provided language string (`language_str`). If it's 'EN' (English), it uses the `split_sentences_latin` function to split the text. Otherwise, it assumes another language (possibly Chinese based on the presence of `split_sentences_zh` though not shown) and uses a different splitting function (`split_sentences_zh` not provided).\n\n[Inputs]\n\n* `text`: String containing the text to be split.\n* `min_len` (optional): Integer representing the minimum number of words desired in each output sentence (defaults to 10).\n* `language_str` (optional): String representing the language code (defaults to '[EN]' for English).\n\n[Output]\n\n* The function returns a list of strings containing the split sentences based on the language rules. "},"openvoice__utils__split_sentences_latin":{"label":"split_sentences_latin","systemPath":"C:/Users/sanju/Desktop/projects/explore/OpenVoice\\openvoice\\utils.py:85","relativePath":"openvoice/utils.py","lineNo":"85","emgithubIframeLink":"https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2Fmyshell-ai%2FOpenVoice%2Fblob%2Fmain%2Fopenvoice%2Futils.py%23L85-L135&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on","description":"[Quick summary]\n\nThis function, `split_sentences_latin`, prepares and splits a Latin text into a list of shorter sentences. It first cleans the text by removing various punctuation and formatting. Then, it splits the text based on punctuation markers and filters out empty entries. Finally, it iterates through the sentences, building new sentences that don't exceed a minimum word length (`min_len`) and calls another function (`merge_short_sentences_latin`) to avoid ending with very short sentences.\n\n[Inputs]\n\n* `text`: String containing the Latin text to be split.\n* `min_len` (optional): Integer representing the minimum number of words desired in each output sentence (defaults to 10).\n\n[Output]\n\n* The function returns a list of strings containing the split sentences. The sentences are no longer than `min_len` words (except potentially the last one) and short sentences are merged with the following sentence whenever possible (handled by `merge_short_sentences_latin`)."},"openvoice__utils__merge_short_sentences_latin":{"label":"merge_short_sentences_latin","systemPath":"C:/Users/sanju/Desktop/projects/explore/OpenVoice\\openvoice\\utils.py:120","relativePath":"openvoice/utils.py","lineNo":"120","emgithubIframeLink":"https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2Fmyshell-ai%2FOpenVoice%2Fblob%2Fmain%2Fopenvoice%2Futils.py%23L120-L170&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on","description":"[Quick summary]\n\nThis function, `merge_short_sentences_latin`, aims to improve readability of Latin text by combining very short sentences with the following sentence. It iterates through a list of sentences and checks if the previous sentence is too short (2 words or less). If so, it merges the current sentence with the previous one. The function handles potential errors at the end (if the last sentence is short).\n\n[Inputs]\n\n* `sens`: List of strings representing individual sentences in Latin.\n\n[Output]\n\n* The function returns a list of strings containing the modified sentences. Short sentences are merged with the following sentence whenever possible."},"openvoice__api__BaseSpeakerTTS__tts":{"label":"tts","systemPath":"C:/Users/sanju/Desktop/projects/explore/OpenVoice\\openvoice\\api.py:73","relativePath":"openvoice/api.py","lineNo":"73","emgithubIframeLink":"https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2Fmyshell-ai%2FOpenVoice%2Fblob%2Fmain%2Fopenvoice%2Fapi.py%23L73-L123&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on","description":"[Quick summary]\n\nThis function, `tts`, performs text-to-speech synthesis for a given input text. It splits the text into sentences considering language-specific markers, applies text preprocessing, and feeds it to a pre-trained model. The model generates audio for each sentence, which are then concatenated and saved to a file (if provided) or returned as a NumPy array.\n\n[Inputs]\n\n* `text`: String containing the text to be spoken.\n* `output_path` (optional): String representing the path to save the generated audio file.\n* `speaker`: String representing the desired speaker ID from the model configuration.\n* `language` (optional): String representing the language of the text (defaults to English).\n* `speed` (optional): Float representing the desired speaking speed (defaults to 1.0).\n\n[Output]\n\n* The function returns either:\n    * A NumPy array containing the generated audio data (if `output_path` is None).\n    * None (if audio is saved to a file specified by `output_path`).\n"},"openvoice__openvoice_app__predict":{"label":"predict","systemPath":"C:/Users/sanju/Desktop/projects/explore/OpenVoice\\openvoice\\openvoice_app.py:37","relativePath":"openvoice/openvoice_app.py","lineNo":"37","emgithubIframeLink":"https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2Fmyshell-ai%2FOpenVoice%2Fblob%2Fmain%2Fopenvoice%2Fopenvoice_app.py%23L37-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on","description":"[Quick summary]\n\nThis function, `predict`, takes a text prompt, desired speaking style, audio path (optional), and agreement to terms as input. It checks for language compatibility and style support, then uses a Text-To-Speech model and a tone color converter to generate audio that matches the prompt and desired style. Finally, it returns informative messages and the generated audio path.\n\n[Inputs]\n\n* `prompt`: String containing the text to be spoken.\n* `style`: String representing the desired speaking style (e.g., whispering, shouting).\n* `audio_file_pth` (optional): String representing the path to an audio file (potentially used for reference).\n* `agree`: Boolean indicating agreement to terms and conditions.\n\n[Output]\n\n* The function returns a tuple containing three elements:\n    * `text_hint`: String containing any error messages or informative notes.\n    * `save_path`: String representing the path to the generated audio file (if successful).\n    * `speaker_wav`: String representing the path to the provided audio file (unchanged)."},"openvoice__se_extractor__hash_numpy_array":{"label":"hash_numpy_array","systemPath":"C:/Users/sanju/Desktop/projects/explore/OpenVoice\\openvoice\\se_extractor.py:118","relativePath":"openvoice/se_extractor.py","lineNo":"118","emgithubIframeLink":"https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2Fmyshell-ai%2FOpenVoice%2Fblob%2Fmain%2Fopenvoice%2Fse_extractor.py%23L118-L168&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on","description":"[Quick summary]\n\nThis function, `hash_numpy_array`, takes an audio file path and aims to create a unique identifier for the audio content. It does this by converting the audio data loaded using `librosa` to a byte stream, hashing it with SHA-256, and then encoding the hash in base64 with some modifications.\n\n[Inputs]\n\n* `audio_path`: This is a string representing the file path of the audio file.\n\n[Output]\n\n* The function returns a string that is a shortened (16 characters) and modified base64 encoded representation of the SHA-256 hash of the audio data. "},"openvoice__se_extractor__split_audio_vad":{"label":"split_audio_vad","systemPath":"C:/Users/sanju/Desktop/projects/explore/OpenVoice\\openvoice\\se_extractor.py:77","relativePath":"openvoice/se_extractor.py","lineNo":"77","emgithubIframeLink":"https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2Fmyshell-ai%2FOpenVoice%2Fblob%2Fmain%2Fopenvoice%2Fse_extractor.py%23L77-L127&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on","description":"[Quick summary]\n\nThis function, `split_audio_vad`, splits an audio file into segments based on voice activity detection (VAD). It uses an external function `get_audio_tensor` to process the audio and identify speech regions. Then, it cuts the original audio file based on these speech segments and saves them as separate WAV files in a subfolder.\n\n[Inputs]\n\n* `audio_path`: String representing the path to the audio file.\n* `audio_name`: String representing the name of the audio file (used for naming output files).\n* `target_dir`: String representing the path to the target directory where the split audio segments will be saved.\n* `split_seconds` (optional): Float representing the desired maximum duration (in seconds) for each split segment (defaults to 10 seconds).\n\n[Output]\n\n* The function returns a string representing the path to the directory containing the split audio segments in WAV format. "}}