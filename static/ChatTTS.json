{
    "ANKIConfig": {
        "GIT_URL": "https://github.com/2noise/ChatTTS/blob/main/"
    },
    "ChatTTS__core__Chat": {
        "label": "Chat",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 31,
        "endLineNo": 601,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L31-L601&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary:\n\nThis code defines a class or object that handles the process of loading, managing, and applying language models for text-to-speech generation. It includes methods for loading models, \n   \n## Inputs:\n* **text:** \n    \n    * **prompt:**  \n   \n\nThe code is designed to\ninputs\nThe  provides a function to generate audio based on prompts and \n.\n    * **force_redownload\n    * **params_infer_code\n\ninputs:\n    *.tmp:\n    * **device \n    \n\n## Outputs:\n* **result:  \n    \n    \n    \n    * **wavs:\n\n## Outputs:\n\n[summary]\n\n\n## Input Instructions\n```python\n def\n   \n```\n\n```pythondef load\n    * **path\n    * **idim:\n\n\n  \n\n    * **device:\n    * **params_refine_text\n    * **model_weights_only=True,  \n    * **force_redownload\n\n    * **vocos_ckpt_path: str,\n    * **complie\n    * **params_infer_code_path:\n    * **device:\n\n\nPython\n    * **decoder_path:\n    * **tokenizer:\n    * **device_gpt\n    \n    * **path\n    * **\n    * **config\n    * **gpt.voice\n    * **\n    * **prompt\n    * **\n    *\n    * **\n    * **pretrained = self\n\n    * **\n    * **params_refine_\n    * **params_infer\n    * **show_tqdm: bool\n\n    *  \n    * **\n\n__init__\n    * **\n    * **\n    * **stream\n    * **\n    * **config\n    * **path\n    * **\n\n    * **\n\n    * **decoder\n    * **checkpoint\n\n    * **text\n    * **\n    * **\n   \n    * **\n\n    \n        \n    *\n    *\n\n\n```\n:\n\n    * **unload\n    *\n```python\n    * **\n    * **\n    * **\n    * **device\n    \n    * **\n  \n\n    * **\n    * **\n\n    * **\n    * **params_infer_\n    \n\n\n\n#\n\n    * **\n    * **sample_random\n    * **refinen\n    * **sample\n    *\n    * **\n\n    * **\n\n    * **\n    *\n    * **sample\n```python\n    *\n    `\n\n    * **interp\n    * **sample\n    * **\n    \n    * **normalizer\n    * **\n    * ** \n    \n\n    * **download\n    \n    *\n\n\n    * **load\n    *\n\n\n    *\n     * **\n    *\n\n    *\n\n\n\t\n\n\n\n```python\n    * **\n    \n    * **\n    *\n    *\n    * **\n    * **\n        \n    *\n\n\n    *\n\n\n    * **\n\n    * **\n    *\n\n    * ##\n\n    *\n\n    * **\n\n\n     *\n\n\n\t\n\n\n\n    * **\n    *\n\n\n    *\n\n\n    *\n\n\n    * **\n    * **\n    * **\n    * **\n\n    \n    \n    \n    * **\n            \n            \n\npython\n        \n\n\n\n\n            \n    *\n\n\n    * **\n\n    *\n     \n    * **\n       \n    * **\n        \n    *\n\n\n    * **\n            \n    * **\n        \n    * **\n\n    *\n\n\n    \n\n    * **\n    \n    * **\n            \n            \n    *\n\n    * **\n    *\n\n\n    \n            \n    *\n           \n    *\n\n\n    *\n\n\n            \n    *\n    \n    * **\n            \n            \n\n    * **\n    \n    *\n\n    * **\n    * **\n    * **\n    * **\n\n    * **\n    * **\n    * **\n    * **\n    * **\n    * **\n    \n\t\t\n        \n    * **\n            \n    * **\n            \n    *\n\n    *\n    * **\n         \n        \n    *\n    * **\n    *\n    * **\n        \n        \n    * **\n\n#\n\n    * **\n    * **\n\n\n    *\n\n\n    *\n\n    * **\n    * **\n    * **\n\n    * **\n        \n\n    * **\n            \n            \n                \n    *\n\n    * **\n    *\n    *\n\n    \n    * **\n            \n\n\n    * **\n            \n    * **\n\n    * **\n            \n    * **\n    * **\n            \n    * **\n            \n    * **\n\n            \n    * **\n            \n    * **\n            \n    * **\n    \n\n    *\n\n    * **\n    * **\n\n    *\n    * **\n            \n    * **\n    * **\n            \nreturn\n    * **\n            \n    * **\n            \n    \n    * **\n            \n    *\n    * **\n            \n        \n            \n    * **\n\n\n\n    *\n    *\n        \n\n    *\n\n    \n    *\n    *\n            \n                \n    *\n            \n    * **\n\n    * **\n    *\n            \n                \n                \n    * **\n    *\n\n    *\n    * **\n    * **\n                \n            \n    *\n                \n\n    *\n\n\n    *\n                \n    * **\n                \n\n\n        \n            \n\n    \n\n       \n        \n            \n        \n                \n    *\n                \n                \n    * **\n                \n\n                \n                \n\n\n            \n               \n                \n                \n                \n                \n                \n\n\n    *\n                \n                \n                \n\n\n\n        \n                \n                \n                \n\n                \n                \n\n                \n                \n                \n                \n                \n                \n                \n\n\n\n    * **\n\n    *\n\n\n                \n                \n\n                \n\n\n    *\n                \n\n\n    * **\n\n    \n                \n                \n                \n                \n                \n\n\n            \n            \n            \n            \n            \n            \n\n            \n                \n                \n                \n                \n                \n                \n                \n\n                \n                \n                \n                \n                \n                \n\n           \n            \n                   \n                \n\n    *\n                    \n                \n\n\n\n                \n\n    *\n\n                \n                \n\n\n        \n                \n                \n\n    *\n\n                \n                \n\n                \n                           \n\n    *\n\n\n                \n\n\n            \n                \n                \n                \n                \n\n\n\n\n                \n                \n                \n                \n                \n                \n\n            \n\n\n                \n\n            \n                \n                \n\n\n\n                \n\n                \n\n                \n\n                \n                \n                \n                \n\n                \n                \n                \n\n    *\n\n            \n                \n                \n                \n                \n\n            \n                \n                \n\n\n    * **\n\n\n                \n                \n                \n                \n                \n                \n\n                \n\n                \n                \n\n                \n                \n\n\n                \n\n\n\n                    \n\n                \n                    \n                    \n                    \n\n                    \n                    \n                    \n                    \n                    \n                    \n                    \n\n\n                \n                \n                \n                \n                \n                   \n                \n                    \n                    \n                    \n\n\n\n                \n\n    \n                    \n\n                \n                    \n\n\n                \n                    \n\n                \n                    \n            \n                        \n                    \n                        \n\n                \n\n                        \n\n                        \n                        \n                        \n                        \n\n               \n\n                        \n                        \n                        \n\n                        \n\n\n                \n\n\n                \n                \n                \n                \n                \n                \n\n                \n                \n                \n\n\n                    \n    \n            \n            \n            \n            \n            \n            \n\n                    \n            \n            \n\n           \n\n\n            \n                \n            \n\n            \n           \n\n                \n           \n                \n\n           \n                \n\n                \n\n\n        \n\n\n                \n                \n                \n\n                \n                \n\n\n            \n\n                \n\n            \n\n                \n            \n\n\n            \n\n                \n                \n                \n                \n\n                \n            \n            \n\n\n\n                \n            \n                \n                \n            \n                \n\n                \n            \n                \n                \n            \n                \n                \n\n                \n                \n                \n                \n.join(\n            \n\n\n            \n            \n            \n                \n                \n                \n\n                \n                \n                \n             \n                \n\n                \n                \n\n                \n                \n                \n\n                \n            \n            \n                \n                \n                \n\n\n                \n                \n                \n```python\n                \n\n                \n                \n                \n                \n\n\n\n    \n                    \n    \n                    \n                    \n\n                \n\n\n\n    \n                    \n                \n                \n\n                \n\n```\n\n                \n\n                \n                \n\n    \n**\n\n                \n\n                \n```python\n                \n                \n                \n                \n                \n                \n                \n                \n                \n\n    \n                \n\n                \n                \n\n            \n            \n\n```\n        \n            \n\n            \n                \n            \n            \n\n\n\n    \n                \n\n\n\n                \n\n                \n                \n                \n\n                \n                \n\n\n\n    \n                \n                \n                \n\n\n            \n            \n                \n                \n\n\n    \n                \n                \n\n                \n\n\n            \n\n            \n\n                \n\n            \n            \n                \n                \n                \n                \n\n\n            \n                \n                \n                \n\n               \n               \n                \n\n\n            \n               \n\n               \n               \n               \n\n\n                \n\n                \n                \n                \n                \n                \n\n\n                \n                \n\n\n                \n                \n                \n                \n                \n                \n\n                \n\n                \n                \n                \n                \n                \n                \n\n\n            \n                \n                \n                \n                \n                \n                \n                \n                \n\n           \n\n                \n\n                \n                \n\n\n            \n                \n                \n                \n                \n\n\n                \n                \n                \n                \n                \n                \n                \n\n                \n                \n                \n\n```\n    \n                \n\n\n            \n\n            \n                \n                \n                \n                \n                \n\n                \n\n\n                    \n\n            \n                    \n\n                    \n            \n\n\n                \n\n\n            \n            \n                    \n                    \n\n                    \n                    \n                    \n\n\n                \n                    \n                    \n                    \n\n                \n                    \n                    \n\n                    \n                \n                    \n                    \n                    \n```\n\n```\n            \n                \n                \n                \n                \n\n```\n                \n                \n                \n                \n```\n                    \n                \n                \n            \n```\n\n                \n                \n\n\n                \n                \n            \n                \n                \n\n\n            \n                \n                \n\n\n                \n                \n                \n                 \n                \n\n                   \n                \n\n\n\n    \n    \n    \n\n\n            \n            \n            \n            \n\n\n        \n            \n\n        \n\n\n\n            \n\n            c\n\n           \n            \n\n            \n            \n\n\n\n```\n\n\n```\n           \n```\n\n```\n```\n           \n           \n           \n```\n\n```\n```l\n            \n```\n\n\n        \n            \n            \n\n\n            \n\n\n\n        \n\n\n        \n        \n        \n        \n```\n```\n        \n        \n\n\n        \n        \n```\n```\n\n\n            \n            \n\n\n        \n            \n            \n```\n            \n            \n            \n            \n            \n            .\n\n            \n            \n```\n            \n\n\n\n            \n            \n            \n            \n            \n\n            \n            \n            \n            \n            \n```\n            \n            \n            \n\n\n\n            \n            \n            \n\n\n\n            \n            \n            \n            \n\n\n            \n\n\n            \n            \n            \n            \n            \n\n            \n            \n\n            \n            \n            \n```\n                \n\n\n            \n                \n\n            \n                \n\n\n\n\n                \n                \n                \n```\n    \n            \n\n\n\n                \n            \n                \n                \n\n                \n\n\n                \n\n                \n                \n                \n\n                \n                \n\n                \n\n\n```\n            \n\n\n                \n\n                \n                \n\n\n                \n                \n\n                \n                \n\n                \n```\n                \n\n\n                \n                \n                \n```\n\n\n\n```\n```\n                \n                \n\n\n\n```\n```\n                \n                \n                \n                \n                \n                \n                \n                \n\n\n\n\n                \n                \n                \n                \n                \n```\n                \n                \n                \n                \n                \n\n\n\n\n                \n                \n                \n                \n```\n                \n                \n                \n                \n\n                \n                \n                \n                \n                \n\n                \n            \n\n                \n                \n                \n\n\n                \n                \n\n                \n                \n                \n                \n                \n```\n```\n                \n                \n                \n                \n                \n                \n                \n                \n```\n\n            \n                \n                \n\n\n                \n```\n                \n\n                \n                \n                \n            \n\n\n\n                \n                \n                \n\n\n                \n\n                \n                \n                \n```\n```\n                \n                \n                \n\n\n```\n\n```\n```\n                \n                \n                \n                \n                \n                \n                \n```\n                \n\n\n                \n                \n                \n        \n```\n```\n```\n                \n\n\n\n                \n\n```\n    \n    \n\n\n            \n\n            \n            \n            \n        \n\n\n            \n            \n  \n            \n            \n            \n            \n            \n            \n        \n            \n```\n```\n            \n            \n\n\n            \n            \n\n            \n            \n            \n            \n            \n            \n            \n            \n\n\n\n            \n```\n            \n            \n            \n            \n\n\n\n\n            \n            \n            \n            \n            \n\n\n\n            \n            \n```\n\n\n           \n\n\n\n            \n```\n            \n\n\n            \n        \n\n            \n            \n        \n\n            \n            \n"
    },
    "ChatTTS__model__gpt__GPT__generate": {
        "label": "generate",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 356,
        "endLineNo": 652,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L356-L652&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick Summary]** This function implements a text generation algorithm, likely for a language model. It iteratively generates tokens based on a given input sequence, considering probabilities and applying various processing techniques to refine the output. The purpose is to produce new text given a prompt, potentially with fine-grained control over aspects like temperature and repetition penalty.\n\n**[Inputs]**\n\n* `emb`: Embedding representations of input tokens.\n* `inputs_ids`: Integer representations of the input tokens.\n* `temperature`: A scaling factor influencing the randomness of token selection.\n* `eos_token`: Token ID marking the end of a sequence.\n* `attention_mask`: Mask indicating which input tokens are attended to.\n* `max_new_token`: Maximum length of the generated output.\n* `min_new_token`: Minimum length of the generated output.\n* `logits_warpers`: Functions modifying the predicted token logits.\n* `logits_processors`: Functions further processing the generated tokens.\n* `infer_text`: Boolean indicating whether generating text or code.\n* `return_attn`: Boolean determining if attention weights are returned.\n* `return_hidden`: Boolean determining if hidden states are returned.\n* `stream`: Boolean controlling streamed output generation.\n* `show_tqdm`: Boolean controlling progress bar display.\n* `ensure_non_empty`: Boolean ensuring a non-empty output.\n* `stream_batch`: Batch size for streamed output.\n* `context`: A context object, likely for managing interruptions.\n\n**[Output]**\n\n* A sequence of generated tokens.\n* Optional: Attention weights and hidden states, depending on `return_attn` and `return_hidden`.\n\n\n\n"
    },
    "web__webui__main": {
        "label": "main",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/webui.py",
        "relativePath": "examples/web/webui.py",
        "lineNo": 17,
        "endLineNo": 276,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Fwebui.py%23L17-L276&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary \n\nThis Python function sets up and launches a Gradio web interface for the ChatTTS text-to-speech model. It allows users to input text, customize generation parameters, and generate spoken audio output. The code's purpose is to provide a user-friendly and interactive way to experiment with the ChatTTS model.\n\n## Inputs\n\n* `text_input`: Text input field for the user to enter the text they want to convert to speech. \n* `temperature_slider`: Slider to adjust the randomness of the generated audio.\n* `top_p_slider`: Slider to control the top percentage of probabilities used for text generation.\n* `top_k_slider`: Slider to limit the number of top most probable words considered for text generation.\n* `audio_seed_input`: Number input to set a seed for audio generation.\n* `text_seed_input`: Number input to set a seed for text generation.\n* `refine_text_checkbox`: Checkbox to enable/disable text refinement.\n* `spk_emb_text`:  Text input field for user to input speaker embedding. \n\n## Output\n\n*  `audio_output`: An audio player displaying the generated speech output. \n* `text_output`: A text area displaying the refined input text.\n"
    },
    "stream__ChatStreamer": {
        "label": "ChatStreamer",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 10,
        "endLineNo": 186,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L10-L186&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## ChatStreamer Code Analysis \n\n**Quick summary**\n\nThis Python code defines a `ChatStreamer` class designed to handle and process streams of audio data, likely from a conversational AI. It aims to manage the data in a way that allows for efficient batch processing and streaming of audio output.  \n\n**Inputs**\n\n* `streamchat`: A sequence (e.g., list) of audio data chunks, likely representing spoken turns in a conversation.\n* `output_format`: A string specifying the desired output audio format (\"PCM16_byte\", \"PCM16\", or None).\n* `wait`: An integer representing the initial delay in seconds for audio playback.\n\n**Output**\n\n* A generator yielding processed audio data chunks in the specified output format. \n* For the `play` method, it produces audio output streamed to the default sound device. \n\n\n\n"
    },
    "ChatTTS__norm__Normalizer": {
        "label": "Normalizer",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 37,
        "endLineNo": 209,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L37-L209&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function processes text, normalizing it for Chinese and English languages, handling potential homophone misspellings, and removing invalid characters. Its purpose is to prepare text for downstream natural language processing tasks by ensuring consistent and accurate representation.\n\n## Inputs\n\n* `text`: The input string to be processed.\n* `do_text_normalization`:  A boolean flag indicating whether to apply text normalization rules.\n* `do_homophone_replacement`: A boolean flag indicating whether to replace homophones with their correct pronunciations.\n* `lang`: Optional. Specifies the language of the input text (\"zh\" for Chinese, \"en\" for English).\n\n ## Output\n\n* A processed string with normalizations, homophone replacements, and invalid character handling applied. \n"
    },
    "ChatTTS__model__gpt__GPT___prepare_generation_inputs": {
        "label": "_prepare_generation_inputs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 208,
        "endLineNo": 316,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L208-L316&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary**\n\nThis function prepares input data for a Transformer model, specifically during text generation. It handles caching previous context, adjusting input lengths based on past context, and creates position embeddings. The overall purpose is to efficiently feed text data into the model for generating sequential text output.\n\n**Inputs**\n\n* `input_ids`: Tokenized input text.\n* `past_key_values`:  Cached key-value pairs from previous model steps.\n* `attention_mask`:  Mask indicating which input tokens are relevant.\n* `inputs_embeds`:  Precomputed embeddings for the input text (optional).\n* `cache_position`:  Positional information for the cached tokens.\n* `position_ids`:  Precomputed positional embeddings for the input tokens (optional).\n* `use_cache`:  Boolean flag indicating whether to use cached tokens.\n\n**Output**\n\n*  `_GenerationInputs`: A custom object containing the prepared inputs for the model:\n    * `position_ids`:  Positional embeddings.\n    * `cache_position`: Cached token positions.\n    * `use_cache`:  Flag indicating cache usage.\n    * `input_ids`: Tokenized input text. \n    * `past_key_values`: Cached key-value pairs.\n    * `attention_mask`: Attention mask.\n    * `inputs_embeds`: Precomputed embeddings. \n\n\n"
    },
    "ChatTTS__core__Chat___load": {
        "label": "_load",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 238,
        "endLineNo": 338,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L238-L338&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Summary, Inputs & Outputs \n\n**[Quick Summary]**\n\nThis function initializes a high-fidelity speech synthesis system, likely for research or development purposes. It loads pre-trained models for voice conversion (Vocos), Denoising Vector Quantized Variational Auto-Encoders (DVAE), a GPT-based text-to-speech model, and an optional decoder.  \n\n**[Inputs]**\n* `vocos_ckpt_path`: Path to the pre-trained Vocos model checkpoint.\n* `dvae_ckpt_path`: Path to the pre-trained DVAE model checkpoint.\n* `gpt_ckpt_path`: Path to the pre-trained GPT model checkpoint.\n* `decoder_ckpt_path`: Path to the pre-trained decoder model checkpoint (optional).\n* `tokenizer_path`: Path to the tokenizer model (optional).\n* `device`: Target device for computation (e.g., 'cuda' for GPU, 'cpu' for CPU).\n* `compile`: Boolean flag to indicate whether to compile the GPT model.\n* `coef`: String representing coefficients for DVAE training (optional).\n* `use_flash_attn`: Boolean flag to enable flash attention in GPT (optional).\n\n**[Output]**\n* True: Indicates that all models were successfully loaded and the system is ready to use.  \n"
    },
    "ChatTTS__model__tokenizer__Tokenizer__encode": {
        "label": "encode",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/tokenizer.py",
        "relativePath": "ChatTTS/model/tokenizer.py",
        "lineNo": 37,
        "endLineNo": 130,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Ftokenizer.py%23L37-L130&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Summary\n\nThis function processes a list of text strings, potentially incorporating a pre-defined prompt, and prepares it as input for a Transformer-based language model.  It tokenizes, pads, and masks the text, and adds the prompt to the input sequence if provided.  The goal is to standardize the input format for consistent processing by the model.\n\n## Inputs\n\n* `text`: A list of strings representing the text to be processed.\n* `num_vq`: An integer specifying the number of vector quantization (VQ) dimensions.\n* `prompt_str`: An optional string containing a pre-defined prompt to be added to the input.\n* `device`: A string (\"cpu\" or \"gpu\") indicating the device on which to perform computations.\n\n## Output\n\n* `new_input_ids`: A tensor containing the tokenized and padded input sequence with the prompt included. \n* `attention_mask`: A tensor indicating which tokens in the input sequence are real tokens (not padding).\n* `text_mask`: A boolean tensor derived from the attention_mask, likely used to filter or mask parts of the input. \n\n\n\n"
    },
    "ChatTTS__core__Chat___infer_code": {
        "label": "_infer_code",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 455,
        "endLineNo": 545,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L455-L545&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function processes text input, generates code with a pre-trained GPT model, and returns the generated code along with potential hidden layer outputs. The purpose of the code is to enable natural language driven code generation using a GPT-based model.  \n\n## Inputs\n\n* `text`:  List of strings representing the text input to be used for code generation.\n* `stream`: Boolean indicating whether to stream the generated output. \n* `device`:  The device (CPU or GPU) where the model will be executed.\n* `return_hidden`: Boolean indicating whether to return the hidden states from the GPT model.\n* `params`:  A class containing parameters that control the code generation process, such as temperature, top-k, top-p, and repetition penalty. \n\n## Output\n\n*  Generated code as output.\n*  Optional hidden states output if `return_hidden` is True. \n\n\n"
    },
    "ChatTTS__norm__Normalizer____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 38,
        "endLineNo": 128,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L38-L128&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**Quick Summary:**\n\nThis Python function initializes a text preprocessing pipeline for Chinese text. It aims to clean and normalize text by handling homophones (words with similar pronunciation), standardizing punctuation, and converting between halfwidth and fullwidth characters.\n\n**Inputs:**\n\n\n*  `logger`: A logging object used for recording messages and debugging.\n*  `map_file_path`:  A path to a JSON file containing a mapping of pinyin (phonetic transcription) to common Chinese characters, used for correcting homophone errors.\n\n**Output:**\n\n*  An object (`self`) containing the initialized preprocessing components:\n    *   `homophones_map`: The loaded homophone mapping. \n    \n    *   Other attributes (`normalizers`, `coding`, `reject_pattern`, `sub_pattern`, `chinese_char_pattern`, `english_word_pattern`, `character_simplifier`, `halfwidth_2_fullwidth`) that define regular expressions and character conversions for text preprocessing. \n\n\n\n\n\n\n"
    },
    "ChatTTS__core__Chat___infer": {
        "label": "_infer",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 339,
        "endLineNo": 417,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L339-L417&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "You got it! Here's a breakdown of the code snippet:\n\n**[Quick Summary]**\n\nThis Python function converts text into speech (audio waveforms) using a pre-trained speech synthesis model. It performs text normalization, optional text refinement, and then generates audio using the model. There's also support for streaming audio output, allowing for real-time generation.\n\n**[Inputs]**\n\n*  `text`: The input text to be converted to speech. Can be a string or a list of strings.\n*  `stream`:  A boolean indicating whether to stream the generated audio output (True) or generate it all at once (False).\n*  `lang`: The language code of the input text (e.g., 'en' for English).\n*  `skip_refine_text`:  A boolean indicating whether to skip the text refinement step.\n*  `refine_text_only`: A boolean indicating whether to only return the refined text and not generate audio.\n*  `use_decoder`: A boolean indicating whether to use the decoder component of the speech synthesis model.\n*  `do_text_normalization`: A boolean indicating whether to perform text normalization (e.g., handling contractions, punctuation).\n*  `do_homophone_replacement`: A boolean indicating whether to replace homophones (words that sound alike but have different meanings).\n*  `params_refine_text`:  Parameters for the text refinement process.\n*  `params_infer_code`: Parameters for the speech synthesis inference process.\n\n**[Output]**\n\n* Audio waveforms:  The generated speech audio, represented as numerical data. It may be streamed or returned as a complete array. \n\n\n"
    },
    "stream__ChatStreamer__generate": {
        "label": "generate",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 75,
        "endLineNo": 148,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L75-L148&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis Breakdown:\n\n**[Quick Summary]**\n\nThis function processes a stream of audio data, likely from a conversational chatbot, segmenting it based on pauses or silence. It applies audio formating, potentially including normalization, and yields the formatted audio samples sequentially for streaming playback or further processing. The overall purpose seems to be the efficient and structured handling of audio input from a conversational AI.\n\n**[Inputs]**\n\n* `streamchat`: This likely represents a list or generator of audio data segments, potentially from a conversation.\n* `output_format`: A string specifying the desired output audio format (e.g., \"PCM16_byte\", \"PCM16\").  \n* `base_block_size`: An integer determining the target block size for audio segmentation.\n\n**[Output]**\n\n* Yields formatted audio samples (potentially NumPy arrays representing audio data) based on the segmented conversation, allowing for streaming playback or other operations on individual audio segments. \n\n\n"
    },
    "ChatTTS__utils__dl__download_all_assets": {
        "label": "download_all_assets",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/dl.py",
        "relativePath": "ChatTTS/utils/dl.py",
        "lineNo": 104,
        "endLineNo": 172,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fdl.py%23L104-L172&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**Quick Summary:** This function downloads and executes the `rvcmd` tool necessary for interacting with the RVC (Real Value Computing)  speech synthesis model. It handles different operating systems and architectures, utilizing a fallback mechanism if the primary download source is unavailable. The ultimate purpose is to initiate a speech synthesis process using the `assets/chtts` dataset.\n\n**Inputs:**\n\n* `version`: The version number of the desired `rvcmd` tool.\n* `tmpdir`: A temporary directory for downloading and extracting files.\n* `logger`: A logging object used for error reporting.\n\n**Output:**\n\n* Successful execution of the `rvcmd` tool with the `-notui`, `-w`, and `assets/chtts` arguments.\n* Error report if the specified architecture is unsupported.\n\n\n\n\n"
    },
    "ChatTTS__model__gpt__GPT____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 23,
        "endLineNo": 85,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L23-L85&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\nThis function initializes a model that combines a pre-trained Llama model with a Vector Quantization (VQ) embedding layer for audio data. It likely aims to process both textual and audio inputs, possibly for a multimodal understanding or generation task.\n\n## Inputs\n* **gpt_config:** A dictionary containing configuration parameters for the Llama model.\n* **num_audio_tokens:**  The number of unique audio tokens in the vocabulary.\n* **num_text_tokens:** The number of unique text tokens in the vocabulary.\n* **num_vq:** The number of clusters used in the VQ embedding.\n* **use_flash_attn:** A boolean indicating whether to use the Flash Attention mechanism (likely for efficiency).\n* **device:**  The device (CPU or GPU) to run the model on.\n* **logger:** A logging object for recording information during training or inference. \n\n## Output\n*  **An initialized model:**  A PyTorch model object combining the Llama model with the VQ embedding layers. \n\n\n"
    },
    "ChatTTS__model__dvae__GFSQ": {
        "label": "GFSQ",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 68,
        "endLineNo": 129,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L68-L129&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function implements a quantizer for a tensor, likely within a larger neural network model. It uses grouped residual finite state quantization (GFSQ) to compress the input data while preserving essential information. The quantized output can then be used for efficient computations and model activation.\n\n## Inputs\n\n* **`x`:** A torch.Tensor representing the input data to be quantized.\n* **`dim`:** An integer specifying the dimensionality of the input data.\n* **`levels`:**  A list of integers defining the quantization levels for each dimension.\n* **`G`:** An integer indicating the number of groups for grouped quantization.\n* **`R`:** An integer specifying the number of residual values for each group.\n* **`eps`:** A small floating-point value (default 1e-5) used for numerical stability.\n* **`transpose`:** A boolean flag (default True) controlling the transposition of input and output tensors.\n\n## Output\n\n* **`ind`:** A torch.Tensor containing the quantized indices of the input data. \n\n\n"
    },
    "ChatTTS__model__cuda__te_llama___replace_params": {
        "label": "_replace_params",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 134,
        "endLineNo": 192,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L134-L192&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function aims to migrate weights from a HuggingFace (HF) model's state dictionary (`hf_state_dict`) to a different model's state dictionary (`te_state_dict`), specifically focusing on layers with prefixes matching a pattern. It assumes both models have similar layer structures and adjusts key names for compatibility.\n\n## Inputs\n\n*  `hf_state_dict`: A dictionary containing the pre-trained weights from a HuggingFace model.\n*  `te_state_dict`: An empty dictionary representing the target model's state dictionary where weights will be loaded.\n*  `config`: This likely refers to a configuration object containing model-specific parameters like `intermediate_size`.\n\n## Output\n\n*  `all_layer_prefixes`: A set containing the prefixes of all layers successfully processed in the mapping. \n"
    },
    "ChatTTS__core__Chat__download_models": {
        "label": "download_models",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 68,
        "endLineNo": 123,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L68-L123&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function downloads and handles asset locations for a language model. \n\nIt determines the source of the model (local, Huggingface, or custom) and downloads necessary files if required. It validates downloaded assets using checksums for integrity. \n\nThe purpose seems to be managing efficient and reliable model loading.\n\n## Inputs\n\n* `source`: A string specifying the source of the model (\"huggingface\", \"local\", or \"custom\").\n* `force_redownload`: A boolean indicating if the assets should be re-downloaded even if present.\n* `custom_path`: An optional file-like object pointing to a custom location for the model.\n\n## Output\n\n* A string representing the file path to the downloaded or selected model directory. \n"
    },
    "ChatTTS__core__Chat___refine_text": {
        "label": "_refine_text",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 547,
        "endLineNo": 601,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L547-L601&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown\n\n**Quick Summary:** This function generates text using a pre-trained GPT model. It takes input text, device information, and generation parameters, processes them, and outputs generated text. The code's purpose is to provide a user-friendly interface for text generation with customizable parameters.\n\n**Inputs:**\n\n*  `text`: A string or list of strings representing the input text to be processed.\n*  `device`: A PyTorch device object specifying where the computation should be performed (e.g., CPU or GPU).\n*  `params`: A `RefineTextParams` object containing generation parameters like temperature, top_P, top_K, repetition penalty, etc.\n\n**Output:**\n\n*  Generated text: A string or list of strings containing the text generated by the GPT model. \n"
    },
    "ChatTTS__model__dvae__ConvNeXtBlock": {
        "label": "ConvNeXtBlock",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 13,
        "endLineNo": 67,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L13-L67&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary:** This function implements a ConvNeXt block, a type of neural network building block used in architectures like convolutional transformers. It applies depthwise convolution, pointwise convolutions, activation, and normalization to process an input tensor and create a residual connection.  Likely used to build a larger convolutional network.\n\n**Inputs:**\n\n*  `x`: This is the input tensor, representing a feature map or intermediate output from a previous layer.\n* `cond`: This input is unused in the provided code, suggesting it may be a placeholder for potential future conditional information (e.g., attention masks, control signals).\n\n**Output:**\n\n* A modified input tensor (`x`) representing the processed feature map after applying the ConvNeXt block operations.\n\n\n"
    },
    "main__generate_voice": {
        "label": "generate_voice",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/api/main.py",
        "relativePath": "examples/api/main.py",
        "lineNo": 62,
        "endLineNo": 110,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fapi%2Fmain.py%23L62-L110&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function takes user text input, processes it using a text-to-speech (TTS) model (`chat`), and generates synthesized audio. It then compresses the audio files into a ZIP archive for download. The overall purpose is to provide a downloadable audio file containing the synthesized voice of the user's text input.\n\n## Inputs\n\n* **params.text:** Text string to be converted to speech.\n* **params.audio_seed:**  Seed value for random number generation in the audio synthesis process.\n* **params.text_seed:** Seed value for random number generation during text refining. \n* **params.stream:**  Indicates whether audio should be streamed (e.g., live) or generated as files.\n* **params.lang:** Language code for the input text.\n* **params.skip_refine_text:** Boolean indicating whether to skip text refining.\n* **params.use_decoder:** Boolean indicating whether to use a decoder for speech synthesis.\n* **params.do_text_normalization:** Boolean indicating whether to apply text normalization.\n* **params.do_homophone_replacement:** Boolean indicating whether to replace homophones.\n* **params.params_infer_code:**  Parameters specific to the code generation model.\n* **params.params_refine_text:** Parameters specific to the text refining process.\n\n\n## Output\n\n* **StreamingResponse:** A streaming response containing a ZIP archive of synthesized MP3 audio files. \n* **headers:** The \"Content-Disposition\" header is set to `attachment; filename=audio_files.zip`, prompting the browser to download the file.\n\n\n\n\n"
    },
    "ChatTTS__model__cuda__te_llama__TELlamaDecoderLayer": {
        "label": "TELlamaDecoderLayer",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 50,
        "endLineNo": 95,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L50-L95&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines a wrapper class around `TE.TransformerLayer` to make it work more like `HF.LlamaDecoderLayer`. The purpose is to enable easier replacement of the decoder layer in a model built with HuggingFace Transformer components with one from the TE toolkit. \n\n\n## Inputs\n\n*  `config`: Configuration object (likely a `LlamaConfig` instance) containing model parameters like hidden size, attention heads, etc.\n*  `args`: Positional arguments, intended for compatibility with `LlamaDecoderLayer`. Specific meaning depends on the underlying `TransformerLayer`.\n*  `kwargs`: Keyword arguments, also for compatibility with `LlamaDecoderLayer`. \n*  `hidden_states`: The input tensor containing the hidden states of the model.\n*  `attention_mask`: A tensor indicating which tokens are attended to (e.g., for padding).\n*  `rotary_pos_emb`: Rotary Position Embedding tensor likely specific to the TE framework.\n\n## Output\n\n* A tensor representing the transformed hidden states, formatted to match the output of `HF.LlamaDecoderLayer`.  \n"
    },
    "web__funcs__generate_audio": {
        "label": "generate_audio",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 153,
        "endLineNo": 197,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L153-L197&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**\n\nThis function generates speech audio from given text input, incorporating speaker embedding and optional audio/text samples for fine-tuning. It utilizes a `chat` object (likely a text-to-speech model) and handles streaming audio output if requested. \n\n**Inputs:**\n\n* `text`: The input text to be converted to speech.\n* `temperature`: A parameter controlling the randomness of the generated speech.\n* `top_P`:  A parameter controlling the nucleus sampling for text generation.\n* `top_K`:  A parameter limiting the number of most likely tokens considered during text generation.\n* `spk_emb_text`:  A string representing the speaker embedding, likely a vector encoding the speaker's characteristics.\n* `stream`: A boolean indicating whether to stream the audio output or return it as a single chunk.\n* `audio_seed_input`: A seed value for audio generation, ensuring reproducibility.\n* `sample_text_input`: Optional text sample for fine-tuning the speech generation.\n* `sample_audio_code_input`: Optional audio code sample for fine-tuning the speech generation.\n\n**Output:**\n\n*  A generator yielding (sample_rate, audio_data) pairs.\n    * `sample_rate`:  The audio sample rate (likely 24000 Hz).\n    * `audio_data`:  The generated audio data as 16-bit integers. \n\n\n\n"
    },
    "web__webui__main__make_audio": {
        "label": "make_audio",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/webui.py",
        "relativePath": "examples/web/webui.py",
        "lineNo": 185,
        "endLineNo": 229,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Fwebui.py%23L185-L229&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown:\n\n**Quick Summary:** This code defines a function that orchestrates the text-to-speech generation process. It handles user inputs for text, audio parameters, and other settings, then triggers a sequence of operations to generate and display audio output. This likely forms part of a larger application allowing users to create spoken versions of their text input. \n\n**Inputs:**\n\n* `text_input`: User-provided text\n* `text_seed_input`:  A seed value potentially used for text generation.\n* `refine_text_checkbox`:  A toggle to control whether the text undergoes refinement.\n* `temperature_slider`: A slider controlling the randomness of the generated audio.\n* `top_p_slider`: A slider controlling the nucleus sampling probability.\n* `top_k_slider`: A slider controlling the number of top-k tokens considered.\n* `spk_emb_text`:  Textual representation of speaker embedding (potentially).\n* `stream_mode_checkbox`: Toggle for streaming audio output. \n* `audio_seed_input`: Seed value for audio generation.\n* `sample_text_input`: Text used for sampling audio.\n* `sample_audio_code_input`: Audio code used for sampling audio. \n* `generate_button`: Button triggering the text-to-speech process.\n* `interrupt_button`: Button to interrupt the generation process.\n\n**Outputs:**\n\n* `audio_output`:  An Audio component displaying the generated audio. \n\n\n"
    },
    "ChatTTS__model__dvae__DVAEDecoder": {
        "label": "DVAEDecoder",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 130,
        "endLineNo": 173,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L130-L173&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function defines a 1-dimensional convolutional neural network model for audio processing or time series data.  It uses a hierarchical structure with a series of convolutional blocks to learn complex temporal features and then maps the output to a desired dimension.\n\n## Inputs\n\n* `x`: This is the input tensor, likely representing audio data or a time series.Its shape is expected to be (Batch, Channels, Time).\n* `conditioning`: This is an optional input, potentially used to provide additional context or guidance to the model during training or inference. It could represent features related to the input audio or other auxiliary information.\n\n## Output\n\n* A tensor of shape (Batch, odim, Time) containing the processed audio features or a transformed representation of the input time series. \n\n\n\n"
    },
    "run__main": {
        "label": "main",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/run.py",
        "relativePath": "examples/cmd/run.py",
        "lineNo": 30,
        "endLineNo": 70,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Frun.py%23L30-L70&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary:\n\nThis function generates speech audio from given text input using the ChatTTS model. It selects a random speaker, infers the speech from the text, and saves each generated audio segment as a separate MP3 file. The code aims to demonstrate text-to-speech functionality within a Python environment using the ChatTTS library. \n\n## Inputs:\n\n\n* `texts`: This is likely a list of strings containing the text to be converted into speech.\n* `stream`:  This is a boolean value, likely indicating whether the output audio should be streamed or saved as individual files.\n* `spk`:  This could be an identifier or embedding representing a specific speaker from the ChatTTS model. If `None`, it randomly selects a speaker.\n\n## Output:\n\n* **Generated audio files:** MP3 files, each containing a segment of speech corresponding to a text input. \n* **Streaming audio:** If `stream` is True, the audio will be streamed.  \n* **No explicit return value:** The function primarily focuses on saving/streaming the audio output. \n\n\n\n"
    },
    "ChatTTS__model__cuda__te_llama__TELlamaModel": {
        "label": "TELlamaModel",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 96,
        "endLineNo": 133,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L96-L133&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis code defines a custom class that inherits from `LlamaModel`, enhancing it by incorporating custom decoder layers (`TELlamaDecoderLayer`) and loading state dictionaries in a specialized manner. The purpose is to create a modified Llama language model tailored for a specific application or framework (likely TransformerEngine).\n\n[Inputs]\n- `config`:  `LlamaConfig` object,  likely containing model hyperparameters and architecture details.\n- `state_dict`: A dictionary of model weights and parameters, presumably from a pre-trained Llama model or a saved checkpoint.\n\n[Output]\n- A modified `LlamaModel` instance with the following changes:\n    - Uses `TELlamaDecoderLayer` instead of the standard `LlamaDecoderLayer`.\n    -  State parameters are loaded in a specific way, potentially handling custom additions or modifications introduced by the `TELlamaDecoderLayer`. \n\n\n\n"
    },
    "stream__ChatStreamer__play": {
        "label": "play",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 149,
        "endLineNo": 186,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L149-L186&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis function generates audio output from a given `streamchat` using a specified format (likely textual representation of sound data). It aims to deliver the audio through an output stream, ensuring a smooth playback by pre-filling the buffer with enough data before starting. \n\n## Inputs\n\n* `streamchat`: This likely represents a textual representation or data source containing audio information.\n* `output_format`: Specifies the format the generated audio should be in (in this case \"PCM16_byte\").\n* `wait`: Numerical value might indicate a desired delay or buffer filling time before starting audio playback.\n\n## Output\n\n*  Plays audio through the connected speakers represented by the `stream_out`. \n"
    },
    "tools__audio__av__load_audio": {
        "label": "load_audio",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/audio/av.py",
        "relativePath": "tools/audio/av.py",
        "lineNo": 42,
        "endLineNo": 79,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Faudio%2Fav.py%23L42-L79&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Audio Loading Function Summary\n\nThis function loads an audio file and converts it to a NumPy array of floating-point samples at a specified sampling rate (sr).  The code likely aims to process audio data for voice conversion applications.\n\n\n## Inputs\n\n*  **file:**  The path to the audio file to be loaded.\n* **sr:** The desired sampling rate for the output audio data.\n\n\n\n## Output\n\n* **decoded_audio:** A NumPy array containing the audio data as floating-point samples at the specified sampling rate (sr). \n\n"
    },
    "ChatTTS__model__dvae__DVAE__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 251,
        "endLineNo": 286,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L251-L286&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function processes an input tensor, potentially encoding and decoding it using a VQ layer and a decoder network. It aims to generate a potentially modified version of the input, likely involving vector quantization and learned transformations.\n\n## Inputs\n\n* **inp:**  A torch.Tensor, representing the input data (likely audio or a representation thereof).\n\n* **mode:** A string (\"encode\" or \"decode\") specifying the function's operation.\n\n## Output\n\n* A torch.Tensor, representing the processed output data. \n\n\n"
    },
    "ChatTTS__utils__gpu__select_device": {
        "label": "select_device",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/gpu.py",
        "relativePath": "ChatTTS/utils/gpu.py",
        "lineNo": 6,
        "endLineNo": 40,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fgpu.py%23L6-L40&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function determines the optimal device (CPU, GPU, or MPS) for running PyTorch models based on available resources and experimental flags. It prioritizes GPUs with the most free memory and offers MPS as an experimental option for Apple silicon.\n\n## Inputs\n\n* `min_memory`:  A minimum required amount of free memory (in MB) on the chosen device.\n* `experimental`: A boolean flag indicating whether to experiment with MPS on Apple silicon.\n* `logger`: An object used for logging messages (e.g., warnings or info).\n\n## Output\n\n* `device`:  A `torch.device` object representing the selected device (e.g., \"cpu\", \"cuda:0\", or \"mps\").  \n\n\n"
    },
    "ChatTTS__model__dvae__DVAE____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 206,
        "endLineNo": 239,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L206-L239&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary**\n\nThis function defines a class likely used for speech processing or audio generation. It initializes an audio decoder model with optional encoder and Vector Quantization (VQ) layers, further customizing it through provided configurations and a learned coefficient vector. \n\n**Inputs**\n\n* `decoder_config`: A dictionary likely containing hyperparameters and architectural specifications for the decoder component.\n* `encoder_config`: An optional dictionary with configurations for an encoder component, potentially used for feature extraction.\n* `vq_config`: An optional dictionary for configuring a Vector Quantization layer.\n* `dim`: An integer specifying the dimension of the hidden representations used within the model.\n* `coef`: An optional string representing pre-trained coefficients that are loaded and used within the model.\n\n**Output**\n\n* An initialized instance of the class, ready to be used for decoding audio or generating speech. \n\n\n\n\n"
    },
    "ChatTTS__model__processors__CustomRepetitionPenaltyLogitsProcessorRepeat": {
        "label": "CustomRepetitionPenaltyLogitsProcessorRepeat",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/processors.py",
        "relativePath": "ChatTTS/model/processors.py",
        "lineNo": 6,
        "endLineNo": 37,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fprocessors.py%23L6-L37&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Functionality Analysis\n\n**Quick Summary:** \n\nThis function modifies a set of scores based on the frequency of input tokens, penalizing the scores of frequently used tokens. It aims to prevent over-reliance on common tokens and encourage diversity in token selection.\n\n**Inputs:**\n\n* `input_ids`: A tensor representing the sequence of input tokens.\n* `scores`: A tensor containing the predicted scores for each possible token.\n\n**Output:**\n\n* A modified tensor of scores, adjusted based on token frequency and the penalty parameter. \n\n\n"
    },
    "web__funcs__load_chat": {
        "label": "load_chat",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 62,
        "endLineNo": 93,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L62-L93&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]**\nThis function loads a chat model, either from a default location or a specified custom path. It then attempts to register language normalization procedures for English (using \"nemo_text_processing\") and Chinese (using \"WeTextProcessing\"). The purpose is to set up a chat model for text input processing and potential multilingual support.\n\n**[Inputs]**\n* `cust_path`: A string potentially containing a path to a custom model file.\n* `coef`:  Likely a numerical value or object representing model coefficients.\n* `sys.platform`:  A system-specific identifier (e.g., \"win32\" for Windows).\n\n**[Outputs]**\n* A boolean value indicating whether the model loading was successful (`ret`). \n* Potential side effects: \n    * Registered language normalizers for English and Chinese if the necessary packages are available.  \n    * Error messages if packages are missing or normalizer registration fails.\n    * Updates to the `custom_path` global variable if a custom path was used.   \n\n\n\n"
    },
    "ChatTTS__core__Chat__infer": {
        "label": "infer",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 203,
        "endLineNo": 233,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L203-L233&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary\n\nThis function takes text input and performs code inference, potentially refining the text beforehand. It can generate code output sequentially (streaming) or return a single result. \n\n## Inputs\n\n* `text`: The input text to be converted into code.\n* `stream`: A boolean flag indicating whether to generate code sequentially (True) or return a single result (False).\n* `lang`: The programming language to target for the code generation.\n* `skip_refine_text`: A boolean flag indicating whether to skip text refinement steps.\n* `refine_text_only`:  A boolean flag indicating whether only text refinement should be performed.\n* `use_decoder`: A boolean flag controlling the use of a decoder component in the inference process.\n* `do_text_normalization`: A boolean flag controlling whether text normalization should be applied.\n* `do_homophone_replacement`: A boolean flag controlling whether homophone replacement should be performed.\n* `params_refine_text`:  Parameters to control the text refinement process.\n* `params_infer_code`: Parameters to control the code inference process.\n\n## Output\n\n*  If `stream` is True: A generator object yielding code output sequentially.\n*  If `stream` is False:  A single string containing the generated code.  \n\n\n\n\n"
    },
    "ChatTTS__model__dvae__MelSpectrogramFeatures": {
        "label": "MelSpectrogramFeatures",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 174,
        "endLineNo": 204,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L174-L204&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary**\nThis Python function processes audio input by transforming it into mel-spectrogram features and then applying logarithmic compression. This type of processing is common in speech recognition and music analysis tasks for representing audio data in a more meaningful way for machine learning models.\n\n**Inputs**\n* `audio`: A PyTorch Tensor containing the raw audio signal.\n\n**Output**\n* `features`: A PyTorch Tensor containing the log-mel spectrogram representation of the input audio. \n\n\n\n"
    },
    "ChatTTS__model__dvae__ConvNeXtBlock____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 14,
        "endLineNo": 44,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L14-L44&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary] This Python function defines a `ConvNeXtBlock`, a fundamental building block in the ConvNeXt architectural family. It implements a depthwise convolution followed by pointwise convolutions, a GElu activation function, and layer scaling, designed to enhance feature extraction and representation learning in a neural network, likely for tasks like image or audio recognition.\n\n\n[Inputs]\n- `dim`:  The dimensionality of the input and output feature maps.\n- `intermediate_dim`: The number of channels in the intermediate layer after the depthwise convolution.\n- `kernel`: The size of the convolution kernel.\n- `dilation`: The dilation rate of the convolution kernel, controlling its receptive field.\n\n[Outputs]\n- The output of the `ConvNeXtBlock`, which is a tensor containing feature maps with the same dimensionality as the input (`dim`). \n"
    },
    "ChatTTS__model__dvae__DVAEDecoder____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 131,
        "endLineNo": 161,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L131-L161&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function defines a 1D convolutional neural network (CNN) architecture, likely a part of a larger model for audio processing or time-series analysis. It takes an input signal, processes it through a series of convolutional blocks with increasing depth, then outputs a signal of a different dimensionality. \n\n[Inputs]\n*  `idim`: Number of input features\n*  `odim`: Number of output features\n*  `n_layer`: Number of convolutional blocks in the decoder \n*  `bn_dim`: Dimensionality of the bottleneck layer\n*  `hidden`:  Number of features in the convolutional blocks\n*  `kernel`: Kernel size of the convolutional layers\n*  `dilation`: Dilation rate of the convolutional layers\n*  `up`: Boolean indicating whether upsampling should be applied\n\n[Output]\n* A processed 1D signal with `odim` features.\n\n\n\n\n"
    },
    "ChatTTS__norm__Normalizer____call__": {
        "label": "__call__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 129,
        "endLineNo": 158,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L129-L158&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis function preprocesses text by normalizing it, replacing homophones, and removing invalid characters. The overall purpose is to cleanse and standardize text for further processing, likely in natural language processing (NLP) tasks.\n\n## Inputs\n\n*  `text`: The input string to be preprocessed.\n*  `do_text_normalization`: A boolean flag indicating whether to perform text normalization.\n*  `do_homophone_replacement`: A boolean flag indicating whether to replace homophones.\n*  `lang`: An optional string specifying the language of the input text (\"zh\" for Chinese, \"en\" for English).\n\n## Output\n\n*   A preprocessed string with normalized characters, replaced homophones, and removed invalid characters. \n\n\n"
    },
    "ChatTTS__model__dvae__GFSQ__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 101,
        "endLineNo": 129,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L101-L129&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function processes an input tensor `x`, likely representing audio data, through a quantizer to obtain indices `ind`. It then performs some manipulations on these indices, potentially for embedding or representation learning.  The purpose might be to learn a compact and efficient representation of the input data.\n\n## Inputs\n\n*  `x`: A tensor likely representing audio data. \n*  `self.transpose`: A boolean flag determining whether to transpose the output.\n*  `self.quantizer`:  A quantizer object, likely used to discretize the input data.\n*  `self.n_ind`: An integer representing the number of discrete indices.\n\n## Output\n\n* `ind.transpose_(1, 2) if self.transpose else ind`: The processed indices, possibly transposed depending on the `self.transpose` flag.\n\n\n"
    },
    "ChatTTS__model__gpt__GPT__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 159,
        "endLineNo": 187,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L159-L187&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis function combines textual embeddings with code embeddings to create a unified embedding representation for both. The purpose is likely to be used in a model that processes both text and code, allowing it to understand the relationship between them.\n\n## Inputs\n\n*  `input_ids`:  Tokenized representations of both text and code.\n* `text_mask`: A boolean tensor indicating which tokens are part of the text.\n\n## Output\n\n* `emb`: A tensor containing the combined embeddings for both text and code tokens.  \n\n\n\n\n"
    },
    "ChatTTS__core__Chat___decode_to_wavs": {
        "label": "_decode_to_wavs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 426,
        "endLineNo": 453,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L426-L453&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function takes a list of processed audio features, potentially from a decoder, and converts them into synthesized audio waveforms using a pre-trained vocoder. It processes the features in batches to enhance efficiency.  This code likely represents part of a text-to-speech (TTS) or speech synthesis system. \n\n## Inputs\n\n*  `result_list`: A list of torch tensors containing processed audio features (e.g., mel- spectrograms).\n*  `use_decoder`: A boolean flag indicating whether to use a dedicated decoder model or the shared DVAE model for processing.\n\n## Output\n\n* A tensor containing synthesized audio waveforms.  \n"
    },
    "ChatTTS__model__gpt__GPT___prepare_generation_outputs": {
        "label": "_prepare_generation_outputs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 328,
        "endLineNo": 354,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L328-L354&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary:** This function processes and slices  text input data (likely from a transformer model) based on provided start and end indices. It then combines these slices with corresponding attention and hidden state information before packaging them into a GenerationOutputs object. The purpose is to prepare this data for text generation tasks.\n\n**Inputs:**\n\n* **inputs_ids:** A tensor representing the tokenized input text\n* **start_idx:** An integer indicating the starting index for text slicing\n* **end_idx:** A tensor specifying the ending indices for text slicing\n* **attentions:** A list of optional tuples containing attention weights \n* **hiddens:** A list of tensors representing hidden states \n* **infer_text:** A boolean flag indicating whether text generation is being performed\n\n**Output:**\n\n* **GenerationOutputs:**  An object containing:\n    * **ids:** The sliced tokenized text\n    * **attentions:**  The corresponding attention weights\n    * **hiddens:**  The sliced hidden state information \n\n\n"
    },
    "ChatTTS__utils__dl__check_model": {
        "label": "check_model",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/dl.py",
        "relativePath": "ChatTTS/utils/dl.py",
        "lineNo": 19,
        "endLineNo": 45,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fdl.py%23L19-L45&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis:\n\n**[Quick Summary]**\n\nThis Python function checks the integrity of a model file by comparing its SHA256 hash to an expected hash value.  It ensures the file hasn't been corrupted or tampered with and optionally removes incorrect or outdated copies of the file. \n\n**[Inputs]**\n\n* `dir_name`: Path to the directory where the model file is located.\n* `model_name`: Name of the model file (e.g., \"my_model.pkl\").\n* `hash`: The expected SHA256 hash value of the model file.\n* `remove_incorrect`: A boolean flag indicating whether to remove incorrect model files.\n\n**[Output]**\n\n* `True`: If the file hash matches the expected hash and no inconsistencies are found.\n* `False`: If the file hash doesn't match, or if the `remove_incorrect` flag is set and the file is deemed corrupted/incorrect.\n\n\n"
    },
    "ChatTTS__model__tokenizer__Tokenizer__apply_spk_emb": {
        "label": "apply_spk_emb",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/tokenizer.py",
        "relativePath": "ChatTTS/model/tokenizer.py",
        "lineNo": 143,
        "endLineNo": 168,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Ftokenizer.py%23L143-L168&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]** \n\nThis function modifies a speech embedding tensor (`emb`) by selectively replacing it with a speaker embedding (`n`). It accomplishes this based on a condition derived from an input tensor (`input_ids`) indicating which token corresponds to a specific speaker.\n\n\n**[Inputs]**\n\n*  `emb`: A tensor containing speech embeddings.\n*  `spk_emb`: A string representing a speaker identifier (likely encoded as a numerical representation).\n*  `input_ids`: A tensor likely containing token IDs from a text input, used to identify which tokens belong to the target speaker.\n*  `device`: A torch.device object indicating where the computation should take place (e.g., CPU or GPU).\n\n**[Output]**\n\n* The modified `emb` tensor where embeddings corresponding to the target speaker are replaced with the speaker embedding `n`. \n\n\n"
    },
    "ChatTTS__core__Chat__load": {
        "label": "load",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 124,
        "endLineNo": 147,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L124-L147&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[**Quick Summary**]\n\nThis Python function downloads and loads a pre-trained model. It takes as input the model source (HuggingFace, local file, or custom path), whether to force redownload existing files, compilation settings, and optional parameters for loading the model.  The function returns `True` if the model was successfully loaded, `False` otherwise.\n\n\n[**Inputs**] \n*  `source`: Specifies where to download the model from (\"huggingface\", \"local\", or \"custom\").\n*  `force_redownload`:  Indicates whether to redownload existing model files, even if they are already present.\n*  `compile`:  Controls whether to compile the model for faster inference.\n*  `custom_path`:  An optional path to a custom model directory.\n*  `device`:  The device (CPU or GPU) to load the model onto.\n*  `coef`:  An optional tensor containing model coefficients.\n*  `use_flash_attn`:  A boolean flag enabling FlashAttention, a memory-efficient attention mechanism.\n\n[**Output**]\n*  `True`: If the model was successfully downloaded and loaded.\n*  `False`: If there were errors during the download or loading process. \n\n\n\n"
    },
    "ChatTTS__model__dvae__ConvNeXtBlock__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 45,
        "endLineNo": 67,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L45-L67&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:**\n\nThis function implements a residual block commonly found in deep learning architectures like ResNet. It takes an input tensor, applies a sequence of convolutions, normalization, and activation functions, and then adds the result to the original input (residual) for improved gradient flow and deeper network training.\n\n**Inputs:**\n\n*  `x`: The input tensor to the residual block.\n\n**Output:**\n\n* `x`: The modified output tensor after applying the residual block operations. \n\n\n"
    },
    "ChatTTS__model__gpt__GPT__from_pretrained": {
        "label": "from_pretrained",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 86,
        "endLineNo": 108,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L86-L108&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function loads a pre-trained language model from a file. \n\nIt then attempts to optimize the model for NVIDIA GPUs on Linux systems by switching to a CUDA-accelerated version if available. If the CUDA acceleration fails, it reverts to the default implementation.\n\n[Purpose:  To efficiently load and potentially accelerate a language model based on system capabilities.]\n\n## Inputs\n\n* `file_path`: Path to the file containing the pre-trained model weights.\n* `self.device_gpt`: This likely refers to the device (CPU or GPU) where the model should be loaded.\n\n## Output\n\n* An instance of a language model: \n    * This could be either the standard `LlamaModel` or the CUDA-accelerated `TELlamaModel` if the conditions are met. \n    * The model will be loaded with the weights from the specified `file_path`.\n\n\n"
    },
    "ChatTTS__utils__io__del_all": {
        "label": "del_all",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/io.py",
        "relativePath": "ChatTTS/utils/io.py",
        "lineNo": 22,
        "endLineNo": 44,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fio.py%23L22-L44&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Summary:**\n\nThis function safely removes all nested data structures (dicts, lists, and dataclasses) from a given input. It recursively delves into each nested level, emptying them before ultimately deleting the entire input. This likely serves a purpose like cleaning data for storage or transmission where complex structures might be problematic.\n\n**Inputs:**\n\n* **d:** The primary input, which can be:\n    * A dataclass\n    * A dictionary\n    * A list\n    * Any other data type\n\n**Output:**\n\n* The function eliminates the input `d` and all its nested data structures (dicts, lists, dataclasses). \n* Nothing is returned explicitly. \n\n\n\n"
    },
    "web__funcs__reload_chat": {
        "label": "reload_chat",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 94,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L94-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**[Quick Summary]**\n\nThis function attempts to reload a chatbot model from a specified path (`custom_path`). It first checks if the model is currently being generated, preventing reloading during that process. It then unloads any existing model, loads the new one using provided coefficients (`coef`), and if successful, returns the updated model coefficients. \n\n**[Inputs]**\n\n* `coef`: A list of 230 floating-point numbers representing the model coefficients.\n* `custom_path`: A string indicating the path to the model file.\n\n**[Output]**\n\n*  `chat.coef`: A list of 230 floating-point numbers, representing the updated model coefficients.\n"
    },
    "ChatTTS__model__gpt__GPT___build_llama": {
        "label": "_build_llama",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 119,
        "endLineNo": 140,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L119-L140&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]**\n\nThis function initializes a Llama model, potentially using an accelerated attention mechanism (\"flash_attention_2\").  It removes the `embed_tokens` layer for potential modification or efficiency, and returns the model on a specified device (e.g., CPU or GPU). The purpose is to customize and prepare a Llama model for use in downstream tasks or fine-tuning.\n\n**[Inputs]**\n\n* **`self`:** Likely an instance of a class containing additional configuration and functionality.\n* **`config: dict`:** A dictionary containing parameters to configure the Llama model (e.g., number of layers, hidden size, etc.).\n* **`device: torch.device`:** Specifies the hardware device (CPU or GPU) on which the model will be loaded and executed.\n\n**[Output]**\n\n* **`Tuple[LlamaModel, LlamaConfig]`:**  \n    * A LlamaModel instance, ready for use.\n    * The LlamaConfig object used to define the model's parameters.  \n\n\n"
    },
    "ChatTTS__utils__dl__check_all_assets": {
        "label": "check_all_assets",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/dl.py",
        "relativePath": "ChatTTS/utils/dl.py",
        "lineNo": 46,
        "endLineNo": 67,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fdl.py%23L46-L67&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary**\n\nThis function verifies the integrity of pre-trained machine learning models stored in a \"asset\" directory. It compares the SHA256 checksums of the downloaded models with expected checksums, downloaded through a map (`sha256_map`). If any checksums don't match, the download is considered corrupted, and the function returns False, suggesting an update is needed.  If all checksums match, the function logs a success message and returns True.\n\n**Inputs**\n\n* **base_dir:** Path to the base directory where the \"asset\" folder resides.\n* **sha256_map:** A dictionary containing expected SHA256 checksums for the models.\n* **update:** A boolean flag indicating whether to automatically update the models if they are outdated.\n* **logger:** A logging object used for informational messages.\n\n**Output**\n\n* **Boolean:** True if all models are up-to-date and have valid checksums, False otherwise. \n\n\n\n"
    },
    "tools__audio__av__wav2": {
        "label": "wav2",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/audio/av.py",
        "relativePath": "tools/audio/av.py",
        "lineNo": 20,
        "endLineNo": 41,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Faudio%2Fav.py%23L20-L41&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis:\n\n**[Quick summary]** \n\nThis Python function takes an audio file (input) and converts its format to a specified output format. It uses the `av` library to decode the input audio and encode it to the desired output format, writing the result to a new audio file. \n\n**[Inputs]**\n\n* `i`: Path to the input audio file.\n* `o`: Path to the output audio file.\n* `format`:  Desired output audio format (likely a string identifier). \n* `video_format_dict`, `audio_format_dict`: Dictionaries mapping format names to actual AVFormatContext definitions. \n\n**[Output]**\n\n* A new audio file at the specified `o` path with the converted format. \n"
    },
    "ChatTTS__model__cuda__te_llama__replace_decoder": {
        "label": "replace_decoder",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 29,
        "endLineNo": 49,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L29-L49&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function temporarily replaces the standard `LlamaDecoderLayer` and `LlamaRMSNorm` classes within the Hugging Face Transformers library with custom implementations (`te_decoder_cls` and `llama_rms_norm_cls`). This likely allows for testing or modification of these critical components within the Llama model without affecting the main library.\n\n## Inputs\n\n*  `te_decoder_cls`: A custom class representing the modified `LlamaDecoderLayer`.\n*  `llama_rms_norm_cls`: A custom class representing the modified `LlamaRMSNorm`. \n\n## Outputs\n\n* Implicitly: \n    *  Allows the use of the custom `LlamaDecoderLayer` and `LlamaRMSNorm` classes within the Llama model context.\n    *  Restores the original `LlamaDecoderLayer` and `LlamaRMSNorm` classes after the `yield` statement is completed (transient modification). \n\n\n\n"
    },
    "ChatTTS__model__dvae__MelSpectrogramFeatures____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 175,
        "endLineNo": 195,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L175-L195&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis function initializes a MelSpectrogram transformation using PyTorch's torchaudio library. The MelSpectrogram transforms an audio signal into a spectrogram representation using a Mel filterbank, which is useful for speech and music analysis tasks.\n\n## Inputs\n\n* `sample_rate`: The sampling rate of the input audio signal (samples per second). \n* `n_fft`: The number of samples to consider for each FFT calculation.\n* `hop_length`: The number of samples to hop between successive FFT calculations.\n* `n_mels`: The number of Mel-scale filter banks to use.\n* `padding`: Specifies how to pad the input audio signal, either \"center\" (pad equally on both sides) or \"same\" (pad to maintain output size).\n\n## Output\n\n*  A PyTorch tensor containing the Mel spectrogram representation of the input audio signal. \n\n\n"
    },
    "ChatTTS__model__processors__gen_logits": {
        "label": "gen_logits",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/processors.py",
        "relativePath": "ChatTTS/model/processors.py",
        "lineNo": 38,
        "endLineNo": 58,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fprocessors.py%23L38-L58&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]**\n\nThis function configures and returns lists of  \"logits warpers\" and \"logits processors\" used to modify the output probabilities of a text generation model. These modifications aim to control the generation process, encouraging diversity and preventing repetition.\n\n**[Inputs]**\n\n* `num_code`: An integer potentially representing the number of possible code tokens.\n* `top_P`: A float (0-1) controlling the proportion of top-scoring tokens to consider during generation (nucleus sampling).\n* `top_K`: An integer limiting the number of highest-scoring tokens considered during generation.\n* `repetition_penalty`: A float > 1 that penalizes the model for repeating previously generated tokens.\n\n**[Output]**\n\n* Two lists:\n    * `logits_warpers`: Contains instances of `TopPLogitsWarper` and `TopKLogitsWarper`, which adjust token probabilities based on `top_P` and `top_K`.\n    * `logits_processors`: Contains an instance of `CustomRepetitionPenaltyLogitsProcessorRepeat` which modifies token probabilities to discourage repetition based on  `repetition_penalty` and `num_code`.  \n\n\n"
    },
    "tools__logger__log__Formatter": {
        "label": "Formatter",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/logger/log.py",
        "relativePath": "tools/logger/log.py",
        "lineNo": 37,
        "endLineNo": 57,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Flogger%2Flog.py%23L37-L57&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function customizes the formatting of log messages. It takes a log record as input, adds timestamp, log level, and source information (filename and function), and applies colored formatting if the system is not Windows.\n\n## Inputs\n\n* `record`: A logging.LogRecord object containing details about the logged event (level, message, filename, function name, etc.).\n\n## Output\n\n* A formatted string representation of the log message including timestamp, log level, source information, and optional colored formatting. \n"
    },
    "web__funcs__refine_text": {
        "label": "refine_text",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 132,
        "endLineNo": 152,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L132-L152&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]** This function refines text generated by a language model (likely `chat`). It takes the initial text and a seed input for reproducibility, then uses the model to refine only the generated text. A short pause ensures the initial text doesn't appear as a quick response. \n\n**[Inputs]**\n - `text`: The initial text generated by the language model.\n - `text_seed_input`:  A value used for seeding the language model's random number generator, ensuring reproducible results.\n - `refine_text_flag`:  A boolean indicating whether to refine the text. \n\n**[Output]**\n-  Refined text generated by the language model. \n\n\n"
    },
    "ChatTTS__model__cuda__te_llama__TELlamaDecoderLayer____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 61,
        "endLineNo": 80,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L61-L80&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines and initializes a  transformer encoder layer, likely part of a larger language model.  It utilizes a specialized positional embedding called RotaryPositionEmbedding, which is then stored on the GPU for efficient processing.\n\n## Inputs\n\n* `config`:  A configuration object containing hyperparameters for the layer, such as hidden size, number of attention heads, and maximum sequence length.\n\n\n## Output\n\n* `self.te_rope_emb`: A tensor containing the pre-computed rotary positional embeddings for a given sequence length. This is stored on the GPU (indicated by \".cuda()\").  \n"
    },
    "ChatTTS__model__cuda__te_llama__TELlamaModel__from_state_dict": {
        "label": "from_state_dict",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 114,
        "endLineNo": 133,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L114-L133&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary\n\nThis function loads a pre-trained model state dictionary into a vanilla (unmodified) model instance. It aims to combine the weights from pre-trained components with potentially custom components in a specialized  model type, likely \"TransformerEngine.\"\n\n## Inputs\n\n* `cls`: presumably a class definition for the vanilla model\n* `state_dict`: a dictionary containing the pre-trained model weights\n* `config`: a configuration object defining the model architecture\n\n## Output\n\n* A \"vanilla\" model instance loaded with pre-trained weights from `state_dict` \n\n\n"
    },
    "ChatTTS__model__processors__CustomRepetitionPenaltyLogitsProcessorRepeat____call__": {
        "label": "__call__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/processors.py",
        "relativePath": "ChatTTS/model/processors.py",
        "lineNo": 18,
        "endLineNo": 37,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fprocessors.py%23L18-L37&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function modifies probability scores (likely for text generation) by penalizing frequent input tokens. This is done to encourage diversity in the generated output and avoid repetitive patterns. \n\n## Inputs\n\n* **input_ids**: A tensor containing integers representing input tokens.\n* **scores**: A tensor containing floating-point probabilities for each possible next token. \n\n## Output\n* A modified tensor of probabilities, potentially suitable for sampling the next token. \n\n\n\n"
    },
    "tools__llm__llm__ChatOpenAI": {
        "label": "ChatOpenAI",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/llm/llm.py",
        "relativePath": "tools/llm/llm.py",
        "lineNo": 55,
        "endLineNo": 74,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fllm%2Fllm.py%23L55-L74&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**[Quick summary]**\n\nThis function, `call`, interacts with the OpenAI API using a provided API key and base URL. It sends a user's question to the specified OpenAI model, incorporating a pre-defined prompt structure and customizable parameters like temperature. The function then returns the model's generated response.\n\nThe purpose of this code is to streamline interactions with OpenAI's API for generating text responses based on user input.\n\n**[Inputs]**\n\n*   `user_question`: The question or text prompt provided by the user.\n*   `temperature`: A value (between 0 and 1) that controls the randomness or creativity of the model's response.\n*   `prompt_version`: Specifies which predefined prompt structure to use. \n*   `kwargs`: Additional keyword arguments that can be passed to the OpenAI API call.\n\n**[Output]**\n\n*   The text generated by the OpenAI model in response to the `user_question`. \n\n\n"
    },
    "ChatTTS__core__Chat__has_loaded": {
        "label": "has_loaded",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 49,
        "endLineNo": 67,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L49-L67&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**[Quick Summary]**  This function checks if all necessary components (like 'vocos', 'gpt', 'tokenizer', etc.) are initialized within a class instance. It logs warnings if any are missing and indicates successful initialization. \n\n**[Inputs]**\n\n* `self`:  A reference to the current class instance.\n* `use_decoder`: A boolean value indicating whether a decoder model is being used.\n\n\n**[Output]**\n\n*  `True` if all required components are initialized.\n* `False` if any component is missing.  \n\n\n\n"
    },
    "ChatTTS__model__gpt__GPT___GenerationInputs": {
        "label": "_GenerationInputs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 189,
        "endLineNo": 207,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L189-L207&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis function, `to`, is designed to move a Transformer model's tensors (data structures) to a specific device (e.g., CPU or GPU) and potentially change their data type. Its purpose is to ensure all model components are located in the desired environment for efficient computation.\n\n[Inputs]\n\n* `device`: Specifies the target device (e.g., 'cpu', 'cuda:0')\n* `dtype`:  Specifies the desired data type for the tensors\n\n[Output]\n* Modified tensors on the specified device and data type.\n\n\n\n\n\n"
    },
    "ChatTTS__config__config__DVAE": {
        "label": "DVAE",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 31,
        "endLineNo": 48,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L31-L48&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary:\n\nThis code instantiates three components for a likely autoencoder model: an encoder, a decoder, and a vector quantizer (VQ). The encoder compresses input data into a lower-dimensional representation, the VQ quantizes the compressed data into a discrete set of vectors, and the decoder reconstructs the original data from the quantized vectors. \n\n## Inputs:\n\n* `idim`: Input dimension, likely the size of the input data vectors.\n* `odim`: Output dimension, likely the size of the output data vectors.\n* `hidden`: Dimension of the hidden layers within the encoder and decoder.\n* `n_layer`: Number of layers in the encoder and decoder.\n* `bn_dim`: Dimension used in batch normalization layers.\n\n## Output:\n\n* `encoder`: An initialized Encoder object.\n* `decoder`: An initialized Decoder object.\n* `vq`: An initialized VQ object.   \n\n\nLet me know if you'd like more details on any specific component!\n"
    },
    "ChatTTS__core__Chat____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 32,
        "endLineNo": 48,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L32-L48&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick summary:** This Python code initializes an object by setting up logging, loading configuration, and preparing resources for text processing. It likely belongs to a larger system that deals with analyzing or generating text, possibly involving code analysis or plagiarism detection.\n\n**Inputs:**\n\n* `logger`: A logging object used for recording information and errors during execution.\n* `Config()`: An instantiation of a configuration class, likely containing parameters for the system.\n* `os.path.join(os.path.dirname(__file__), \"res\", \"homophones_map.json\")`: Path to a JSON file containing mappings of homophones.\n* `os.path.join(os.path.dirname(__file__), \"res\", \"sha256_map.json\")`: Path to a JSON file containing SHA256 hash mappings.\n\n**Output:**\n\n\n*  An initialized object with the following attributes:\n    * `logger`: The provided logging object.\n    * `config`: An instance of the `Config` class.\n    * `normalizer`: An instance of the `Normalizer` class, likely used for text preprocessing.  \n    * `sha256_map`: A dictionary loaded from the SHA256 hash file. \n\n\n\n\n"
    },
    "stream__ChatStreamer___update_stream": {
        "label": "_update_stream",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 16,
        "endLineNo": 32,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L16-L32&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown of the code snippet:\n\n**Quick summary**\n\nThis function manages a streaming audio processing workflow, potentially used for real-time analysis or generation. It combines incoming audio data (`new_stream_wav`) with a history of previously processed audio (`history_stream_wav`) while enforcing a size limit (`thre`). It returns the updated audio stream and a flag indicating if the stream should be kept for further processing.\n\n **Inputs**\n\n*  `history_stream_wav`: A NumPy array containing previously processed audio data.\n* `new_stream_wav`: A NumPy array containing new incoming audio data.\n* `thre`: A threshold value (likely the maximum allowed size of the audio stream).\n* `random`:  A random number generator object (likely used for debugging or evaluation purposes).\n\n**Output**\n\n* `result_stream`: A NumPy array containing the combined audio data (updated history plus new data).\n* `is_keep_next`: A boolean value indicating whether the processed `result_stream` should be kept for further processing. \n\n\nLet me know if you have any further questions about this code!\n"
    },
    "ChatTTS__model__dvae__GFSQ____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 70,
        "endLineNo": 85,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L70-L85&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## GFSQ Function Analysis\n\n**Quick Summary:**\n\nThis function initializes a class called `GFSQ`, which likely implements a type of quantized neural network layer using Grouped Residual Finite Sum Quantization (GRFSQ).  It sets up the parameters for quantization, including the number of groups and residual sets, and prepares for calculations involving matrix transposes. \n\n**Inputs:**\n\n* `dim`:  The dimensionality of the input data.\n* `levels`: A list of integers defining the number of quantization levels for each dimension.\n* `G`: The number of groups used in the quantization process.\n* `R`:  The number of residual sets used within each group.\n* `eps`: A small floating-point value used for numerical stability (likely in calculations involving finding the quantization thresholds).\n* `transpose`: A boolean flag indicating whether to transpose matrices during operations.\n\n**Output:**\n\n*  An instance of the `GFSQ` class, likely ready to process input data and perform quantization operations. \n\n\n"
    },
    "tools__logger__log__get_logger": {
        "label": "get_logger",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/logger/log.py",
        "relativePath": "tools/logger/log.py",
        "lineNo": 58,
        "endLineNo": 73,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Flogger%2Flog.py%23L58-L73&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**Quick Summary:**\n\nThis function configures a Python logger instance. It sets the logging level, clears existing handlers if specified, and adds a default `StreamHandler` if none exist. It also ensures that all handlers (for both the specific logger and the root logger) utilize the `Formatter` specified.\n\n**Inputs:**\n\n* `name`:  The name of the logger instance to configure.\n* `lv`: The desired logging level (e.g., DEBUG, INFO, WARNING, ERROR, CRITICAL).\n* `remove_exist`: A boolean flag indicating whether to remove existing handlers from the logger.\n* `format_root`: A boolean flag indicating whether to format handlers for the root logger.\n\n**Outputs:**\n\n* A configured `logging.Logger` instance.  \n\n\n"
    },
    "ChatTTS__model__cuda__patch__LlamaRMSNorm": {
        "label": "LlamaRMSNorm",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/patch.py",
        "relativePath": "ChatTTS/model/cuda/patch.py",
        "lineNo": 4,
        "endLineNo": 18,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fpatch.py%23L4-L18&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  LlamaRMSNorm  Analysis\n\n**[Quick Summary]** \nThis code defines a `LlamaRMSNorm` class, which implements a Layer Normalization technique similar to T5LayerNorm.  It normalizes hidden states within a neural network layer by scaling them based on the root mean square (RMS) of their values, providing improved stability and performance during training.\n\n**[Inputs]**\n  * `hidden_states`: A PyTorch tensor containing the activations from the previous layer in a neural network.\n\n**[Output]**\n  * A tensor of normalized hidden states, scaled by a learnable weight (`self.weight`). \n\n\n"
    },
    "ChatTTS__model__cuda__te_llama__TELlamaDecoderLayer__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 81,
        "endLineNo": 95,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L81-L95&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**Quick Summary:** \nThis custom `forward` function modifies the behaviour of a TransformerLayer to suit a specific decoder architecture (likely an implementation similar to HuggingFace's `LlamaDecoderLayer`). It passes modified positional embeddings and filters the arguments to the TransformerLayer's forward pass. The purpose is to ensure consistent output formatting and potentially utilize custom positional embeddings.\n\n**Inputs:**\n\n*  `hidden_states`: TransformerEncoderOutput, likely representing the hidden states of the input sequence\n* `attention_mask`: Binary mask indicating padding or non-padding tokens\n* `rotary_pos_emb`: Custom positional embedding representation (likely Time-Embedding Rotational Positional Embeddings - TE-ROPE)\n\n**Output:**\n\n* A modified `TransformerEncoderOutput` object containing the processed hidden states. \n\n\n"
    },
    "ChatTTS__model__tokenizer__Tokenizer____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/tokenizer.py",
        "relativePath": "ChatTTS/model/tokenizer.py",
        "lineNo": 21,
        "endLineNo": 35,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Ftokenizer.py%23L21-L35&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown\n\n**[Quick Summary]**\nThis function initializes a class for handling BERT tokenization and special tokens related to speaker embeddings and break detection. It loads a pre-trained BERT tokenizer from a file, identifies specific token IDs for speaker embeddings, breaks, and end-of-sequence markers, and defines a decoding function for reconstructing text from token IDs. The purpose is to streamline the processing of text data involving speaker embeddings and turn boundaries in a BERT-based system.\n\n**[Inputs]**\n* `tokenizer_path`: A file path or other object providing access to a saved BERT tokenizer.\n* `device`: A PyTorch device object (e.g., \"cuda:0\" or \"cpu\") indicating where the tokenizer will be loaded.\n\n\n**[Output]**\n*  An instance of the class containing:\n    * The loaded BERT tokenizer (`_tokenizer`).\n    * Length of vocabulary (`len`).\n    * Token IDs for speaker embedding, break, and end-of-sequence tokens.\n    *  A `decode` function for reconstructing text from token IDs. \n"
    },
    "ChatTTS__model__tokenizer__Tokenizer___encode_prompt": {
        "label": "_encode_prompt",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/tokenizer.py",
        "relativePath": "ChatTTS/model/tokenizer.py",
        "lineNo": 187,
        "endLineNo": 201,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Ftokenizer.py%23L187-L201&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary**\n\nThis function compresses a 2D NumPy array representing a prompt into a byte string.  It first checks if the input is a 2D tensor, then encodes the shape of the array and compresses its contents using LZMA.  The resulting compressed string is suitable for efficient storage or transmission.\n\n**Inputs**\n\n*  `prompt`:  A 2D NumPy array containing the data for the prompt.\n\n**Output**\n\n*  `s`: A byte string containing the compressed representation of the prompt. \n\n\n"
    },
    "ChatTTS__norm___fast_replace": {
        "label": "_fast_replace",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 22,
        "endLineNo": 36,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L22-L36&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:** This function decodes a binary-encoded text string using a provided lookup table.  It replaces characters based on the mapping defined by the table and returns both the decoded array and a list of replaced character pairs. The purpose is likely text encoding/decoding or a form of custom character substitution.\n\n**Inputs:**\n\n* `table`: This is a NumPy array with two rows.\n* `text`: This is a bytes object containing the binary-encoded text  \n\n**Output:**\n\n* A NumPy array containing the decoded text.\n* A list where each element is a tuple of two strings, representing the original and replaced characters. \n\n\n\n\n"
    },
    "ChatTTS__norm__Normalizer__register": {
        "label": "register",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 159,
        "endLineNo": 173,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L159-L173&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis function registers a new text normalizer with the class. It checks if a normalizer with the same name already exists, validates the normalizer's functionality, and stores it if it passes the checks.  The purpose is to manage and ensure the quality of registered text normalization functions.\n\n[Inputs]\n* `name`:  A string representing the unique identifier for the normalizer.\n* `normalizer`: A function that takes a string as input and returns a normalized string.\n\n[Output]\n* `True`: If the normalizer was successfully registered.\n* `False`: If the registration failed (e.g., a normalizer with the same name already exists, or the function didn't return a string or encountered an exception). \n"
    },
    "main__ChatTTSParams": {
        "label": "ChatTTSParams",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/api/main.py",
        "relativePath": "examples/api/main.py",
        "lineNo": 46,
        "endLineNo": 60,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fapi%2Fmain.py%23L46-L60&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "You've provided a snippet of code defining parameters for a function, likely related to text-to-speech synthesis or a conversational AI system. \n\n**[Quick Summary]**\n\nThis function appears to handle text processing and potential refinement before generating speech. It takes text input and  a variety of parameters to control text normalization, homophone replacement, refinement processes, and speech synthesis. The purpose is likely to produce high-quality, natural-sounding speech from input text.\n\n**[Inputs]**\n*  `text`: The input text to be processed.\n* `stream`: A boolean indicating whether to process text in a streaming fashion.\n* `lang`: The language of the input text.\n* `skip_refine_text`: A boolean to skip text refinement steps.\n* `refine_text_only`: A boolean to indicate if only text refinement is needed.\n* `use_decoder`: A boolean to control the use of a decoder for speech synthesis.\n* `do_text_normalization`: A boolean to enable text normalization.\n* `do_homophone_replacement`: A boolean to enable homophone replacement.\n* `audio_seed`: A seed value for audio generation.\n* `text_seed`: A seed value for text processing.\n* `params_refine_text`: Parameters for text refinement. \n* `params_infer_code`: Parameters for code inference (potentially related to speech synthesis).\n\n **[Output]**\n\n* Likely a processed version of the input text.\n* Possibly generated speech audio.\n\n\n\n\n"
    },
    "tools__logger__log__Formatter__format": {
        "label": "format",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/logger/log.py",
        "relativePath": "tools/logger/log.py",
        "lineNo": 43,
        "endLineNo": 57,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Flogger%2Flog.py%23L43-L57&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Log Formatting Function Analysis\n\n**[Quick summary]**\n\nThis function formats a log message according to a specified style, incorporating timestamp, log level, filename, function name, and the actual log message. It also includes optional color coding using ANSI escape sequences.\n\n**[Inputs]**\n\n* **`record`:** A logging record object containing information about the log event (level, filename, function name, message, etc.).\n* **`self`:**  Likely a reference to an instance of a custom logging handler class.\n* **`self.tz`:**  A timezone object used for formatting the timestamp.\n* **`self.color`:** A boolean flag determining whether to apply color coding.\n* **`log_level_color_code`:** A dictionary mapping log levels to color codes (likely ANSI escape sequences).\n* **`log_level_msg_str`:** A dictionary mapping log levels to their corresponding short names or abbreviations. \n* **`colorReset`:**  An ANSI escape sequence to reset color formatting.\n\n**[Output]**\n\n* A formatted string representing the log message, including:\n    - Timestamp  in the format defined by `self.tz`.\n    - Log level name or abbreviation.\n    -  Color coding based on `self.color` and `log_level_color_code`.\n    - Function name from the log record.\n\n\nLet me know if you'd like a deeper dive into any specific part of the code!\n"
    },
    "ChatTTS__config__config__GPT": {
        "label": "GPT",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 50,
        "endLineNo": 63,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L50-L63&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary:**\n\nThis code defines hyperparameters for a transformer-based model likely designed for speech recognition or text-to-speech synthesis. It specifies the model's architecture, including the size of hidden layers, attention heads, and the number of layers, as well as parameters related to speaker embedding and audio tokenization.\n\n**Inputs:**\n\n*  **No explicit inputs are defined.** The code establishes the configuration for the transformer model.\n\n**Output:**\n\n* **A configured transformer model is implicitly created.**\n   The parameters set here will be used to build and train the model.\n\n\n\n\nLet me know if you'd like me to elaborate on any specific aspect!\n"
    },
    "ChatTTS__model__tokenizer__Tokenizer___decode_prompt": {
        "label": "_decode_prompt",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/tokenizer.py",
        "relativePath": "ChatTTS/model/tokenizer.py",
        "lineNo": 171,
        "endLineNo": 184,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Ftokenizer.py%23L171-L184&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown\n\n**Quick Summary:**\n\nThis function decodes a compressed array representation, likely from a compressed image format or a similar data structure. It first decodes a base64-encoded byte string, then decompresses LZMA-encoded data to retrieve a 2-dimensional NumPy array. Finally, it converts this array to a PyTorch tensor and returns it. The purpose seems to be loading and processing compressed data efficiently.\n\n**Inputs:**\n\n*  `prompt`: A base64-encoded string containing compressed data.\n\n**Output:**\n\n* A PyTorch tensor representing the decoded 2D array. \n\n\n"
    },
    "ChatTTS__utils__dl__download_and_extract_tar_gz": {
        "label": "download_and_extract_tar_gz",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/dl.py",
        "relativePath": "ChatTTS/utils/dl.py",
        "lineNo": 68,
        "endLineNo": 81,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fdl.py%23L68-L81&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function downloads a tar.gz compressed file from a given URL, extracts its contents, and saves them to a specified folder. It automates the process of acquiring and unpacking data from a remote source.\n\n## Inputs\n\n*  `url`: The URL of the tar.gz file to be downloaded.\n*  `folder`: The local directory where the extracted files should be saved.\n\n## Output\n\n*  The extracted contents of the downloaded tar.gz file are stored within the specified `folder`.\n\n\n\n"
    },
    "ChatTTS__utils__dl__download_and_extract_zip": {
        "label": "download_and_extract_zip",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/dl.py",
        "relativePath": "ChatTTS/utils/dl.py",
        "lineNo": 82,
        "endLineNo": 95,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fdl.py%23L82-L95&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick summary:** This function downloads a zip file from a provided URL, extracts its contents to a specified folder, and logs the progress. It likely aims to automate the process of downloading and unpacking data packages.\n\n**Inputs:**\n\n*  `url`: The web address of the zip file to download.\n*  `folder`:  The local directory where the extracted contents will be saved.\n\n**Output:**\n\n*  The extracted files from the zip archive will be present in the designated `folder`.\n*  Log messages will be printed indicating the download and extraction progress.  \n\n\nLet me know if you'd like a more in-depth explanation of any specific part of the code.\n"
    },
    "ChatTTS__utils__io__get_latest_modified_file": {
        "label": "get_latest_modified_file",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/io.py",
        "relativePath": "ChatTTS/utils/io.py",
        "lineNo": 9,
        "endLineNo": 21,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fio.py%23L9-L21&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Python Code Analysis\n\n**Quick Summary:** This function locates the latest file in a given directory. It first checks if any files exist within the directory before searching for the file with the most recent modification timestamp.\n\n**Inputs:**\n\n* `directory`:  A string representing the path to the directory to search.\n\n**Output:**\n\n*  A string representing the path to the latest file found in the directory, or `None` if no files are present. \n\n\n\n"
    },
    "ChatTTS__core__Chat__InferCodeParams": {
        "label": "InferCodeParams",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 191,
        "endLineNo": 202,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L191-L202&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**  This function likely configures and initiates text generation using a language model. It sets parameters like speed, speaker embeddings, temperature, and batch size to control the generation process. The purpose is to generate text  likely aligned with a specified speaker style or context. \n\n**Inputs:**\n\n* **prompt:** The initial text input prompting the language model.\n* **spk_emb:** Embeddings representing the speaker's voice or style.\n* **spk_smp:**  Possibly a sampling method or parameter related to speaker representation.\n* **txt_smp:** Sampling method or parameter related to text generation.\n* **temperature:** A value influencing the randomness of the generated text.\n* **repetition_penalty:**  A parameter discouraging repetitive text generation.\n* **max_new_token:**  Maximum number of new tokens (words) to generate.\n* **stream_batch:**  Batch size for streaming text generation.\n* **stream_speed:**  Speed at which text is generated.\n* **pass_first_n_batches:** Number of initial batches to ignore.\n\n**Output:**\n\n* Likely a stream of generated text based on the provided inputs and parameters. \n\n\n\nLet me know if you'd like a deeper dive into any specific aspect!\n"
    },
    "ChatTTS__model__dvae__DVAEDecoder__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 162,
        "endLineNo": 173,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L162-L173&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis function defines a neural network decoder, likely part of a larger generative model. It takes an encoded representation (`x`) and some conditioning information (`conditioning`), processes them through a series of decoder blocks (`decoder_block`), and finally outputs a decoded representation (`x_out`). The purpose is to generate new data samples by reconstructing them from their encoded form, potentially guided by the conditioning input. \n\n[Inputs]\n*  `x`: Input encoded representation\n*  `conditioning`: Additional information used to guide the decoding process.\n\n[Output]\n*  `x_out`: Decoded representation, potentially a reconstructed image or text. \n"
    },
    "ChatTTS__model__dvae__GFSQ___embed": {
        "label": "_embed",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 86,
        "endLineNo": 97,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L86-L97&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis Summary\n\nThis function processes an input tensor (`x`) to quantize its values using a provided `quantizer` object. It reshapes, permutes, and potentially transposes the tensor before feeding it to the quantizer. The ultimate purpose is to reduce the precision of the input data, likely for efficiency or memory savings in subsequent processing stages.\n\n\n## Inputs\n\n* **x:** A tensor likely representing feature maps or data needing quantization.\n* **self.transpose:** A boolean flag, likely controlling whether the tensor is transposed before quantization.\n* **self.G:** An integer representing the number of groups in the tensor along a specific dimension.\n* **self.R:** An integer representing the number of channels or elements per group.\n* **self.quantizer:** An object responsible for performing the quantization process on the input tensor.\n\n\n## Output\n\n* **feat:** A tensor representing the quantized version of the input `x`.  \n"
    },
    "main__startup_event": {
        "label": "startup_event",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/api/main.py",
        "relativePath": "examples/api/main.py",
        "lineNo": 34,
        "endLineNo": 45,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fapi%2Fmain.py%23L34-L45&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary**\n\nThis code snippet initializes a ChatTTS object, which likely represents a conversational AI system. It attempts to load pre-trained models, logging success or failure. The purpose is to set up the ChatTTS system for text-to-speech or potentially text-based conversation.\n\n**Inputs**\n\n*  `get_logger(\"ChatTTS\")`: This likely returns a logger object configured to record messages specifically related to \"ChatTTS\".\n*  `sys.exit(1)`:  This is a system call used to terminate the program with an exit code of 1, indicating an error.\n\n**Output**\n\n*  Logs messages indicating initialization status and model loading success or failure.\n*  Either continues execution if models load successfully or exits the program with an error code if loading fails. \n\n\n"
    },
    "tools__audio__pcm__pcm_arr_to_mp3_view": {
        "label": "pcm_arr_to_mp3_view",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/audio/pcm.py",
        "relativePath": "tools/audio/pcm.py",
        "lineNo": 10,
        "endLineNo": 21,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Faudio%2Fpcm.py%23L10-L21&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick summary]** This Python function takes a waveform audio data (`wav`) as input, converts it to a WAV file in memory, then compresses that WAV file into an MP3 format, and returns the MP3 data as a byte string.  The purpose is to efficiently encode audio data  for storage or transmission.\n\n**[Inputs]**\n* `wav`:  A numerical array representing the audio waveform data.\n\n**[Output]**\n*  A byte string containing the compressed MP3 audio data. \n\n\n\n"
    },
    "tools__llm__llm__ChatOpenAI__call": {
        "label": "call",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/llm/llm.py",
        "relativePath": "tools/llm/llm.py",
        "lineNo": 63,
        "endLineNo": 74,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fllm%2Fllm.py%23L63-L74&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]**\n\nThis function sends a user question to an OpenAI language model for completion. It constructs a prompt using existing `prompt_dict` data and the `user_question`, adjusts the `temperature` parameter for creative output, and returns the generated response from the model. The purpose is to interact with an OpenAI model to generate text based on a given prompt and user input.\n\n**[Inputs]**\n\n*  `self.client`: An OpenAI API client object.\n*  `self.model`: The name of the specific OpenAI language model to use.\n*  `prompt_dict`: A dictionary containing different versions of the prompt.\n*  `prompt_version`:  An integer or string representing which version of the prompt to use.\n*  `user_question`: The question the user wants answered.\n*  `temperature`: A float value controlling the randomness of the model's output.\n*  `kwargs`:  Additional keyword arguments to be passed to the OpenAI API call.\n\n**[Output]**\n\n* The generated text response from the OpenAI language model.  \n\n\n"
    },
    "web__funcs__set_buttons_before_generate": {
        "label": "set_buttons_before_generate",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 205,
        "endLineNo": 216,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L205-L216&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]**\n\nThis function manages the visual state of \"generate\" and \"interrupt\" buttons likely within a web interface. It sets global flags to indicate whether the generation process is in progress (`is_in_generate`) and if it has been interrupted (`has_interrupted`).  It then returns a modified version of these buttons based on these flags.\n\n**[Inputs]**\n\n* `generate_button`: An element representing the generate button.\n* `interrupt_button`: An element representing the interrupt button.\n\n\n\n**[Output]**\n\n* A modified version of `generate_button` and `interrupt_button` likely reflecting the current state (enabled/disabled) based on `is_in_generate` and `has_interrupted`. \n"
    },
    "ChatTTS__core__Chat__RefineTextParams": {
        "label": "RefineTextParams",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 179,
        "endLineNo": 189,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L179-L189&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown:\n\n**Quick Summary:** This code snippet likely defines parameters for a text generation function, possibly using a language model. It controls aspects like the input text, the probability distribution used for token selection, temperature for randomness, repetition avoidance, and length constraints. \n\n**Inputs:**\n\n* `prompt`: The initial text input for the model to generate text from.\n* `top_P`: Nucleus sampling parameter, controlling the proportion of likely tokens to consider.\n* `top_K`:  K-best sampling parameter, limiting the selection to the top K most probable tokens.\n* `temperature`:  A scaling factor that controls the randomness of the generated text.\n* `repetition_penalty`:  A penalty applied to repeated tokens, discouraging repetition.\n* `max_new_token`:  Maximum number of new tokens to generate.\n* `min_new_token`:  Minimum number of new tokens to generate.\n* `show_tqdm`:  Indicates whether to display a progress bar during generation.\n\n\n**Output:**\n\n*  Generated text based on the provided prompt and parameters. \n"
    },
    "ChatTTS__core__Chat__unload": {
        "label": "unload",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 148,
        "endLineNo": 158,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L148-L158&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary\n\nThis function appears to be a destructor or cleanup method for an object. It releases resources, deletes instance variables,  and effectively resets the object to its initial state. \n\n## Inputs\n\n* `self`: A reference to the current instance of the class.\n* `logger`: An instance of a logging object, likely used for tracking events during object lifecycle.\n\n## Output\n\n* \nThe function does not explicitly return a value. \n* It modifies the object's state by:\n    * Destroying and deleting the `normalizer` attribute.\n    * Deleting the `sha256_map` attribute.\n    * Removing attributes named \"vocos\", \"gpt\", \"decoder\", \"dvae\", and \"tokenizer\" from the object.   \n    * Reinitializing the object with the `logger` argument. \n\n\n\n"
    },
    "ChatTTS__model__tokenizer__Tokenizer___encode_spk_emb": {
        "label": "_encode_spk_emb",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/tokenizer.py",
        "relativePath": "ChatTTS/model/tokenizer.py",
        "lineNo": 204,
        "endLineNo": 214,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Ftokenizer.py%23L204-L214&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary:** This function takes a NumPy array containing speaker embeddings, compresses it using lzma with the LZMA2 algorithm, and then encodes the compressed data into a string.  The purpose is to efficiently store and transmit the speaker embeddings.\n\n**Inputs:**\n\n*  `spk_emb`:  A NumPy array representing speaker embeddings.\n\n**Output:** \n*  `s`: A compressed string representation of the speaker embeddings. \n\n\n"
    },
    "ChatTTS__utils__log__Logger": {
        "label": "Logger",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/log.py",
        "relativePath": "ChatTTS/utils/log.py",
        "lineNo": 5,
        "endLineNo": 15,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Flog.py%23L5-L15&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**Quick Summary** This Python code defines a basic logger setup. It allows you to initialize a logger instance, optionally set a different logger later, and retrieve the currently active logger. This is commonly used for logging information, warnings, and errors within a program. \n\n**Inputs**\n\n*  `logger`: A  `logging.Logger` object. This is used during object initialization to set up the primary logger.\n\n\n**Output**\n\n*  A `logging.Logger` object   that can be used for logging purposes \n"
    },
    "tools__seeder__ctx__TorchSeedContext": {
        "label": "TorchSeedContext",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/seeder/ctx.py",
        "relativePath": "tools/seeder/ctx.py",
        "lineNo": 4,
        "endLineNo": 14,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fseeder%2Fctx.py%23L4-L14&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis code defines a context manager for managing the random seed in PyTorch. It initializes the random number generator with a given seed when entering the context and restores the original state when exiting, ensuring reproducibility of random number generation within the context.\n\n[Inputs]\n- `seed`: An integer representing the desired random seed.\n\n[Output]\n- No explicit output. The context manager manages the random seed state. \n\n\n"
    },
    "ChatTTS__model__gpt__GPT__Context": {
        "label": "Context",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 109,
        "endLineNo": 118,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L109-L118&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis code defines a simple class that acts as a flag for interrupting a process. The `interrupt` variable can be set to `True` to signal an interruption, and to `False` to clear it. \n\n## Inputs\n\n*  `v: bool`: Boolean value, `True` to set the interrupt flag, `False` to clear it.\n\n## Output\n\n* `bool`: The current state of the `interrupt` flag (True or False).  \n"
    },
    "ChatTTS__model__gpt__GPT__GenerationOutputs": {
        "label": "GenerationOutputs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 318,
        "endLineNo": 327,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L318-L327&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function, `destroy`, is designed to deallocate memory associated with a dataclass-like object storing information about  `ids`,  `attentions`, and `hiddens`. It likely represents a step in model training cleanup or resource management.\n\n## Inputs\n\n* **self:** A reference to the instance of the class containing the data.\n\n## Output\n\n* None: This function appears to modify the state of the object in-place by deleting its internal data, rather than returning a value.\n"
    },
    "ChatTTS__model__gpt__GPT__prepare": {
        "label": "prepare",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 141,
        "endLineNo": 150,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L141-L150&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code snippet aims to optimize a language model (likely a variant of GPT) for inference by utilizing Flash Attention and possibly Inductor compilation. If hardware and software support allows, it converts the model to mixed precision (float16) and tries to compile it for faster execution using Inductor. If compilation fails, it falls back to the default execution mode.\n\n## Inputs\n\n*  `self.use_flash_attn`: A boolean flag indicating whether to use Flash Attention.\n* `is_flash_attn_2_available()`: A function call likely checking for the availability of Flash Attention 2.\n* `compile`: A boolean flag indicating whether to attempt compilation.\n* `self.is_te_llama`: A boolean flag possibly related to whether the model is a specific variant of Llama.\n\n## Outputs\n\n* The code modifies the internal `self.gpt` object, potentially converting its data type and/or compiling it for improved performance.\n* It prints a warning message to the logger if compilation with Inductor fails. \n\n\n"
    },
    "ChatTTS__model__gpt__GPT___GenerationInputs__to": {
        "label": "to",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 198,
        "endLineNo": 207,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L198-L207&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis code snippet appears to be a method within a Transformer model or a similar architecture. It's responsible for moving the model's input tensors to a specified device (likely a GPU) and data type (dtype). This is a common step in deep learning to optimize performance and utilize hardware acceleration.\n\n\n\n## Inputs\n\n*  `self.attention_mask`: This likely represents a mask indicating which tokens in the input sequence should be attended to. \n*  `self.position_ids`: This tensor likely encodes the position information of each token in the input sequence.\n* `self.inputs_embeds`: This could be a pre-computed embedding representation for the input tokens.\n* `self.cache_position`: This likely stores previously computed information for efficient processing of sequential data.\n*  `device`: This indicates the target device (e.g., 'cuda' for GPU or 'cpu' for CPU)\n\n* `dtype`: This specifies the data type of the tensors (e.g., 'float32' or 'float16').\n\n\n\n## Output\n\n* Modified internal tensors of the model: \n    * `self.attention_mask`\n    * `self.position_ids`\n    * `self.inputs_embeds`\n    * `self.cache_position`\n  all moved to the specified `device` and with the specified `dtype`.\n"
    },
    "ChatTTS__model__processors__CustomRepetitionPenaltyLogitsProcessorRepeat____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/processors.py",
        "relativePath": "ChatTTS/model/processors.py",
        "lineNo": 8,
        "endLineNo": 17,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fprocessors.py%23L8-L17&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This function initializes an object (likely related to a language model) with parameters for penalty, maximum input sequence length, and past context window size. It enforces that the penalty is a strictly positive float, raising a ValueError if not. \n\n**Inputs:**\n\n* `penalty`: A float value representing a penalty parameter for the model.\n* `max_input_ids`: An integer specifying the maximum number of input tokens allowed. \n* `past_window`: An integer defining the size of the context window used by the model.\n\n**Output:**\n\n* Initializes the object's attributes: `penalty`, `max_input_ids`, and `past_window`. \n\n\n"
    },
    "ChatTTS__model__tokenizer__Tokenizer___decode_spk_emb": {
        "label": "_decode_spk_emb",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/tokenizer.py",
        "relativePath": "ChatTTS/model/tokenizer.py",
        "lineNo": 132,
        "endLineNo": 141,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Ftokenizer.py%23L132-L141&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function decompresses a speaker embedding encoded with Base14 and the lzma library, converting it into a NumPy array of float16 values for use in a machine learning model or similar application. Its purpose is to load and prepare speaker embeddings from a compressed and encoded format. \n\n## Inputs\n\n* `spk_emb`:  A string likely representing the Base14 encoded compressed speaker embedding data.\n* `b14`:  A hypothetical object responsible for Base14 decoding.\n\n## Output\n\n*  A NumPy array containing the speaker embedding as float16 values. \n\n\n"
    },
    "web__funcs__set_buttons_after_generate": {
        "label": "set_buttons_after_generate",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 217,
        "endLineNo": 226,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L217-L226&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]**\n\nThis function manages the state of generate and interrupt buttons based on whether an audio output is present or if the generation process has been interrupted. It likely updates the visibility or functionality of these buttons within a user interface, likely for a text-to-speech or similar application.\n\n**[Inputs]**\n\n* `generate_button`: A button object associated with initiating the text generation process.\n* `interrupt_button`: A button object for interrupting the ongoing generation process.\n* `audio_output`: A variable indicating whether an audio output is currently being generated or not.\n* `has_interrupted`: A global variable tracking if the generation process has been interrupted.\n\n**[Output]**\n\n*  Returns a modified HTML/UI representation of the buttons.  This likely controls their visibility, state, or potential disabling based on the input conditions. \n\n\n\n"
    },
    "ChatTTS__core__Chat___sample_random_speaker": {
        "label": "_sample_random_speaker",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 169,
        "endLineNo": 177,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L169-L177&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\n\nThis function generates a sample from a specified latent space distribution.  It utilizes a pre-trained GPT model's parameters to define the mean and standard deviation of the distribution.  The function then utilizes these parameters to generate a sample from this latent space.\n\n[Inputs]\n\n* self.gpt: Likely a pre-trained GPT model.\n* self.std: Object defining the standard deviation of the latent distribution.\n* self.mean: Object defining the mean of the latent distribution.\n\n[Output]\n\n* spk: A tensor representing a generated sample from the latent distribution.   \n"
    },
    "ChatTTS__norm__Normalizer___load_homophones_map": {
        "label": "_load_homophones_map",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 182,
        "endLineNo": 190,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L182-L190&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function loads a dictionary of homophones from a JSON file and converts it into a NumPy array. The array represents each homophone pair as a 2-element vector where each element is the Unicode codepoint of a character in the pair. This likely facilitates efficient lookup and comparison of homophones for natural language processing tasks.\n\n## Inputs\n\n* `map_file_path`:  A string representing the path to a JSON file containing a dictionary of homophone pairs.\n\n## Output\n\n* `map`: A 2xN NumPy array where N is the number of homophone pairs in the dictionary. \n    * Each row represents a homophone pair.\n    * Each column represents a character in the pair encoded as its Unicode codepoint. \n\n\n"
    },
    "web__funcs__on_upload_sample_audio": {
        "label": "on_upload_sample_audio",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 117,
        "endLineNo": 125,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L117-L125&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown \n\n**[Quick summary]** This function takes an audio sample as input, identifies the speaking person using a pre-trained model (`chat.sample_audio_speaker`), and returns the speaker's name. Its purpose is to automate the process of determining the speaker from an audio clip. \n\n**[Inputs]**\n\n*  `sample_audio_input`: The audio sample to be processed. This could be a file path or a raw audio data representation.\n*  `24000`:  Likely the expected sample rate for the audio input (samples per second).\n\n**[Output]**\n\n*  A string representing the name of the speaker identified in the audio sample.\n*  An empty string if `sample_audio_input` is `None`. \n\n\n\n"
    },
    "ChatTTS__config__config__Decoder": {
        "label": "Decoder",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 14,
        "endLineNo": 21,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L14-L21&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown: \n\n**Quick summary:** This code snippet appears to define hyperparameters for a deep learning model, likely a Transformer or a similar architecture. It specifies the dimensions of input and output vectors, the number of hidden layers, and a dimension for batch normalization. \n\n**Inputs:**\n\n*  `idim`:  Dimensionality of the input data.\n* `odim`: Dimensionality of the output data. \n* `hidden`: Number of neurons in each hidden layer. \n* `n_layer`: Number of hidden layers in the model.\n* `bn_dim`: Dimensionality used for batch normalization.\n\n**Output:**\n\n*  There is no explicit output defined in this code snippet.\n\n\n\n\n"
    },
    "ChatTTS__config__config__FeatureExtractor": {
        "label": "FeatureExtractor",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 65,
        "endLineNo": 72,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L65-L72&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary] \nThis code snippet appears to define parameters for audio feature extraction, specifically Mel-spectrograms. It sets up constants for sample rate, FFT size, hop length, the number of Mel frequency bins, and padding method used for audio manipulation. \n\n[Inputs]\n* **sample_rate:**  The number of audio samples per second.\n* **n_fft:** The length of the FFT window used for each spectrogram segment.\n* **hop_length:**  The number of samples to move the FFT window in each step.\n* **n_mels:**  The number of Mel frequency bands to use.\n* **padding:** Specifies how to handle padding of the audio signal (e.g., \"center\").\n\n[Output]\n* Mel-spectrogram representation of the input audio data. \n\n\n\n"
    },
    "ChatTTS__config__config__FeatureExtractorInitArgs": {
        "label": "FeatureExtractorInitArgs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 65,
        "endLineNo": 72,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L65-L72&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Audio Processing Function Breakdown\n\n**Quick Summary:** This code snippet defines parameters likely used for audio processing, specifically feature extraction using a Mel-frequency cepstral coefficient (MFCC) analysis. It prepares the audio signal for processing with short-time Fourier transform (STFT) and Mel-scale filtering to extract acoustical features.\n\n**Inputs:**\n\n* `sample_rate`:  The number of audio samples per second.\n* `n_fft`: The size of the sliding window used for the STFT.\n* `hop_length`: The amount the window slides between each STFT calculation.\n* `n_mels`: The number of Mel-filter banks used.\n* `padding`:  Method for padding the audio signal (likely to ensure consistent windowing).\n\n**Output:**\n\n*  MFCC coefficients representing the audio signal's spectral characteristics.\n\n\n\n"
    },
    "ChatTTS__config__config__Path": {
        "label": "Path",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 5,
        "endLineNo": 12,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L5-L12&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis \n\n**[Quick summary]** This code snippet appears to define variables that store paths to various model checkpoints and a tokenizer. This suggests it's setting up the environment to load and utilize machine learning models for text generation or related tasks.\n\n**[Inputs]**\n\n*  `vocos_ckpt_path`: Path to a checkpoint file for a VoCoS model.\n*  `dvae_ckpt_path`: Path to a checkpoint file for a DVAE (Deep Variational Autoencoder) model.\n*  `gpt_ckpt_path`: Path to a checkpoint file for a GPT (Generative Pre-trained Transformer) model. \n*  `decoder_ckpt_path`: Path to a checkpoint file for a decoder model.\n*  `tokenizer_path`: Path to a tokenizer file.\n\n**[Output]**\n\n* The variables themselves hold strings representing file paths.\n* The purpose is to load these models and tokenizer for further use in a text processing application. \n\n\n\n\n"
    },
    "ChatTTS__model__cuda__patch__LlamaRMSNorm____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/patch.py",
        "relativePath": "ChatTTS/model/cuda/patch.py",
        "lineNo": 5,
        "endLineNo": 12,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fpatch.py%23L5-L12&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## LlamaRMSNorm Code Analysis\n\n**[Quick Summary]**\n\nThis code defines a class called `LlamaRMSNorm`, which implements a layer normalization technique similar to T5LayerNorm. It calculates the root mean square (RMS) of activations within a layer and uses this value to normalize the activations. This helps stabilize training and improve performance in transformer models.\n\n**[Inputs]**\n\n* `hidden_size`: The dimension of the input vector.\n\n* `eps`: A small constant added to the variance for numerical stability.\n\n**[Output]**\n\n*  A `Parameter` named `weight` representing the learnable scaling factor for normalization. \n\n\n"
    },
    "ChatTTS__model__gpt__GPT____call__": {
        "label": "__call__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 151,
        "endLineNo": 158,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L151-L158&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick Summary:** This function, likely part of a Transformer-based language model, takes input token IDs and a corresponding text mask as input. It then utilizes a parent class's `__call__` method to generate embeddings for the input text. This embedding output likely represents a numerical representation of the input text, capturing semantic meaning.\n\n**Inputs:**\n\n* `input_ids`: A PyTorch tensor containing the numerical IDs of the input tokens.\n* `text_mask`: A PyTorch tensor indicating which input tokens are real and which are padding tokens (usually 0s and 1s).\n\n**Output:**\n\n* A PyTorch tensor containing the embeddings for the input tokens.  \n\n\n\n\n"
    },
    "ChatTTS__norm__Normalizer___detect_language": {
        "label": "_detect_language",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 202,
        "endLineNo": 209,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L202-L209&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis of Code Snippet \n\n**Quick Summary:** This function analyzes a given sentence to determine its primary language - either Chinese or English. It does this by counting the occurrences of identified Chinese characters and English words within the sentence.\n\n**Inputs:**\n\n* `sentence`:  A string containing the text to be analyzed.\n* `self.chinese_char_pattern`: A regular expression pattern designed to identify Chinese characters within text.\n* `self.english_word_pattern`: A regular expression pattern designed to identify English words within text.\n\n**Output:**\n\n*  \"zh\": Indicates that the sentence is primarily in Chinese.\n*  \"en\": Indicates that the sentence is primarily in English. \n"
    },
    "ChatTTS__utils__dl__download_dns_yaml": {
        "label": "download_dns_yaml",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/dl.py",
        "relativePath": "ChatTTS/utils/dl.py",
        "lineNo": 96,
        "endLineNo": 103,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fdl.py%23L96-L103&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**Quick Summary:** This function downloads a DNS configuration file (`dns.yaml`) from a given URL and saves it to a specified folder.\n\n**Purpose:**  The code fetches a DNS configuration and localizes it for potential use in a local system or environment.\n\n\n**Inputs:**\n\n*  `url`: The URL of the DNS configuration file to download.\n*  `folder`: The directory path where the downloaded file should be saved.\n\n**Output:**\n\n* A file named `dns.yaml` containing the downloaded DNS configuration is saved within the specified `folder`. \n*  Informational log messages are printed indicating the download progress.   \n\n\n\n"
    },
    "run__save_mp3_file": {
        "label": "save_mp3_file",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/run.py",
        "relativePath": "examples/cmd/run.py",
        "lineNo": 22,
        "endLineNo": 29,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Frun.py%23L22-L29&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]** This code snippet converts a PCM (Pulse-Code Modulation) encoded audio signal represented by the `wav` variable into an MP3 audio file. The MP3 file is then saved to a specified location with a filename that includes a unique index.\n\n**[Inputs]**\n*  `wav`: This is likely a NumPy array containing the raw PCM audio data.\n* `index`: This is a numerical value used to generate a unique filename for each saved MP3 file.\n* `logger`: This appears to be a logging object used for recording information about the process.\n\n**[Output]**\n* A new MP3 file is created in the current working directory with the filename \"output_audio_[index].mp3\".\n* The MP3 file contains the audio data originally present in the `wav` variable. \n* A log message is written indicating the successful saving of the MP3 file. \n\n\n\n"
    },
    "stream__ChatStreamer___accum": {
        "label": "_accum",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 34,
        "endLineNo": 41,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L34-L41&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown of the provided Python code snippet:\n\n**Quick Summary**\n\nThis function accumulates and concatenates audio data (`stream_wav`)  into a single multi-channel array (`accum_wavs`). It's designed to process audio streams sequentially, likely as part of a larger audio processing or analysis task.\n\n**Inputs**\n\n* `accum_wavs`:  A NumPy array (potentially empty) holding the accumulated audio data. It likely represents multiple audio channels stored as columns.\n* `stream_wav`:  A NumPy array representing a new segment of audio data, also likely containing multiple audio channels.\n\n**Output**\n\n* `accum_wavs`: An updated NumPy array containing the combined audio data from all processed stream segments. \n\n\nLet me know if you have any more code snippets you'd like me to analyze!\n"
    },
    "stream__ChatStreamer__batch_stream_formatted": {
        "label": "batch_stream_formatted",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 43,
        "endLineNo": 50,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L43-L50&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown of the provided Python function:\n\n**[Quick Summary]**\n\nThis function converts audio data (`stream_wav`) into a desired output format. It handles two specific formats: \"PCM16_byte\" and \"PCM16,\" converting the data to 16-bit integers. For other formats, it leaves the data unchanged. The purpose is to standardize the audio format for further processing or storage.\n\n**[Inputs]**\n\n*  `stream_wav`: This is likely a sequence or iterable containing audio data in some format.\n*  `output_format`: A string specifying the desired output audio format (e.g., \"PCM16_byte,\" \"PCM16,\" etc.).\n\n**[Output]**\n\n* `format_data`: The audio data converted to the specified `output_format`. This could be an array of 16-bit integers or the original data in its native format. \n\n\nLet me know if you'd like me to elaborate on any specific part!\n"
    },
    "stream__ChatStreamer__formatted": {
        "label": "formatted",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 52,
        "endLineNo": 59,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L52-L59&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function converts audio data (`data`) into a specific byte format based on the `output_format` parameter.  It supports \"PCM16_byte\" format, which stores audio data as signed 16-bit integers.\n\n## Inputs\n\n* `data`: This is the audio data to be converted. It's likely a NumPy array containing audio samples.\n* `output_format`:  A string specifying the desired output format. \n\n## Output\n\n* `format_data`: The audio data converted to the specified byte format as bytes. \n\n\n"
    },
    "tools__normalizer__en__normalizer_en_nemo_text": {
        "label": "normalizer_en_nemo_text",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/normalizer/en.py",
        "relativePath": "tools/normalizer/en.py",
        "lineNo": 5,
        "endLineNo": 12,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fnormalizer%2Fen.py%23L5-L12&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown:\n\n**Quick Summary:** This code snippet defines a function that normalizes English text. It leverages the `Normalizer` class from the `nemo_text_processing` library to handle casing, punctuation, and other text normalization tasks.  \n\n**Inputs:**\n\n* `input_text`: The text string to be normalized.\n\n**Output:**\n\n* A normalized version of the input text string. \n"
    },
    "ChatTTS__config__config__Backbone": {
        "label": "Backbone",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 80,
        "endLineNo": 86,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L80-L86&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the function code snippet you'd like me to analyze.  \n\n"
    },
    "ChatTTS__config__config__BackboneInitArgs": {
        "label": "BackboneInitArgs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 80,
        "endLineNo": 86,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L80-L86&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick summary]** This code snippet defines parameters for a Transformer-based model, likely an encoder or decoder.  It specifies the number of input channels, the dimension of the embedding and hidden states, the dimension of the intermediate layer, and the number of transformer layers. This configuration is common in natural language processing tasks.\n\n**[Inputs]**\n\n* `input_channels`:  The number of features in the input data (e.g., word embeddings).\n* `dim`: The dimension of the embedding vectors and hidden state representations.\n* `intermediate_dim`: The dimension of the feed-forward network within each transformer layer.\n* `num_layers`: The number of transformer encoder or decoder layers stacked.\n\n**[Output]**\n\n* This code snippet does not have an explicit output. It defines parameters for a model that will be constructed and trained later.\n\n\n"
    },
    "ChatTTS__config__config__FourierHead": {
        "label": "FourierHead",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 94,
        "endLineNo": 100,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L94-L100&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis code snippet defines parameters likely used for audio processing, specifically Short-Time Fourier Transform (STFT). It sets up the dimensions for transforming audio into frequency representations. \n\nThe STFT allows analyzing the frequency content of audio signals over short time intervals, essential for tasks like speech recognition and music analysis.\n\n## Inputs\n\n* `dim: int = 512`:  Size of the output feature vector for each time frame.\n* `n_fft: int = 1024`: Size of the FFT window used for transformation.\n* `hop_length: int = 256`: Number of samples to move the window between successive transformations. \n* `padding: str = \"center\"`: Padding strategy used to ensure even input length for STFT.\n\n## Output\n\n*  A transformed representation of the audio signal in the frequency domain. \n* This output is likely a 2D array or matrix where each row represents a time frame and each column represents a frequency bin. \n\n\n"
    },
    "ChatTTS__config__config__FourierHeadInitArgs": {
        "label": "FourierHeadInitArgs",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 94,
        "endLineNo": 100,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L94-L100&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]**\n\nThis code snippet defines parameters likely used for audio processing, specifically for a short-time Fourier transform (STFT). It sets the dimensions for a  spectrogram, which is a visualization of the frequency content of an audio signal over time. \n\n**[Inputs]**\n\n* `dim: int = 512`: Likely the number of frequency bins (or FFT size) used in the spectrogram.\n* `n_fft: int = 1024`: The size of the FFT window used to analyze short segments of the audio signal. \n* `hop_length: int = 256`: The number of samples to move the FFT window forward for each subsequent analysis.\n* `padding: str = \"center\"`: Specifies how to handle padding of the input audio signal to ensure the desired `n_fft` length.\n\n**[Output]**\n\n*  A spectrogram representation of the audio signal.  \n"
    },
    "ChatTTS__config__config__VQ": {
        "label": "VQ",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 23,
        "endLineNo": 29,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L23-L29&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**[Quick Summary]** This code snippet defines parameters for a multi-dimensional structure likely used in image processing or a similar field. It sets up dimensions (`dim`), hierarchical levels (`levels`), and some numerical constants (`G`, `R`) that might represent geometric or color-related factors. The purpose is probably to initialize settings for a data structure or algorithm.\n\n**[Inputs]**\n* `dim`:  Dimensionality of the structure (possibly spatial, as in the number of pixels per dimension).\n* `levels`: Tuple defining the hierarchical structure, possibly representing levels of detail, resolution, or sub-components.\n* `G`:  Numerical constant, potentially related to a geometric factor or parameter.\n* `R`: Numerical constant, possibly related to a color component or parameter. \n\n**[Output]**\n\n*  The code doesn't explicitly produce an output. \n* Instead, it sets up variables  for further use within a larger program. \n\n\n"
    },
    "ChatTTS__model__cuda__te_llama__TELlamaModel____new__": {
        "label": "__new__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/te_llama.py",
        "relativePath": "ChatTTS/model/cuda/te_llama.py",
        "lineNo": 106,
        "endLineNo": 112,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fte_llama.py%23L106-L112&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]**\n\nThis function creates a modified version of the Llama model by substituting the default decoder layer and layer normalization with custom implementations (`TELlamaDecoderLayer` and `LlamaRMSNorm`).  The purpose is likely to experiment with alternative decoder architectures and normalization techniques to potentially improve the model's performance. \n\n**[Inputs]**\n\n*  `config`: This likely refers to a dictionary or object containing hyperparameters and architectural specifications for the Llama model.\n\n**[Output]**\n\n*  `model`: A modified Llama model instance incorporating the custom decoder layer and normalization.  \n\n\n\n\nLet me know if you have any other code snippets you'd like analyzed!"
    },
    "ChatTTS__norm___find_index": {
        "label": "_find_index",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 14,
        "endLineNo": 20,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L14-L20&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis:\n\n**[Quick Summary]**\n\nThis function searches for a specific value (`val`) within a list-like structure (`table`) and returns its index if found. If the value is not present, it returns -1. Essentially, it performs a linear search to locate the target value.\n\n**[Inputs]**\n\n* `table`: The list-like structure (likely an array) being searched.\n* `val`: The value to be searched for within the `table`.\n\n**[Output]**\n\n*  The index of the first occurrence of `val` in `table`, or -1 if `val` is not found.  \n"
    },
    "ChatTTS__utils__dl__sha256": {
        "label": "sha256",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/dl.py",
        "relativePath": "ChatTTS/utils/dl.py",
        "lineNo": 12,
        "endLineNo": 18,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Fdl.py%23L12-L18&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Summary, Inputs, and Output  \n\n**[Summary]** This Python function calculates the SHA256 hash of a file. It utilizes the `mmap` function to efficiently read the entire file into memory, computes the hash using the `hashlib` library, and finally returns the hexadecimal representation of the hash. \n\n**[Inputs]**\n\n-  `fileno`: This likely refers to a file descriptor obtained through an open file call. It represents the open file.\n- `ACCESS_READ`: This is a constant defining read-only access to the file. \n\n**[Output]** \n\n-  A string containing the hexadecimal representation of the SHA256 hash of the file. \n\n\nLet me know if you'd like a more detailed explanation of any part of the code.\n"
    },
    "stream__ChatStreamer__checkvoice": {
        "label": "checkvoice",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 61,
        "endLineNo": 67,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L61-L67&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary**\n\nThis Python function analyzes audio data represented as a NumPy array (`data`). It checks if the maximum absolute value in the data is less than a very small threshold (1e-6). If it is, the function returns `False`, indicating the audio is likely silent; otherwise, it returns `True`, suggesting the presence of audible content.\n\nThis code snippet is likely part of a larger system for audio processing that needs to determine whether an audio segment is active or silent.\n\n\n**Inputs**\n\n* `data`: A NumPy array containing numerical representation of audio waveform.\n\n**Output**\n\n*  `True`: Audio data contains significant content.\n*  `False`: Audio data is likely silent.  \n"
    },
    "tools__llm__llm__ChatOpenAI____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/llm/llm.py",
        "relativePath": "tools/llm/llm.py",
        "lineNo": 56,
        "endLineNo": 62,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fllm%2Fllm.py%23L56-L62&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:** \nThis code snippet initializes an OpenAI client object with a provided API key and base URL. Then, it assigns a specific \"model\" to the client. This suggests the intention is to interact with an OpenAI AI model for tasks like text generation or classification.\n\n**Inputs:**\n\n*  `api_key`: A unique identifier for accessing the OpenAI API.\n*  `base_url`: The URL endpoint for the OpenAI API.\n*  `model`: The name or identifier of the specific OpenAI model to use.\n\n**Output:**\n\n*  `self.client`: An initialized OpenAI client object ready for API calls.\n*  `self.model`: The selected OpenAI model for use. \n\n\n\n"
    },
    "web__funcs__interrupt_generate": {
        "label": "interrupt_generate",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 198,
        "endLineNo": 204,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L198-L204&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**Quick Summary:** \n\nThis code snippet simulates interrupting a running chat interaction.  It sets a global flag `has_interrupted` to `True` and then calls a function `chat.interrupt()` to signal an interruption in the chat process.\n\n**Inputs:**\n\n*  `chat`: An object representing the chat application or interaction.\n*  `has_interrupted`: A global boolean flag, presumably used to track whether an interruption has occurred.\n\n**Output:**\n\n* A signal (likely a message or action) is sent to the `chat` object to interrupt its current state or flow. \n\n\n\n\n"
    },
    "ChatTTS__config__config__Vocos": {
        "label": "Vocos",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/config/config.py",
        "relativePath": "ChatTTS/config/config.py",
        "lineNo": 108,
        "endLineNo": 113,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fconfig%2Fconfig.py%23L108-L113&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This code snippet likely initializes three components for a machine learning model: a `FeatureExtractor` to prepare input data, a `Backbone` for feature extraction, and a `FourierHead` for tasks involving Fourier transforms.  The purpose is to set up a specialized model, possibly for audio or signal processing. \n\n**Inputs:**\n* `FeatureExtractor`: An object responsible for transforming raw input data into a suitable format for the model.\n* `Backbone`: A neural network architecture for extracting features from the processed input.\n* `FourierHead`: A component likely performing operations related to Fourier transforms, possibly for feature analysis or generation.\n\n**Output:** \n*  Initialized objects: `feature_extractor`, `backbone`, and `FourierHead` are ready to be used in a larger model or training pipeline.  \n\n\n\n\n\n"
    },
    "ChatTTS__core__Chat___vocos_decode": {
        "label": "_vocos_decode",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 419,
        "endLineNo": 424,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L419-L424&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function decodes a spectrogram (`spec`) into audio using a Vocoder model (`self.vocos`).  Whether it runs on CPU or GPU depends on the device string in `self.device`.\n\n## Inputs\n\n* `spec`:  Likely a spectrogram representation of audio data.\n* `self.device`: A string indicating the device to use for computation (e.g., \"mps\" for Apple M1 chip, otherwise likely a GPU).\n* `self.vocos`: A Vocoder model object.\n\n## Output\n\n* A NumPy array containing the decoded audio data.\n\n\n"
    },
    "ChatTTS__model__cuda__patch__LlamaRMSNorm__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/cuda/patch.py",
        "relativePath": "ChatTTS/model/cuda/patch.py",
        "lineNo": 13,
        "endLineNo": 18,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fcuda%2Fpatch.py%23L13-L18&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis\n\n**Quick Summary:**\n\nThis function normalizes a set of hidden states using a technique called layer normalization. It calculates a scaling factor based on the variance of each hidden state vector and scales the hidden states accordingly. This normalization helps stabilize training and improve performance in deep learning models.\n\n**Inputs:**\n\n* **hidden_states:** A tensor representing the output of a Transformer layer (usually).\n* **self.weight:** A trainable weight tensor that scales the normalized hidden states.\n* **self.variance_epsilon:** A small constant added to the variance to prevent division by zero.\n\n**Output:**\n\n*  A tensor representing the normalized hidden states, scaled by the trainable weight.   \n"
    },
    "ChatTTS__model__dvae__MelSpectrogramFeatures__forward": {
        "label": "forward",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 199,
        "endLineNo": 204,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L199-L204&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick Summary]** This function takes an audio input, converts it into a Mel spectrogram, applies a logarithm and clipping operation to the spectrogram, and returns the processed Mel spectrogram as a tensor. The purpose is likely to extract features from the audio for use in a machine learning model.\n\n**[Inputs]**\n\n*  `audio`: Likely an audio signal represented as a torch.Tensor. \n\n**[Output]**\n\n*  `features`: A torch.Tensor representing the log-clipped Mel spectrogram of the input audio. \n\n\n\n"
    },
    "stream__ChatStreamer___subgen": {
        "label": "_subgen",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 69,
        "endLineNo": 74,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L69-L74&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis Python function iterates through a dataset `data` in chunks of size `thre` and yields each chunk.  This is useful for processing large datasets efficiently, potentially streaming data in real-time or handling memory constraints.\n\n## Inputs\n\n* `data`: This is likely a NumPy array or a similar data structure holding the dataset.\n* `thre`: This integer determines the size of each chunk.\n\n\n## Output\n\n* Yields a NumPy array representing a chunk of the data.  \n"
    },
    "web__funcs___set_generate_buttons": {
        "label": "_set_generate_buttons",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 126,
        "endLineNo": 131,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L126-L131&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:**  This function dynamically controls the visibility and interactivity of two buttons, \"generate_button\" and \"interrupt_button,\" based on the boolean value `is_reset`. When `is_reset` is True, the \"generate_button\" becomes visible and interactive, while the \"interrupt_button\" is hidden and non-interactive. Conversely, when `is_reset` is False, the \"interrupt_button\" becomes visible and interactive, and the \"generate_button\" is hidden.  \n\n**Inputs:**\n\n* `generate_button`: Likely a graphical button element.\n* `interrupt_button`:  Another graphical button element.\n* `is_reset`: A boolean value (True or False) determining which button is active. \n\n**Output:**\n\n* Updates the \"generate_button\" and \"interrupt_button\" elements.\n* Changes the visibility and interactiveness of these buttons based on `is_reset`. \n\n\n"
    },
    "web__funcs__on_audio_seed_change": {
        "label": "on_audio_seed_change",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 56,
        "endLineNo": 61,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L56-L61&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function, likely part of a dialogue system, aims to randomly select a speaker from a set of available speakers.  It uses a random seed (`audio_seed_input`) to ensure reproducibility of speaker selection.\n\n## Inputs\n\n* `audio_seed_input`:  A seed value used for initializing random number generation, ensuring consistent speaker selection across runs.\n\n\n## Output\n\n* `rand_spk`: A randomly selected speaker identifier (likely a string or index).  \n"
    },
    "ChatTTS__core__Chat__sample_audio_speaker": {
        "label": "sample_audio_speaker",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 163,
        "endLineNo": 167,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L163-L167&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown: \n\n**Quick Summary:** \n\nThis function takes an audio waveform (potentially as a NumPy array) and encodes it into a textual representation using a combination of a DVAEs (Deep Variational Autoencoders) and a tokenizer. The encoded audio is then likely used for downstream tasks such as speech recognition or text generation.\n\n**Inputs:**\n\n*  `wav`: The audio waveform, possibly a NumPy array.\n\n*  `self.device`: A variable indicating the target device for computation (e.g., CPU or GPU).\n*  `self.tokenizer`: A tokenizer object used to convert the encoded audio into a format suitable for processing by a language model.\n\n **Output:**\n\n* A textual representation of the encoded audio.  This could be a sequence of tokens, embeddings, or another format depending on the tokenizer. \n"
    },
    "ChatTTS__model__dvae__DVAE____call__": {
        "label": "__call__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 245,
        "endLineNo": 249,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L245-L249&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick Summary]\nThis function likely overrides a method in a parent class, specializing the behavior for encoding or decoding. It delegates the actual processing to `super().__call__(inp, mode)`, which suggests it's part of a larger sequence modeling system like a Transformer. The purpose appears to be to provide a consistent interface for input processing based on the desired mode.\n\n[Inputs]\n* `inp`:  A PyTorch tensor containing input data, representing a sequence.\n* `mode`:  A string specifying the operation mode, \"encode\" or \"decode\".\n\n[Output]\n* A PyTorch tensor, the output of the encoding or decoding process. \n\n\n\n"
    },
    "ChatTTS__model__dvae__DVAE____repr__": {
        "label": "__repr__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 240,
        "endLineNo": 244,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L240-L244&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:**\n\nThis function encodes a numerical coefficient array (`self.coef`) into a byte string using a specific encoding scheme (likely protobuf) represented by `b14`.  The purpose is probably to serialize the coefficients for storage, transmission, or use with a system that expects this particular byte representation.\n\n**Inputs:**\n\n* `self.coef`: A tensor or array of numerical coefficients likely representing weights or parameters within a machine learning model.\n\n**Output:**\n\n* A byte string representing the encoded numerical coefficients.  \n\n\n"
    },
    "ChatTTS__model__gpt__GPT__GenerationOutputs__destroy": {
        "label": "destroy",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 323,
        "endLineNo": 327,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L323-L327&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Snippet Analysis\n\n**Quick Summary:**\n\nThis code snippet deletes all elements from three lists: `self.ids`, `self.attentions`, and `self.hiddens`. This suggests it's likely part of a class method used for resetting or clearing internal storage related to a machine learning model, possibly after training or when preparing for a new input.\n\n**Inputs:**\n\n* `self.ids`: A list, possibly containing identifiers or indices.\n* `self.attentions`: A list likely holding attention weights or values.\n* `self.hiddens`: A list probably containing hidden state representations from a model's layers.\n\n**Output:**\n\n* The three lists (`self.ids`, `self.attentions`, `self.hiddens`) will be emptied of all their elements. \n"
    },
    "ChatTTS__norm__Normalizer___count_invalid_characters": {
        "label": "_count_invalid_characters",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 191,
        "endLineNo": 195,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L191-L195&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Python Code Analysis \n\n**Quick Summary**\n\nThis function identifies and returns a set of non-alphabetic Chinese characters present within a given string. It achieves this by first removing any matches to a defined \"sub_pattern\" and then extracting all occurrences of characters matching the \"reject_pattern.\" This likely suggests the code aims to filter out specific unwanted characters from a Chinese text string. \n\n**Inputs**\n\n*  `s`: The input string potentially containing Chinese characters.\n*  `self.sub_pattern`: A regular expression pattern used to remove specific substrings from the input string. \n*  `self.reject_pattern`: A regular expression pattern used to identify non-alphabetic Chinese characters within the remaining string.\n\n**Output**\n\n* A set of strings representing the identified non-alphabetic Chinese characters within the input string.   \n"
    },
    "tools__logger__log__Formatter____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/logger/log.py",
        "relativePath": "tools/logger/log.py",
        "lineNo": 38,
        "endLineNo": 42,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Flogger%2Flog.py%23L38-L42&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code snippet likely determines the user's local timezone and stores it as `self.tz`, alongside storing a color value in `self.color`. This suggests it's part of a class  responsible for handling time and/or visual display, possibly in a GUI application.  \n\n## Inputs\n\n*  \n    `datetime.now(timezone.utc)`: Gets the current date and time, specifically in Coordinated Universal Time (UTC).\n*  `astimezone()`: Converts the UTC time to the user's local timezone.\n*  `tzinfo`: Extracts the timezone information from the converted time.\n*  `color`: A color value (likely a string or numeric representation).\n\n\n## Output\n\n* `self.tz`: The user's local timezone information.\n* `self.color`: The given color value. \n"
    },
    "web__funcs__generate_seed": {
        "label": "generate_seed",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 47,
        "endLineNo": 51,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L47-L51&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]**\n\nThis function randomly selects a seed value within a given range (defined by `seed_min` and `seed_max`) and updates a variable named `gr`. It likely controls aspects related to sound generation or audio processing, as hinted by its name (`gr`) and the context of \"choosing an instrument.\"\n\n**[Inputs]**\n\n* `seed_min`: The minimum allowed seed value.\n* `seed_max`: The maximum allowed seed value. \n* `gr`: A variable presumably holding a value that will be updated.\n\n\n**[Output]**\n\n* An updated value of `gr` - a random integer between `seed_min` and `seed_max`. \n"
    },
    "ChatTTS__norm__Normalizer__destroy": {
        "label": "destroy",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 178,
        "endLineNo": 181,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L178-L181&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n\n**[Quick Summary]**\n\nThis function purges internal data structures used in a larger text processing system. It deallocates any `normalizers` and clears the `homophones_map`. The purpose is likely to release memory and reset the internal state of the object for a fresh processing cycle.\n\n**[Inputs]**\n\n*  **self.normalizers:**  Likely a collection of normalization objects (e.g., stemming, lemmatization) \n*  **self.homophones_map:**  Possibly a dictionary mapping homophones (words that sound alike but have different spellings) to their canonical forms.\n\n**[Output]**\n\n*  None (The function modifies the object in-place and doesn't return a value) \n\n\nLet me know if you have any other code snippets you'd like me to analyze! \n"
    },
    "ChatTTS__norm__Normalizer__unregister": {
        "label": "unregister",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 174,
        "endLineNo": 177,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L174-L177&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick summary:** This code snippet removes a specific normalizer from a dictionary called `self.normalizers`. Normalizers are likely used for data preprocessing in machine learning. The purpose appears to be selectively removing a previously defined normalizer by its name. \n\n**Inputs:**\n\n*  `name`: A string representing the name of the normalizer to be deleted.\n*  `self.normalizers`: A dictionary likely storing normalizers, keyed by their name.\n\n**Output:**\n\n*  Modified `self.normalizers` dictionary with the specified `name` removed.\n\n\n\n\n Let me know if you have any other code snippets you'd like analyzed!\n"
    },
    "ChatTTS__utils__log__Logger__get_logger": {
        "label": "get_logger",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/log.py",
        "relativePath": "ChatTTS/utils/log.py",
        "lineNo": 12,
        "endLineNo": 15,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Flog.py%23L12-L15&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down that code snippet.\n\n**Quick Summary**\n\nThis function is designed to retrieve and return a logger object. The purpose of this code appears to be part of a larger program where logging is used to record events, messages, or errors during execution.\n\n\n**Inputs**\n\n*  `self`: This likely refers to the instance of a class this function belongs to.\n\n\n**Output**\n\n*  A logger object. This object is typically used to write log messages to a file, console, or other destination. \n"
    },
    "stream__ChatStreamer____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/cmd/stream.py",
        "relativePath": "examples/cmd/stream.py",
        "lineNo": 11,
        "endLineNo": 14,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fcmd%2Fstream.py%23L11-L14&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**Quick summary** \n\nThis function likely initializes a data processing component that handles streaming data in chunks (\"base_block_size\"). It seems designed to temporarily buffer incomplete chunks until sufficient data is available for processing.\n\n**Inputs**\n\n* `base_block_size`: Determines the size of each data chunk (likely in bytes or similar units).\n\n\n**Output**\n\n*  None (The function likely modifies an internal state rather than producing a direct output value).   \n"
    },
    "tools__audio__n__float_to_int16": {
        "label": "float_to_int16",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/audio/np.py",
        "relativePath": "tools/audio/np.py",
        "lineNo": 8,
        "endLineNo": 11,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Faudio%2Fnp.py%23L8-L11&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Audio Scaling Function Analysis\n\n**[Quick Summary]** \n\nThis function scales an audio signal (`audio`) to the maximum possible amplitude for 16-bit signed integer representation. It calculates an appropriate scaling factor (`am`) to achieve this while preserving the signal's relative amplitudes. \n\n\n**[Inputs]**\n\n* `audio`: A NumPy array representing the audio signal.\n* `math`: A Python module providing mathematical functions, specifically `ceil` for rounding up.\n* `np`:  A NumPy module for numerical operations, specifically `abs` for absolute value and `multiply` for element-wise multiplication.\n\n**[Output]**\n\n* A NumPy array representing the scaled audio signal, converted to 16-bit signed integer (`int16`) type. \n\n\n"
    },
    "tools__normalizer__zh__normalizer_zh_tn": {
        "label": "normalizer_zh_tn",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/normalizer/zh.py",
        "relativePath": "tools/normalizer/zh.py",
        "lineNo": 4,
        "endLineNo": 7,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fnormalizer%2Fzh.py%23L4-L7&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**[Quick Summary]** This code defines a function that normalizes Chinese text. It likely standardizes characters, removes unwanted whitespace, and handles typographical variations. The purpose is to prepare Chinese text for processing by other applications which may require consistent formatting.\n\n**[Inputs]**\n\n*  No explicit inputs are defined within the code snippet.\n*  The function `Normalizer().normalize` assumes it receives a string of Chinese text as input.\n\n**[Output]**\n\n*  The function returns a normalized version of the input Chinese text as a string. \n\n\n"
    },
    "tools__seeder__ctx__TorchSeedContext____enter__": {
        "label": "__enter__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/seeder/ctx.py",
        "relativePath": "tools/seeder/ctx.py",
        "lineNo": 9,
        "endLineNo": 12,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fseeder%2Fctx.py%23L9-L12&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This function likely initializes a random number generator used within a larger model. \n\nIt sets a reproducible seed for the generator and ensures deterministic results.\n\n**Inputs:**\n\n*  `self.seed`: An integer value representing the seed for the random number generator.\n\n**Output:**\n\n*  `self.state`: A snapshot of the random number generator's internal state after initialization, allowing for reproducibility. \n\n\n"
    },
    "tools__seeder__ctx__TorchSeedContext____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/seeder/ctx.py",
        "relativePath": "tools/seeder/ctx.py",
        "lineNo": 5,
        "endLineNo": 8,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fseeder%2Fctx.py%23L5-L8&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:**\n\nThis code snippet initializes an object with `seed` and `state` attributes. The `seed` likely serves as an initial value for a random number generator, ensuring reproducible random sequences. The `state` attribute probably stores the current state of the random number generator.\n\n**Inputs:**\n\n*  `seed`: An integer value used to initialize the random number generator.\n\n**Output:**\n\n* This code does not explicitly return a value. \n\n\n"
    },
    "web__funcs__on_voice_change": {
        "label": "on_voice_change",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/examples/web/funcs.py",
        "relativePath": "examples/web/funcs.py",
        "lineNo": 52,
        "endLineNo": 55,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Fexamples%2Fweb%2Ffuncs.py%23L52-L55&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown: \n\n**[Quick summary]** \nThis function retrieves the \"seed\" value associated with a specific voice from a dictionary called \"voices\".  The purpose is likely to use this seed value for text-to-speech synthesis, as \"seed\" often plays a role in controlling the randomized variations in speech output.\n\n**[Inputs]**\n* **voice_selection:** This is likely a string or integer representing the name or index of a specific voice within the \"voices\" dictionary.\n\n**[Output]**\n* A numerical value representing the \"seed\" associated with the selected voice. \n\n\n"
    },
    "ChatTTS__core__Chat__interrupt": {
        "label": "interrupt",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 234,
        "endLineNo": 236,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L234-L236&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:** This code sets a value named \"True\" into a context, likely a variable or object holding program-wide or situational data. This context setting could be used to signal a change in state or trigger specific behaviour within the program.\n\n**Inputs:**\n\n* `self.context`: Indicates this code is part of a class method.  \"self\" refers to the instance of the class, and \"context\" is likely a variable or attribute within that instance.\n\n* `True`: The value being set within the context. This suggests a boolean flag or state change.\n\n**Output:**\n\n*  The `context` variable within the object the method belongs to will be set to `True`.\n\n\n"
    },
    "ChatTTS__core__Chat__sample_random_speaker": {
        "label": "sample_random_speaker",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/core.py",
        "relativePath": "ChatTTS/core.py",
        "lineNo": 159,
        "endLineNo": 161,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fcore.py%23L159-L161&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**[Quick Summary]**\n\nThis function randomly selects a speaker from a set of available speakers and encodes its identifier into a speaker embedding using a tokenizer. This embedding likely represents the speaker's identity or characteristics in a way that can be used in downstream tasks, like speaker diarization or voice conversion.\n\n\n**[Inputs]**\n\n* `self.tokenizer`: This object is likely responsible for tokenizing and encoding text data, and in this case, it has a method `_encode_spk_emb` for encoding speaker information.\n* `self._sample_random_speaker()`: A method within the class that presumably returns a randomly chosen speaker identifier.\n\n**[Output]**\n\n* A single speaker embedding, potentially a numerical vector, representing the chosen speaker. \n\n\n"
    },
    "ChatTTS__model__dvae__GFSQ____call__": {
        "label": "__call__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 98,
        "endLineNo": 100,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L98-L100&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[**Quick Summary**]\nThis function is likely a method within a class that **overrides** the behavior of a base class's method (denoted by `super().__call__(x)`). It calls the parent class's version of the method, potentially passing the argument 'x' along, indicating that the subclass method is designed to build upon or modify the actions of the parent's method. \n\n[**Inputs**]\n* `x`: This argument is passed to the overridden method. Its precise meaning depends on the context of the class and the specific purpose of the overridden method. \n\n[**Output**] \n* The output is determined by the behavior of the parent class's method (`super().__call__(x)`).  \n\n\n\n"
    },
    "ChatTTS__model__dvae__MelSpectrogramFeatures____call__": {
        "label": "__call__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/dvae.py",
        "relativePath": "ChatTTS/model/dvae.py",
        "lineNo": 196,
        "endLineNo": 198,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fdvae.py%23L196-L198&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis function likely overrides a `__call__` method in a class. It takes audio as input, and then calls the parent class's `__call__` method with the same audio. This suggests the function is extending or specializing the behaviour of an audio processing class.\n\n[Inputs]\n- `audio`: This is likely an audio signal or data structure representing an audio clip.\n\n[Output]\n- The output is determined by the parent class's `__call__` method and depends on what that method does with the provided audio. \n\n\n"
    },
    "ChatTTS__model__gpt__GPT__Context____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 110,
        "endLineNo": 112,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L110-L112&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This code initializes a boolean variable named `_interrupt` to `False`. This likely sets a flag to control whether a task or process can be interrupted, with `False` indicating it cannot be interrupted at this time.\n\n**Inputs:** \n\n* `_interrupt`: A boolean variable likely used to control interruptibility.\n\n**Output:**\n\n*  Sets `_interrupt` to `False`. \n"
    },
    "ChatTTS__model__gpt__GPT__Context__get": {
        "label": "get",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 116,
        "endLineNo": 118,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L116-L118&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "You did not provide a function selection for me to analyze. Please provide the code snippet so I can give you the summary, inputs, and output. \n\n"
    },
    "ChatTTS__model__gpt__GPT__Context__set": {
        "label": "set",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/model/gpt.py",
        "relativePath": "ChatTTS/model/gpt.py",
        "lineNo": 113,
        "endLineNo": 115,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fmodel%2Fgpt.py%23L113-L115&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis: \n\n**[Quick Summary]**\n\nThis function, likely part of a larger control mechanism, sets an internal flag called `_interrupt` to a boolean value (`v`). This flag probably acts as an indicator to pause or stop the execution of some process or loop within the program.\n\n[**Inputs**]\n* `v`: A boolean value (True/False). \n\n [**Output**] \n* Internal modification: Sets the value of the `_interrupt` flag.  \n"
    },
    "ChatTTS__norm__Normalizer___apply_character_map": {
        "label": "_apply_character_map",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 199,
        "endLineNo": 201,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L199-L201&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** This function simplifies characters within a given text string using a predefined `character_simplifier` mapping. Its purpose is likely to reduce the complexity or size of the text, potentially for display or storage purposes.\n\n**Inputs:**\n\n* `text`:  A string containing the text to be simplified.\n* `self.character_simplifier`: A mapping (likely a dictionary or similar structure) that defines character substitutions for simplification.\n\n**Output:**\n\n* A modified string where characters have been simplified according to the `character_simplifier` mapping. \n\n\n"
    },
    "ChatTTS__norm__Normalizer___apply_half2full_map": {
        "label": "_apply_half2full_map",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/norm.py",
        "relativePath": "ChatTTS/norm.py",
        "lineNo": 196,
        "endLineNo": 198,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Fnorm.py%23L196-L198&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function converts half-width characters (typically used in Japanese text) to their corresponding full-width versions. This is likely used for text processing tasks where consistent character width is important, such as formatting or displaying text.\n\n## Inputs \n\n* **`text`:** This is the input string containing text that potentially includes half-width characters.\n\n* **`self.halfwidth_2_fullwidth`:** This is likely a mapping dictionary or translation table that specifies the conversion rules for half-width to full-width characters.\n\n## Output\n\n* **A new string:** The output is the original input string with all half-width characters replaced by their full-width counterparts. \n\n\n\n"
    },
    "ChatTTS__utils__log__Logger____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/log.py",
        "relativePath": "ChatTTS/utils/log.py",
        "lineNo": 6,
        "endLineNo": 8,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Flog.py%23L6-L8&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze.  I need the actual code to give you a summary, inputs, and output. \ud83d\ude0a   \n\n"
    },
    "ChatTTS__utils__log__Logger__set_logger": {
        "label": "set_logger",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/ChatTTS/utils/log.py",
        "relativePath": "ChatTTS/utils/log.py",
        "lineNo": 9,
        "endLineNo": 11,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2FChatTTS%2Futils%2Flog.py%23L9-L11&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze.  I need the code to give you a summary, inputs, and output. \ud83d\ude0a \n\n"
    },
    "tools__audio__ffmpeg__has_ffmpeg_installed": {
        "label": "has_ffmpeg_installed",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/audio/ffmpeg.py",
        "relativePath": "tools/audio/ffmpeg.py",
        "lineNo": 4,
        "endLineNo": 5,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Faudio%2Fffmpeg.py%23L4-L5&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis: \n\n**Quick Summary:** This function checks if the system has the necessary tools `ffmpeg` and `ffprobe` installed and available in the system's PATH. \n\n**Inputs:**\n* None.\n\n**Output:**\n* A boolean value (True or False) indicating whether both `ffmpeg` and `ffprobe` are found.  The `which` command returns the path to an executable if found, otherwise, it returns an empty string. \n\n\n\n"
    },
    "tools__seeder__ctx__TorchSeedContext____exit__": {
        "label": "__exit__",
        "systemPath": "/home/sanjay/Development/explore/ChatTTS/tools/seeder/ctx.py",
        "relativePath": "tools/seeder/ctx.py",
        "lineNo": 13,
        "endLineNo": 14,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2F2noise%2FChatTTS%2Fblob%2Fmain%2Ftools%2Fseeder%2Fctx.py%23L13-L14&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Okay, here's a breakdown of the code: \n\n**[Quick Summary]**\n\nThis code snippet appears to be setting the random number generator (RNG) state within a PyTorch context. PyTorch leverages RNGs for tasks involving randomness, like weight initialization in neural networks.  By restoring a specific `state`, the code aims to reproduce the same sequence of seemingly random numbers, ensuring deterministic behavior.\n\n**[Inputs]**\n\n* `self.state`: A variable presumably holding a saved snapshot of the PyTorch RNG's internal state.\n\n**[Outputs]**\n\n*  None (In this case, the function likely doesn't directly return a value.)\n\n\n\nLet me know if you'd like me to elaborate on any of these points!\n"
    }
}