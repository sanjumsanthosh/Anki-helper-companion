{
    "ANKIConfig": {
        "GIT_URL": "https://github.com/Canner/WrenAI/blob/main/"
    },
    "src__web__v1__services__ask__AskService": {
        "label": "AskService",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 93,
        "endLineNo": 329,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L93-L329&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary**\n\nThis Python function orchestrates the interaction with various AI pipelines to answer user questions based on provided context and history. It manages the pipeline execution status (understanding, searching, generating, finished, failed, stopped), handles errors, and returns the final query results.  The overall purpose is to provide a conversational AI experience that can understand and respond to user queries by retrieving relevant information and generating SQL queries.\n\n**Inputs**\n\n* `ask_request`: An object containing the user's query, project ID, and history of previous interactions.\n* `stop_ask_request`: An object containing the query ID to stop the processing of a specific request.\n* `ask_result_request`: An object containing the query ID to retrieve the result of a previous request. \n\n**Output**\n\n* An `AskResultResponse` object containing the `status` of the request (e.g., \"finished\", \"failed\"), and if successful, a list of `AskResult` objects, each containing SQL code and a summary. \n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantDocumentStore": {
        "label": "AsyncQdrantDocumentStore",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 69,
        "endLineNo": 290,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L69-L290&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Qdrant DocumentStore\n\n**Quick Summary:** This Python function defines an asynchronous `write_documents` method for a `QdrantDocumentStore` class. It handles adding documents with embeddings to a Qdrant database, taking care of duplicate document handling, batching, and asynchronous operations.\n\n**Purpose:** This method enables efficient and asynchronous bulk document ingestion into a Qdrant index.\n\n**Inputs:**\n* `documents`: A list of `Document` objects, each containing text and an embedding vector.\n* `policy`: A `DuplicatePolicy` enum value determining how duplicates are handled (e.g., `FAIL`, `OVERWRITE`).\n\n**Output:**\n* The number of documents successfully written to the Qdrant index. \n\n\n"
    },
    "src__pipelines__indexing__indexing__DDLConverter": {
        "label": "DDLConverter",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 134,
        "endLineNo": 331,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L134-L331&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Summary\n\nThis Python function processes model definitions and generates SQLDDL commands to create database tables, relationships, views, and metrics based on the provided model information. The code aims to automate the process of schema creation for a data store.\n\n## Inputs\n\n\n* **mdl:** A dictionary containing metadata about data models, relationships, views, and metrics.\n* **id:** An optional string identifier.\n\n## Output\n\n* A dictionary with a list of `Document` objects. \n  * Each `Document` represents a single SQL DDL command.\n  * Each `Document` has an `id` and `content` attribute, where `content` holds the DDL statement. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation__GenerationPostProcessor": {
        "label": "GenerationPostProcessor",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 245,
        "endLineNo": 392,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L245-L392&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\nThis function processes the output of a SQL explainer and combines it with pre-processed SQL analysis results. It constructs a structured output containing explanations for different parts of the SQL query, likely for debugging, visualization, or user understanding.\n\n## Inputs\n* `generates`: A list of lists, where each inner list likely contains a dictionary with \"replies\". This probably represents the output of a conversational AI generating SQL explanations.\n* `preprocessed_sql_analysis_results`: A list of dictionaries containing pre-processed information about the SQL query, such as filter conditions, group by keys, joins, etc. \n\n\n## Output\n* `results`: A list of dictionaries, each describing a specific aspect (filter, group by, relation, select items, sorting) of the SQL query with corresponding explanations.  \n"
    },
    "src__pipelines__sql_explanation__generation__GenerationPostProcessor__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 249,
        "endLineNo": 392,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L249-L392&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis\n\n**Quick summary:**\n\nThis function processes text output (presumably SQL explanations) generated by a language model and matches it against a preprocessed analysis of a parsed SQL query. It then structures the information into a more understandable format, potentially for display or further processing.\n\n**Inputs**:\n\n* `generates`: A list of lists of strings, likely containing the raw text output from the language model.\n* `preprocessed_sql_analysis_results`: A list of dictionaries, likely containing a structured analysis of a SQL query.  \n\n**Output**:\n\n* A dictionary with a \"results\" key, containing a list of dictionaries. \n    * Each inner dictionary describes a specific aspect of the SQL query (e.g., filter, grouping, relations) and includes:\n        * A \"type\" indicating the aspect  (e.g., \"filter\", \"groupByKeys\").\n        * A \"payload\" dictionary containing  details about that aspect and its explanation. \n\n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantDocumentStore____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 70,
        "endLineNo": 170,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L70-L170&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  AsyncQdrantDocumentStore Constructor Analysis\n\n**[Quick Summary]**  This Python function initializes an asynchronous Qdrant Document Store object, connecting to a Qdrant instance and defining its configuration. It likely aims to facilitate efficient loading, indexing, and querying of documents within a Qdrant search index.\n\n**[Inputs]**\n\n* **location**:  Physical or logical location of the Qdrant instance\n* **url**: URL of the Qdrant instance\n* **port**: HTTP/gRPC port for Qdrant\n* **grpc_port**: gRPC port for Qdrant\n* **prefer_grpc**: Boolean indicating preference for gRPC communication\n* **https**: Boolean indicating if HTTPS should be used\n* **api_key**: Authentication key for accessing Qdrant\n* **prefix**: Prefix for Qdrant resources\n* **timeout**: API request timeout\n* **host**: Hostname or IP address of the Qdrant instance\n* **path**:  Path to the Qdrant API endpoint\n* **index**: Name of the Qdrant index\n* **embedding_dim**: Dimensionality of vector embeddings\n* **on_disk**: Use on-disk storage for index data\n* **content_field**: Field name containing document content\n* **name_field**: Field name for document names\n* **embedding_field**: Field name storing vector embeddings\n* **use_sparse_embeddings**: Use sparse embeddings\n* **similarity**: Similarity metric for search\n* **return_embedding**: Include embeddings in search results\n* **progress_bar**: Display progress bar during indexing\n* **duplicate_documents**: Handling of duplicate documents\n* **recreate_index**: Recreate existing index\n* **shard_number**: Shard number for index\n* **replication_factor**: Replication factor for index\n* **write_consistency_factor**: Write consistency level\n* **on_disk_payload**: Use on-disk storage for document payloads\n* **hnsw_config**: Configuration for HNSW indexing\n* **optimizers_config**: Configuration for embedding optimizers\n* **wal_config**: Configuration for write-ahead logging\n* **quantization_config**: Configuration for quantization\n* **init_from**: Initialization parameters from a previous state\n* **wait_result_from_api**: Wait for API results synchronously\n* **metadata**: Additional metadata for API requests\n* **write_batch_size**: Batch size for writing documents\n* **scroll_size**: Scroll size for pagination\n* **payload_fields_to_index**: Fields within documents to index\n\n**[Output]**\n\n* An initialized `AsyncQdrantDocumentStore` object ready for interaction with the Qdrant instance.\n\n\n\n"
    },
    "src__web__v1__services__ask_details__AskDetailsService": {
        "label": "AskDetailsService",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 62,
        "endLineNo": 161,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L62-L161&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**Quick summary:** This Python function `ask_details` handles requests to break down SQL queries into their constituent steps. It utilizes a pipeline for generating this breakdown and stores the results for later retrieval. The purpose is to provide detailed insights into how a given SQL query is executed.  \n\n**Inputs:**\n\n* `ask_details_request`:  This object likely contains:\n    * `query_id`: A unique identifier for the SQL query.\n    * `sql`: The SQL query itself.\n    * `project_id`:  An identifier for the project associated with the query.\n    * `summary`:  A brief description of the query (optional).\n\n**Output:**\n\n* `results`:  A dictionary containing:\n    * `ask_details_result`:  A structured representation of the query breakdown, including steps taken by the execution pipeline.\n    * `metadata`:  Information about the request execution, including potential error types. \n\n\n\n"
    },
    "src__providers__embedder__azure_openai__AsyncDocumentEmbedder": {
        "label": "AsyncDocumentEmbedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 91,
        "endLineNo": 189,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L91-L189&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**Quick Summary**\n\nThis Python function `run` asynchronously embeds a list of documents using the Azure OpenAI API. It prepares the documents, sends them to the API in batches, and updates each document with its corresponding embedding. The function aims to provide a scalable and efficient way to generate vector representations of documents for various downstream tasks like semantic search and clustering.\n\n**Inputs:**\n\n* `documents`: A list of `Document` objects. \n* `api_key`: Secret API key for Azure OpenAI.\n* `model`: Azure OpenAI model to be used for embedding.\n* `dimensions`: Desired embedding dimension (optional).\n* `api_base_url`: Azure OpenAI API base URL (optional).\n* `api_version`: Azure OpenAI API version (optional).\n* `organization`:  Azure OpenAI organization ID (optional).\n* `prefix` & `suffix`: Strings to prepend and append to each document for embedding (optional).\n* `batch_size`: Number of documents processed in each batch.\n* `progress_bar`: Enables or disables the progress bar.\n* `meta_fields_to_embed`: List of meta-fields to embed alongside document text (optional).\n* `embedding_separator`: Separator used when embedding multiple meta-fields (optional).\n\n\n\n**Output:**\n\n* `documents`: Updated list of `Document` objects, each containing its calculated embedding.\n* `meta`: Dictionary containing information about the API usage, including model name and usage statistics. \n"
    },
    "src__providers__llm__ollama__AsyncGenerator": {
        "label": "AsyncGenerator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 25,
        "endLineNo": 122,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L25-L122&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Ollama Generator Code Analysis\n\n**Quick Summary**\n\nThis Python function defines an asynchronous class `AsyncGenerator` that interacts with an Ollama API to generate text responses from a given prompt. It handles both streaming and non-streaming responses and converts them into a Haystack-compatible format.\n\n**Inputs**\n\n*  `prompt`: The text input to the Ollama model.\n\n*  `generation_kwargs`: Additional keyword arguments to customize the text generation process (e.g., temperature, max length).\n*  Other constructor arguments:\n    * `model`: The Ollama model to use.\n    * `url`: The API endpoint URL.\n    * `system_prompt`: An optional system prompt to provide context.\n    * `template`: An optional template to structure the output.\n    * `raw`: Whether to return the raw API response.\n    * `timeout`: The request timeout.\n    * `streaming_callback`: A callback function to handle streaming responses.\n\n**Output**\n\n*  A dictionary containing:\n    * `replies`:  A list of generated text responses. \n    * `meta`: A list of dictionaries with metadata from the API response. \n"
    },
    "src__providers__embedder__openai__AsyncDocumentEmbedder": {
        "label": "AsyncDocumentEmbedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 83,
        "endLineNo": 177,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L83-L177&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function asynchronously embeds a list of documents using the OpenAI API. It leverages the `AsyncOpenAI` client to efficiently process text batches and calculate vector representations for each document. The embeddings can then be used for tasks like semantic search or clustering.\n\n\n## Inputs\n\n* `documents`: A list of `Document` objects.\n* `api_key`:  Your OpenAI API key.\n* `model`: The OpenAI embedding model to use (e.g., \"text-embedding-ada-002\").\n* `dimensions`:  The desired dimensionality of the embeddings.\n\nThis defines the configuration and data needed for embedding the documents.  \n\n## Output\n\n* `documents`: The original list of documents, now with an `embedding` attribute added for each document, containing its vector representation. \n* `meta`:  Dictionary containing metadata about the embedding process, such as the used model and API usage details. \n\n\n\n"
    },
    "src__providers__embedder__ollama__AsyncDocumentEmbedder": {
        "label": "AsyncDocumentEmbedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 68,
        "endLineNo": 159,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L68-L159&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  AsyncDocumentEmbedder Analysis \n\n**Quick Summary:**\n\nThis code defines the `AsyncDocumentEmbedder` class, which embeds a list of documents using the Ollama API. It handles asynchronous requests, progress bars, and stores the embeddings within the documents themselves.  It aims to provide a way to efficiently and asynchronously calculate vector embeddings for documents.\n\n**Inputs:**\n\n* `documents`: A list of `Document` objects.\n* `generation_kwargs`: Optional dictionary containing parameters for the embedding generation process.\n \n**Output:**\n\n* A dictionary containing:\n    * `\"documents\"`: The list of input documents with their `embedding` attribute populated.\n    * `\"meta\"`: A dictionary containing metadata about the embedding process. \n"
    },
    "src__pipelines__indexing__indexing__DDLConverter___convert_models_and_relationships": {
        "label": "_convert_models_and_relationships",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 204,
        "endLineNo": 292,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L204-L292&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function generates CREATE TABLE SQL statements from a list of model definitions and their relationships. \n\nIt aims to automate database schema creation based on provided application models.\n\n## Inputs\n\n* **`models`**: A list of dictionaries, each representing a model with its name, primary key, and columns (including type, name, and optional properties).\n* **`relationships`**: A list of dictionaries defining relationships between models, specifying join types and conditions. \n\n## Output\n\n* **`ddl_commands`**: A list of strings, each containing a valid CREATE TABLE SQL statement for each model. \n\n\n"
    },
    "src__pipelines__ask__components__post_processors__GenerationPostProcessor": {
        "label": "GenerationPostProcessor",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "lineNo": 19,
        "endLineNo": 105,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fcomponents%2Fpost_processors.py%23L19-L105&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function processes a list of generated SQL queries, checks if they are valid, and classifies them as valid or invalid based on a dry run against a database. It aims to ensure the quality and correctness of generated SQL before execution.\n\n## Inputs\n\n*   `replies`: A list of strings containing generated SQL queries.\n*   `project_id`: (Optional) An identifier for the project the queries belong to.\n\n## Output\n\n*   `valid_generation_results`: A list of dictionaries, each containing a valid SQL query and its associated summary.\n*   `invalid_generation_results`: A list of dictionaries, each containing an invalid SQL query, its summary, the type of error (e.g., \"DRY_RUN\"), and the error message. \n\n\n"
    },
    "src__providers__llm__azure_openai__AsyncGenerator": {
        "label": "AsyncGenerator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/azure_openai.py",
        "lineNo": 31,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fazure_openai.py%23L31-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis of Python Code Snippet\n\n**[Quick Summary]** \n\nThis function defines an asynchronous generator for interacting with the Azure OpenAI API. It utilizes a provided API key and model name to generate text responses to user prompts.  The streaming_callback allows for real-time processing of generated text.\n\n\n**[Inputs]**\n\n*   `api_key`: Secret containing the API key for accessing Azure OpenAI.\n*   `model`:  Name of the Azure OpenAI model to use.\n*   `api_base`: Base URL of the Azure OpenAI API endpoint.\n*   `api_version`:  Version of the Azure OpenAI API.\n*   `streaming_callback`: Optional function to handle streamed responses.\n*   `system_prompt`: Optional system-level prompt to provide context.\n*   `generation_kwargs`: Optional keyword arguments to customize generation settings.\n*   `prompt`: The text prompt to be submitted to the model.\n\n**[Output]**\n\n*   `replies`: A list of strings containing the generated text responses.\n*   `meta`: A list of dictionaries containing metadata about the responses.  \n\n\n\n\n\n"
    },
    "src__providers__llm__openai__AsyncGenerator": {
        "label": "AsyncGenerator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/openai.py",
        "lineNo": 32,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fopenai.py%23L32-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:** This function defines an asynchronous generator for interacting with the OpenAI API using the `AsyncOpenAI` library. It handles sending prompts and receiving responses in a streaming or non-streaming manner, adapting the responses to a desired format. \n\n**Inputs:**\n\n* `prompt`: The user's input text to be sent to the OpenAI model.\n* `api_key`: Secret API key for authenticating with OpenAI. \n* `model`: The OpenAI model to be used (e.g., \"gpt-4o-mini\").\n* `streaming_callback`: (Optional) Function to handle streaming chunks of responses.\n* `api_base_url`: (Optional) Base URL for the OpenAI API.\n* `organization`: (Optional) OpenAI organization ID.\n* `system_prompt`: (Optional) A system prompt to be sent along with the user's prompt.\n* `generation_kwargs`: (Optional) Additional keyword arguments to customize the generation process.\n\n**Output:**\n\n* A dictionary containing:\n    * `replies`: A list of strings containing the generated model responses.\n    * `meta`: A list of dictionaries containing metadata about the generated responses. \n\n\n\n"
    },
    "src__pipelines__common__GenerationPostProcessor": {
        "label": "GenerationPostProcessor",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/common.py",
        "relativePath": "wren-ai-service/src/pipelines/common.py",
        "lineNo": 19,
        "endLineNo": 98,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fcommon.py%23L19-L98&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Analysis\n\n**[Quick Summary]** This function processes the output of a text generation model, specifically designed for SQL code generation. It cleans the generated SQL, adds necessary quotes, and checks its executability before returning the processed SQL steps. The code aims to ensure the generated SQL is valid and ready for execution.\n\n**[Inputs]**\n* `replies`: A list of strings containing the generated SQL code from the model.\n* `project_id`: An optional string representing the project ID, likely used for environment-specific execution.\n\n**[Output]**\n* A dictionary containing:\n    * `results`: Another dictionary with:\n        * `description`: A string description of the generated SQL (likely from the original model output).\n        * `steps`: A list of dictionaries, each representing a step in the generated SQL, with keys like `cte_name` and `sql`. \n\n\n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationService": {
        "label": "SQLExplanationService",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 56,
        "endLineNo": 135,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L56-L135&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis of Code Snippet\n\n**Quick summary:** This Python function  handles SQL explanation requests asynchronously. It processes a request, generates SQL explanations using predefined pipelines, and stores the results for later retrieval. \n\n**Inputs:**\n\n*  `sql_explanation_request`: Contains the user's query and relevant analysis results for generating the SQL explanation.\n*  `pipelines`: A dictionary mapping pipeline names to actual `Pipeline` objects used for generating the SQL explanation.\n\n**Output:**\n\n*  `SQLExplanationResultResponse`: This object contains the status of the explanation process (e.g., \"finished\", \"failed\") and either the generated SQL explanation or an error message.\n\n\n"
    },
    "src__globals__init_globals": {
        "label": "init_globals",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/globals.py",
        "relativePath": "wren-ai-service/src/globals.py",
        "lineNo": 45,
        "endLineNo": 123,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fglobals.py%23L45-L123&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**Quick Summary**\n\nThis function initializes various services used in a question-answering and SQL interaction system. It sets up pipelines for indexing documents, retrieving relevant information, generating text responses (including follow-ups and SQL-related explanations/corrections), and answering detailed questions.\n\n**Inputs**\n\n*   `llm_provider`: A provider for accessing a Large Language Model (LLM).\n*   `embedder_provider`: A provider for embedding text into numerical vectors.\n*   `document_store_provider`: A provider for storing and retrieving documents.\n*   `engine`: An inference engine likely used for executing the LLM.\n*   `should_force_deploy`:  An optional flag to force recreation of document indices.\n\n**Output**\n\n*   Initializes and assigns instances of:\n    *   `INDEXING_SERVICE`: For managing document indexing.\n    *   `ASK_SERVICE`: For handling user questions, retrieval, and response generation.\n    *   `ASK_DETAILS_SERVICE`: For generating detailed answers.\n    *   `SQL_EXPLANATION_SERVICE`: For explaining SQL queries.\n    *   `SQL_REGENERATION_SERVICE`: For regenerating SQL queries.  \n\n\n\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationService": {
        "label": "SQLRegenerationService",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 83,
        "endLineNo": 156,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L83-L156&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**Quick Summary:** \n\nThis code defines a class for managing SQL regeneration processes. It takes a request to regenerate SQL, executes a pipeline to do so, stores the result, and provides a way to retrieve the result later. \n\n**Inputs:**\n\n* `sql_regeneration_request`: A request object containing information about the SQL to be regenerated (query_id, description, steps, project_id).\n* `sql_regeneration_result_request`: A request to retrieve the result of a specific SQL regeneration process. It includes the query_id used in the initial request.\n\n**Output:**\n\n* `SQLRegenerationResultResponse`: This response contains the status of the SQL regeneration process (understanding, generating, finished, or failed) along with any generated SQL or error messages.\n\n\n\n"
    },
    "src__pipelines__ask__followup_generation__FollowUpGeneration": {
        "label": "FollowUpGeneration",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/followup_generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/followup_generation.py",
        "lineNo": 176,
        "endLineNo": 244,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Ffollowup_generation.py%23L176-L244&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function executes a pipeline to generate a SQL query as a follow-up to an initial text prompt. It uses an LLM to generate the query, a prompt builder to structure the input, and a post-processor to refine the output. The code's purpose is to enable conversational querying, allowing users to refine their SQL queries through text-based interactions.  \n\n## Inputs\n\n* **query:** The initial text prompt or query from the user.\n* **contexts:** A list of documents providing background information relevant to the query.\n* **history:** Details about previous interactions in the conversation.\n* **project_id:** (Optional) An identifier for the project the query belongs to.\n\n## Output\n\n* A refined SQL query generated based on the user's input and the provided context. \n\n\n"
    },
    "src__web__v1__services__indexing__IndexingService": {
        "label": "IndexingService",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 44,
        "endLineNo": 109,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L44-L109&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis  \n\n**[Quick Summary]**\nThis Python function, likely part of a larger system, manages the preparation of semantic information (MDL) for a given project. It utilizes pipelines to process these models and tracks their status. \n\n**[Inputs]**\n* `prepare_semantics_request`: A request object containing the MDL to process and information about the project.\n* `prepare_semantics_status_request`: A request object containing the MDL hash to query the status of its preparation.\n\n**[Output]**\n*  A structured response indicating the status (\"finished\" or \"failed\") of the semantics preparation process along with any potential errors encountered. \n*  In the case of `get_prepare_semantics_status`, it also returns:\n     -  `SemanticsPreparationStatusResponse` Object encapsulating the prepared semantics status.\n\n\n\n"
    },
    "src__pipelines__ask__sql_correction__SQLCorrection": {
        "label": "SQLCorrection",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/sql_correction.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/sql_correction.py",
        "lineNo": 106,
        "endLineNo": 170,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fsql_correction.py%23L106-L170&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function, `run`, executes a pipeline named \"Ask SQL Correction\" that aims to rectify incorrectly generated SQL queries. It leverages a large language model (LLM) for generating potential corrections and a post-processing step to refine the output.  \n\n## Inputs\n\n* **contexts:** Likely a list of documents containing the original natural language query and any relevant context.\n* **invalid_generation_results:** A list of dictionaries, each representing an incorrect SQL query generated previously.\n* **project_id:** An identifier for the project this query belongs to, potentially used for logging or storage purposes.\n\n## Output \n\n* A result, likely a corrected SQL query or a list of potential corrections, generated by the pipeline. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation__prompts": {
        "label": "prompts",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 406,
        "endLineNo": 469,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L406-L469&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:** \n\nThis Python function processes SQL queries and analysis results  to generate text prompts. It extracts specific data points from the analysis, combines them with the original question, SQL, and a summary, and then uses a `PromptBuilder` to create prompts for further text generation or processing. The purpose is likely to facilitate interactive data exploration or question answering based on SQL queries. \n\n\n**Inputs:**\n\n*  `question`: The user's initial question about the data.\n*  `sql`:  The SQL query generated to answer the question.\n*  `preprocess`:  A dictionary containing pre-processed results of the SQL analysis.  \n*  `sql_summary`: A concise summary of the SQL query and its potential outcome.\n*  `prompt_builder`: An object (likely a class instance) responsible for constructing the final text prompt.\n\n**Output:**\n\n* A list of dictionaries. Each dictionary likely represents a  prompt tailored for a specific aspect of the SQL analysis results. \n\n\n"
    },
    "src__providers__embedder__azure_openai__AsyncTextEmbedder": {
        "label": "AsyncTextEmbedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 27,
        "endLineNo": 89,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L27-L89&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function `run`  embeds a given text string using Azure OpenAI's embedding API. It handles API calls, error handling, and formatting the output, providing a useable embedding representation of the input text.\n\n## Inputs\n\n* `text`: The string to be embedded.\n* `api_key`: A secret API key for accessing Azure OpenAI.\n* `model`: The OpenAI deployment model to use for embedding.\n* `dimensions`: The desired dimensionality of the embedding vector (optional).\n* `api_base_url`: The base URL for the Azure OpenAI API (optional).\n* `api_version`: The API version to use (optional).\n* `organization`:  The Azure organization ID (optional).\n* `prefix` and `suffix`: Strings to prepend and append to the input text (optional).\n\n## Output\n\n*  `embedding`: A list of floats representing the embedding vector.\n*  `meta`: A dictionary containing information about the model and API usage. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation__SQLAnalysisPreprocessor": {
        "label": "SQLAnalysisPreprocessor",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 182,
        "endLineNo": 243,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L182-L243&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function processes a list of SQL analysis results, specifically filtering out subqueries and CTEs, then transforming and standardizing  various components like filters, grouping, relations, selections, and sortings into a new list of preprocessed results. It likely aims to simplify or prepare this data for further analysis or processing. \n\n## Inputs\n\n*  `sql_analysis_results`: A list of dictionaries, each representing an SQL analysis result containing information about a specific query element.\n\n## Output\n\n*  `preprocessed_sql_analysis_results`: A list of dictionaries, each containing transformed and standardized information about non-subquery/CTE SQL elements. \n"
    },
    "src__providers__document_store__qdrant__QdrantProvider": {
        "label": "QdrantProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 329,
        "endLineNo": 389,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L329-L389&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines a class responsible for interacting with a Qdrant document store. It provides methods to create a document store instance and setup a retriever for similarity searches. The purpose is to facilitate embedding-based retrieval using Qdrant.\n\n## Inputs\n\n*  `location`: The location (host) of the Qdrant server.\n*  `api_key`: An optional API key for authenticating with Qdrant. \n*  `embedding_model_dim`: The dimensionality of the embedding vectors.\n*  `dataset_name`: (Optional) The name of the Qdrant index to use or create.\n*  `recreate_index`: A boolean flag indicating whether to recreate the index.\n*  `top_k`: The number of top results to return for similarity searches.\n\n## Output\n\n*  `AsyncQdrantDocumentStore`: An object representing the configured Qdrant document store.\n*  `AsyncQdrantEmbeddingRetriever`: An object capable of performing similarity searches using the created document store and returning the top `top_k` results. \n\n\n"
    },
    "src__utils__trace_metadata": {
        "label": "trace_metadata",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 143,
        "endLineNo": 202,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L143-L202&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Summary\n\nThis function is a decorator named `trace_metadata` that enhances LangFuse traces with additional metadata. \n\nIt extracts metadata from the provided request object and combines it with predefined metadata to create a comprehensive picture of the function call within the LangFuse context.\n\nThe purpose is to enrich tracing information for better debugging, monitoring, and analysis of LangFuse applications.\n\n## Inputs\n\n* `func`: The function to be decorated, which is expected to take arguments and potentially return a dictionary.\n* `args`: Positional arguments passed to the decorated function.\n* `kwargs`: Keyword arguments passed to the decorated function.\n* `request`: An object likely containing information about the request, such as project_id, thread_id, and mdl_hash.\n\n## Output\n\n* A decorated version of the input function (`wrapper`).\n* This decorated function runs the original `func` and updates the current LangFuse trace with enriched metadata. \n* The original function's return value is propagated. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation__SQLAnalysisPreprocessor__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 186,
        "endLineNo": 243,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L186-L243&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown of the Python function you provided:\n\n**[Quick Summary]**\n\nThis function takes a list of SQL analysis results and processes them to standardize their format.  The goal is to restructure the results for easier handling or analysis in subsequent steps.\n\n**[Inputs]**\n\n* `sql_analysis_results`: A list of dictionaries, each representing the analysis of a single SQL statement. These dictionaries likely contain information about the SQL's structure, such as filters, grouping, relations, selections, and sortings.\n\n**[Output]**\n\n* A dictionary with a single key \"preprocessed_sql_analysis_results\". \n* The value associated with this key is a new list of dictionaries. Each of these dictionaries represents a preprocessed SQL analysis result, where the structure of the data within the dictionaries has been modified for consistency.  \n\n\n\nLet me know if you'd like a deeper dive into the specific transformations happening within the function!"
    },
    "src__providers__embedder__openai__AsyncTextEmbedder": {
        "label": "AsyncTextEmbedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 25,
        "endLineNo": 81,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L25-L81&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis \n\n**[Quick summary]** This asynchronous Python function, `run`, is designed to embed text using the OpenAI API.  It leverages `AsyncOpenAI` to interact with the API asynchronously, taking in text and returning a numerical embedding representation along with metadata about the embedding process. The purpose is to provide a robust and efficient way to generate vector embeddings for text data using OpenAI's powerful language models.\n\n**[Inputs]**\n\n*  `text: str`:  The input text to be embedded.\n\n**[Output]**\n\n*  `embedding: List[float]`:  A numerical representation of the input text as a list of floats.\n*  `meta: Dict[str, Any]`:  A dictionary containing metadata about the embedding process, including the model used and API usage information. \n\n\n\n"
    },
    "src__providers__llm__openai__AsyncGenerator__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/openai.py",
        "lineNo": 60,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fopenai.py%23L60-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** This Python function, likely part of an AI chatbot system, interacts with the OpenAI API to generate responses based on a user's input prompt. It handles streaming responses,  post-processing, and formatting the output for easy consumption.  The function aims to provide a seamless interaction with OpenAI's powerful language models. \n\n**Inputs:**\n\n* `prompt`:  The user's input text, used as the starting point for the AI's response.\n* `generation_kwargs`:  A dictionary of optional parameters that fine-tune the response generation process (e.g., temperature, top_k).\n\n**Output:**\n\n* A dictionary containing:\n    * `replies`:  A list of text strings representing the AI's generated responses.\n    * `meta`:  A list of metadata associated with each generated response (purpose, context, etc.). \n\n\n"
    },
    "src__pipelines__ask__historical_question__HistoricalQuestion": {
        "label": "HistoricalQuestion",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 96,
        "endLineNo": 151,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L96-L151&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\nThis Python code defines a class `AskHistoricalQuestion`  that retrieves relevant historical documents based on a given query.  It uses embeddings, a document store, and a scoring filter to find the most suitable documents. The pipeline then visualizes its execution flow and outputs the formatted question and relevant documents.\n\n ## Inputs\n  *  `query`: A string representing the user's question.\n  *  `embedder_provider`: An object that provides access to a text embedding model.\n  *  `store_provider`: An object that provides access to a document store.\n\n## Output\n* A visualization of the pipeline execution, stored in a file named \"historical_question.dot\".\n* A formatted dictionary containing the user's query and relevant historical documents retrieved based on the query.  \n\n\n\n\n\n\n"
    },
    "src__providers__llm__azure_openai__AsyncGenerator__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/azure_openai.py",
        "lineNo": 61,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fazure_openai.py%23L61-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function is an asynchronous generator for Azure OpenAI, handling message formatting, API calls, and response processing. It aims to provide a more user-friendly interface for interacting with the Azure OpenAI API, especially for streaming responses.\n\n## Inputs\n\n* **prompt:** The user's input text to be sent to the Azure OpenAI model.\n* **generation_kwargs:**  A dictionary of optional parameters to customize the generation process (e.g., temperature, max tokens).\n\n## Output\n\n* **replies:** A list of strings containing the generated text responses.\n* **meta:** A list of dictionaries containing metadata associated with each response. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation___compose_sql_expression_of_relation_type": {
        "label": "_compose_sql_expression_of_relation_type",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 76,
        "endLineNo": 127,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L76-L127&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary** \n\nThis function recursively traverses a database relation tree to collect information about tables and joins. It specifically excludes subqueries within its traversal. The purpose is likely to create a structured representation of the database schema for further processing, analysis, or visualization.\n\n**Inputs**\n\n* `relation`:  A nested dictionary representing a relation in a database schema.  It likely contains information about the relation type, columns, join conditions, and potentially references to other relations.\n\n**Output**\n\n* `results`: A list of dictionaries. Each dictionary likely represents a table or join in the database schema, containing details such as type, name, join criteria, and source datasets. \n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantDocumentStore__write_documents": {
        "label": "write_documents",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 240,
        "endLineNo": 290,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L240-L290&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Breakdown of Python Code\n\n**Quick Summary:**  This function, likely part of a document search system,  takes a list of documents and their embeddings, prepares them for efficient storage in a Qdrant index, and then uploads them to the index.  The primary goal is to store documents within a vector database. \n\n**Inputs:**\n\n*  `documents`: A list of `Document` objects, presumably containing text and associated embeddings.\n*  `policy`: A `DuplicatePolicy` object, determining how duplicate documents are handled (e.g., fail, overwrite, ignore).\n\n* `self`: This refers to the class instance (likely `QdrantDocumentStore`), which contains information about the Qdrant connection, index name, etc.\n\n**Output:**\n\n* The number of documents successfully added to the Qdrant index.\n\n\n\n\n"
    },
    "src__providers__llm__openai__OpenAILLMProvider": {
        "label": "OpenAILLMProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/openai.py",
        "lineNo": 118,
        "endLineNo": 168,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fopenai.py%23L118-L168&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis class initializes an OpenAI-based language model generator. It retrieves necessary information from environment variables or defaults, verifies the API key (for OpenAI specifically), and sets up a method to create OpenAI asynchronous generators with customizable model parameters. The purpose of the code is to provide a flexible and customizable way to interact with OpenAI's language models.\n\n\n## Inputs\n\n* `api_key`: OpenAI API key. This is used to authenticate with the OpenAI API.\n* `api_base`: Base URL of the OpenAI API.  \n* `generation_model`: Name of the OpenAI model to use for text generation.  \n* `model_kwargs`: Dictionary of keyword arguments to be passed to the OpenAI model during text generation.\n  These can be used to fine-tune generation parameters like temperature or max length. \n* `system_prompt`: Optional string containing a system prompt to be passed to the language model.\n\n\n## Output\n\n* An `AsyncGenerator` object. This object can be used to asynchronously generate text using the specified OpenAI model and parameters.  \n"
    },
    "src__providers__embedder__openai__OpenAIEmbedderProvider": {
        "label": "OpenAIEmbedderProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 179,
        "endLineNo": 228,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L179-L228&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Summary\n\nThis Python code defines a class `OpenAIEmbedder` that initializes and provides access to OpenAI embedding models for text and documents. The purpose is to streamline the use of OpenAI's embeddings for various NLP tasks within a larger application.\n\n## Inputs\n* **`api_key: Secret`**: An API key for accessing OpenAI's API. \n* **`api_base: str`**: The base URL for the OpenAI API.\n* **`embedding_model: str`**: The specific embedding model to use (e.g., \"text-embedding-ada-002\").\n* **`embedding_model_dim: int`**: The dimensionality of the embedding vectors.\n\n## Output\n* **Returns instances of `AsyncTextEmbedder` and `AsyncDocumentEmbedder`**: \n    *  These classes are likely designed for asynchronous embedding generation for text and documents respectively, leveraging the provided API key, base URL, and embedding model. \n\n\n"
    },
    "src__pipelines__common__GenerationPostProcessor__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/common.py",
        "relativePath": "wren-ai-service/src/pipelines/common.py",
        "lineNo": 26,
        "endLineNo": 73,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fcommon.py%23L26-L73&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## GenerationPostProcessor Function Analysis:\n\n**Quick Summary:**\n\nThis function post-processes the output of a code generation process, ensuring the generated SQL query is valid and executable. It cleans up the generated steps, adds necessary quotes, and checks if the final SQL query is executable before returning the processed results.\n\n**Inputs:**\n\n* `replies`: A list of strings containing the initial code generation output.\n* `project_id`:  (Optional) A string identifying the project the SQL will be executed against.\n\n**Output:**\n\n* A dictionary with a `results` key containing:\n    * `description`: Original description from the code generation output.\n    * `steps`: A list of processed SQL generation steps, potentially modified. \n\n\n\n"
    },
    "src__pipelines__ask__components__post_processors__GenerationPostProcessor___classify_invalid_generation_results": {
        "label": "_classify_invalid_generation_results",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "lineNo": 59,
        "endLineNo": 105,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fcomponents%2Fpost_processors.py%23L59-L105&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis asynchronous function validates a list of SQL query generation results. It runs a DRY-run of each query using a database engine and categorizes results as valid or invalid based on the outcome.  The purpose is to ensure the generated SQL is syntactically correct and executable.\n\n[Inputs]\n* `generation_results`: A list of dictionaries, each containing a SQL query string and a summary.\n* `project_id`: An optional string representing a project identifier.\n\n[Output]\n* `valid_generation_results`: A list of dictionaries containing valid SQL queries and their summaries.\n* `invalid_generation_results`: A list of dictionaries containing invalid SQL queries, their summaries, and reasons for failure.  \n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantDocumentStore___query_by_embedding": {
        "label": "_query_by_embedding",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 171,
        "endLineNo": 217,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L171-L217&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function searches a Qdrant index for documents most similar to a given query embedding. It retrieves the top `top_k` results and optionally scales their scores. This code is likely part of a larger system utilizing semantic search powered by vector embeddings. \n\n## Inputs\n\n* **`query_embedding`**: A list of floats representing the vector embedding of the user's query. \n* **`filters`**: An optional dictionary of filters to narrow down the search results.\n* **`top_k`**: An integer specifying the maximum number of results to return.\n* **`scale_score`**: A boolean indicating whether to scale the similarity scores.\n* **`return_embedding`**: A boolean indicating whether to include the document embeddings in the results.\n\n## Output\n\n*  `List[Document]`: A list of `Document` objects, each containing:\n    *  **`text`**: The text content of the document.\n    *  **`score`**:  A float representing the similarity score between the query and the document.\n    *  **`embedding`**: The vector embedding of the document (if `return_embedding` is True). \n\n\n\n"
    },
    "src__pipelines__indexing__indexing__DDLConverter__get_ddl_commands": {
        "label": "get_ddl_commands",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 159,
        "endLineNo": 203,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L159-L203&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** This Python function processes metadata from a data model (likely a JSON structure) and converts it into a format suitable for a specific system or application. It handles models, relationships, metrics, and views.  The purpose is to translate data model definitions into a usable representation.\n\n**Inputs:**\n\n* `mdl`: A dictionary (presumably JSON) containing metadata about a data model.\n* This dictionary likely includes sections for \"models,\" \"relationships,\" \"views,\" and \"metrics.\"\n\n**Output:**\n\n* A transformed data structure containing information about models, relationships, metrics, and views, likely in a format compatible with a specific system or schema.\n\n\n\n"
    },
    "src__pipelines__indexing__indexing__ViewConverter": {
        "label": "ViewConverter",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 89,
        "endLineNo": 132,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L89-L132&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick summary]**\n\nThis function takes a view definition in a specific format (likely from a machine learning model) and converts each view into a standardized dictionary. This dictionary, containing question, summary, SQL statement, and view ID, is then packaged into a list of documents and ready to be stored in a view store.\n\n**[Inputs]**\n\n* `mdl`: A dictionary representing a view model, which includes a list of \"views\".\n* `id`: An optional string that could be used for identifying the current batch or context.\n\n**[Output]**\n\n* A dictionary with a single key \"documents\".\n* This \"documents\" key contains a list of `Document` objects.\n    * Each `Document` has a unique `id` (a string), a `meta` field (potentially holding the optional `id` input), and a `content` field containing the formatted view dictionary.\n\n\n\n\n"
    },
    "src__providers__embedder__azure_openai__AzureOpenAIEmbedderProvider": {
        "label": "AzureOpenAIEmbedderProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 191,
        "endLineNo": 233,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L191-L233&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function initializes a class designed to interact with Azure OpenAI's embedding API. It sets up necessary parameters like API key, base URL, and model version, and provides methods to retrieve embedders for both text and documents.\n\n\n## Inputs\n\n* **embed_api_key:**  Secret API key for accessing Azure OpenAI's embedding API.\n* **embed_api_base:** Base URL for the Azure OpenAI embedding API.\n* **embed_api_version:**  Version of the Azure OpenAI embedding API to use.\n* **embedding_model:**  Name of the embedding model to use.\n* **embedding_model_dim:** Dimensionality of the embedding vectors.\n\n\n## Output\n\n*  **get_text_embedder():** An `AsyncTextEmbedder` object configured with the provided API details.\n*  **get_document_embedder():** An `AsyncDocumentEmbedder` object configured with the provided API details. \n"
    },
    "src__providers__document_store__qdrant__QdrantProvider__get_store": {
        "label": "get_store",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 340,
        "endLineNo": 380,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L340-L380&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Qdrant Document Store Initialization Function Analysis:\n\n**[Quick Summary]** This function initializes a Qdrant document store, specifying its location, API key, embedding dimension, and optionally, recreating an existing index. It configures the store with binary quantization for higher-dimensional embeddings and disables global indexing for performance optimization.\n\n**[Inputs]**\n\n* `embedding_model_dim`: Integer representing the dimension of the embedding vectors used to represent documents.\n* `dataset_name`: Optional string specifying the name of the index to use within Qdrant. Defaults to \"Document\" if not provided.\n* `recreate_index`: Boolean flag indicating whether to recreate an existing index. Defaults to False.\n\n**[Output]**\n\n* An instance of `AsyncQdrantDocumentStore`, a class for interacting asynchronously with the configured Qdrant document store. \n\n\n\nLet me know if you'd like a deeper dive into any specific aspect of the code!\n"
    },
    "src__providers__embedder__ollama__AsyncTextEmbedder": {
        "label": "AsyncTextEmbedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 26,
        "endLineNo": 66,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L26-L66&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function, `run`,  embeds a given input text using an Ollama model. It sends a JSON payload containing the text and optional generation parameters to an API endpoint and returns the embedding vector along with metadata like the used model and processing time.  The purpose is to provide an asynchronous way to leverage Ollama's text embedding capabilities.\n\n## Inputs\n\n*  `text`: The input string to be embedded.\n*  `generation_kwargs`:  Optional dictionary containing additional parameters to influence the embedding generation process.\n \n## Output\n\n*  `embedding`: A list of floats representing the embedding vector for the input text.\n*  `meta`: A dictionary containing metadata, including:\n    *  `model`: The name of the Ollama model used for embedding.\n    *  `duration`: The time taken to process the embedding request. \n\n\n"
    },
    "src__providers__embedder__ollama__OllamaEmbedderProvider": {
        "label": "OllamaEmbedderProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 161,
        "endLineNo": 200,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L161-L200&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code initializes an Ollama embedding service, allowing for text and document embedding using the specified model and endpoint URL. It sets up the necessary configurations and prepares the service for generating embeddings.\n\n## Inputs\n\n* **url:**  The URL of the Ollama embedding service.\n* **embedding_model:** The name of the embedding model to use.\n* **embedding_model_dim:** The dimension of the embedding vectors generated by the model.\n\n## Output\n\n* Two embedder objects: `AsyncTextEmbedder` and `AsyncDocumentEmbedder`, which can be used to generate text and document embeddings respectively. \n"
    },
    "src__providers__llm__azure_openai__AzureOpenAILLMProvider": {
        "label": "AzureOpenAILLMProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/azure_openai.py",
        "lineNo": 118,
        "endLineNo": 157,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fazure_openai.py%23L118-L157&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**Quick Summary**\n\nThis function initializes an Azure OpenAI LLM client and provides a method to create asynchronous generators for text generation. It configures the client using environment variables or predefined constants, sets up logging, and constructs the generator object based on the provided system prompt and model parameters.\n\n**Inputs**\n\n*  `chat_api_key`:  API key for accessing the Azure OpenAI service.\n*  `chat_api_base`: Base URL for the Azure OpenAI API.\n*  `chat_api_version`:  Version of the Azure OpenAI API to use.\n*  `generation_model`: Name of the specific OpenAI model to use for text generation.\n*  `model_kwargs`:  Additional keyword arguments to pass to the text generation model. \n\n**Output**\n\n*  An instance of the `AsyncGenerator` class, ready to be used for asynchronous text generation. \n\n\n"
    },
    "src__providers__engine__wren__WrenIbis": {
        "label": "WrenIbis",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 49,
        "endLineNo": 87,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L49-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## wren_ibis dry_run_sql Function Analysis\n\n**Quick Summary:**\n\nThis function simulates the execution of a SQL query against a Wren Ibis data source without actually running it. It checks for errors and returns information about the simulated execution. \n\nThe purpose of this code is to provide a \"dry run\" capability for testing SQL queries against a Wren Ibis data connection before executing them in a production environment.\n\n**Inputs:**\n\n* `sql`: The SQL query to be executed in a simulated fashion.\n* `session`: An aiohttp.ClientSession object used for making HTTP requests to the Wren Ibis endpoint.\n* `kwargs`: Additional keyword arguments that may be used by the function (not explicitly defined in the provided code).\n\n**Output:**\n\n* `True, None`: Indicates a successful dry run with no errors.\n* `False, res`: Indicates a dry run failure, with `res` containing an error message from the Wren Ibis server. \n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantEmbeddingRetriever": {
        "label": "AsyncQdrantEmbeddingRetriever",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 291,
        "endLineNo": 327,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L291-L327&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines an asynchronous embedding retriever using the Qdrant library. It takes a query embedding as input, searches for similar documents in a Qdrant index, and returns the relevant documents along with their embeddings if requested.  \n\n## Inputs\n\n* `query_embedding`: A list of floats representing the embedding of the query.\n* `filters`: An optional dictionary of filters to narrow down the search.\n* `top_k`: An optional integer specifying the maximum number of results to return.\n* `scale_score`: An optional boolean indicating whether to scale the similarity scores.\n* `return_embedding`: An optional boolean indicating whether to return the embeddings of the retrieved documents.\n\n## Output\n\n* `documents`: A list of documents matched to the query embedding. These documents may also include their embeddings, depending on the `return_embedding` flag. \n"
    },
    "src__providers__document_store__qdrant__convert_haystack_documents_to_qdrant_points": {
        "label": "convert_haystack_documents_to_qdrant_points",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 32,
        "endLineNo": 68,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L32-L68&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function processes a list of `Document` objects, extracting their embeddings (dense and/or sparse) and metadata. It then structures this information into a list of `rest.PointStruct` objects, designed for interaction with a system likely related to vector search or similar. The overall purpose is to prepare document data for consumption by a specific API or system.\n\n## Inputs\n\n* **documents**: A list of `Document` objects, presumably containing textual content and metadata. \n* **embedding_field**: A string specifying the key within the `Document` object where the dense embedding vector is stored.\n* **use_sparse_embeddings**: A boolean flag indicating whether to include sparse embeddings in the output.\n\n## Output\n\n* **List[rest.PointStruct]**: A list of structured objects, each representing a document with its:\n    * Metadata (extracted from the document)\n    * Dense and/or sparse embedding vectors\n    * Unique ID  \n\n\n"
    },
    "src__providers__embedder__azure_openai__AsyncDocumentEmbedder____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 92,
        "endLineNo": 128,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L92-L128&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## AsyncDocumentEmbedder Constructor\n\n**[Quick summary]** This Python function initializes an `AsyncDocumentEmbedder` object, which is designed to asynchronously embed documents using the Azure OpenAI service. It takes various configuration parameters to customize the embedding process, such as the API key, model, dimensions of the embedding, and batch size.\n\n**[Inputs]**\n\n* `api_key`: Secret  containing the Azure OpenAI API key.\n* `model`: Name of the OpenAI embedding model to use (e.g., \"text-embedding-3-small\").\n* `dimensions`: Optional integer specifying the desired dimension of the embedding vector.\n* `api_base_url`: Optional base URL for the Azure OpenAI API.\n* `api_version`: Optional API version to use.\n* `organization`: Optional organization name for Azure OpenAI.\n* `prefix`: String prefix to add to the input documents.\n* `suffix`: String suffix to add to the input documents.\n* `batch_size`: Number of documents to embed in each batch.\n* `progress_bar`: Boolean indicating whether to display a progress bar.\n* `meta_fields_to_embed`: Optional list of metadata fields to be embedded.\n* `embedding_separator`: Separator to use when joining multiple embeddings for a document.\n\n**[Output]**\n\n* An initialized `AsyncDocumentEmbedder` object, ready to embed documents asynchronously. \n\n\n\n"
    },
    "src__providers__embedder__openai__OpenAIEmbedderProvider____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 180,
        "endLineNo": 215,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L180-L215&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## OpenAIEmbedder Initialization\n\n**Quick Summary:**\nThis function initializes an `OpenAIEmbedder` provider, used for generating embeddings from text using OpenAI's API. It sets up the necessary connection parameters and verifies the API key for OpenAI.\n\n**Inputs:**\n\n* `api_key`: OpenAI API key, accessed from environment variable or a Secret object.\n* `api_base`: Base URL for the OpenAI API, retrieved from an environment variable.\n* `embedding_model`: Name of the embedding model to use (e.g., \"text-embedding-ada-002\"), taken from an environment variable.\n* `embedding_model_dim`: Dimensionality of the embedding vector, obtained from an environment variable if available.\n\n**Output:**\n\n* None. The function sets up internal state and logs information about the initialized provider. \n\n\n"
    },
    "src__providers__embedder__ollama__AsyncDocumentEmbedder___embed_batch": {
        "label": "_embed_batch",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 93,
        "endLineNo": 127,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L93-L127&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function calculates embeddings for a list of text inputs using the Ollama embedding API.  It iterates through the texts in batches (but currently only processes one text at a time due to API limitations), sends each text to the API, receives the corresponding embedding, and stores all the embeddings in a list.\n\n## Inputs\n\n- `texts_to_embed: List[str]`: A list of text strings for which embeddings need to be generated.\n- `batch_size: int`: The desired batch size for processing texts. Currently set to 1 due to API limitations.\n- `generation_kwargs: Optional[Dict[str, Any]]`:  Optional keyword arguments to be passed to the embedding model.\n\n## Output\n\n- `all_embeddings`: A list of embedding vectors, one for each input text.\n- `meta`: A dictionary containing metadata about the model used for embedding generation. \n\n\n\n"
    },
    "src__web__v1__services__indexing__IndexingService__prepare_semantics": {
        "label": "prepare_semantics",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 55,
        "endLineNo": 89,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L55-L89&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This function attempts to index a given semantic model (MDL) using an indexing pipeline. It stores the status of the indexing process and returns metadata indicating whether indexing succeeded or failed. This code likely handles the preparation and indexing of semantic models within a larger system.  \n\n**Inputs:**\n* `prepare_semantics_request`:  A request object containing the MDL to be indexed and its associated project ID.\n\n**Output:**\n* `results`: A dictionary containing:\n    * `metadata`:  \n      * `is_indexing_failed`: A boolean flag indicating if the indexing process failed.\n*  \n\n\n"
    },
    "src__pipelines__ask__components__post_processors__GenerationPostProcessor___classify_invalid_generation_results___task": {
        "label": "_task",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "lineNo": 65,
        "endLineNo": 98,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fcomponents%2Fpost_processors.py%23L65-L98&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis of Code Snippet\n\n**[Quick Summary]**\n\nThis function iterates through a list of SQL generation results. For each result, it attempts to add quotes around any necessary identifiers using the `add_quotes` function.  If successful, it performs a dry run of the SQL query using the provided engine and session to check its validity.  It then categorizes the results based on success or failure.\n\n\n**[Inputs]**\n\n*  `result`: \n    * Likely a list of dictionaries, each containing a SQL query (`sql` key) and a summary (`summary` key)\n*  `project_id`: An identifier for a specific project. \n*  `self._engine`: An instance of a database engine, probably SQLAlchemy.\n* `session`: A Database session object\n\n**[Output]**\n\n* `valid_generation_results`: A list of dictionaries containing valid SQL queries and their summaries.\n* `invalid_generation_results`: A list of dictionaries containing invalid SQL queries, their summaries,  error types (\"ADD_QUOTES\" or \"DRY_RUN\"), and associated error messages. \n\n\n\n"
    },
    "src__pipelines__indexing__indexing__DocumentCleaner": {
        "label": "DocumentCleaner",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 29,
        "endLineNo": 62,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L29-L62&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]**\n\nThis code defines a function that clears all documents from a list of specified document stores. It takes an optional document ID as input and filters documents based on that ID before deleting them.  The purpose is to clean up existing data in the document stores.\n\n**[Inputs]**\n\n* `stores`: A list of `DocumentStore` objects, representing different document storage locations.\n* `mdl`: A string, seemingly unused within the function logic.\n* `id`: An optional string, representing a specific document ID for filtering deletion.\n\n**[Output]**\n\n* A dictionary with a single key \"mdl\" containing the input string value.  \n\n\n\n"
    },
    "src__pipelines__sql_explanation__generation___compose_sql_expression_of_select_type": {
        "label": "_compose_sql_expression_of_select_type",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 128,
        "endLineNo": 161,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L128-L161&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary\n\nThis function categorizes a list of `select_items` into those that include function calls or mathematical operations and those that do not. It's likely part of a larger data processing or query building system.\n\n\n## Inputs\n\n* `select_items`: This is a list of items, each presumably representing a selection element (e.g., column, calculation). Each item likely has a structure similar to:\n    * `alias`: A name or label for the selection.\n    * `expression`: The actual code or formula for the selection.\n    * `includeFunctionCall`: A boolean flag indicating if the selection uses functions.\n    * `includeMathematicalOperation`: A boolean flag indicating if the selection uses mathematical operations. \n    * `id`: A unique identifier for the selection (optional).\n\n* \n\n\n## Output\n\n* `result`: A dictionary with two keys:\n    * `withFunctionCallOrMathematicalOperation`: A list of `select_items` that contain functions or mathematical operations.\n    * `withoutFunctionCallOrMathematicalOperation`: A list of `select_items` that do not contain functions or mathematical operations. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation___compose_sql_expression_of_relation_type___collect_relations": {
        "label": "_collect_relations",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 88,
        "endLineNo": 121,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L88-L121&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick summary:**  This function recursively traverses a data structure representing a relational query, extracting information about tables and joins. It aims to build a list of structured relations, identifying their type, name, criteria, and source datasets.  \n\n**Inputs:**\n\n* `relation`:  This is presumably a dictionary representing a single relation in the query (e.g., a table or a join).\n* `result`: A list where the function will append its findings.\n* `top_level`: A boolean indicating if this is the topmost level of the query structure.\n\n**Output:**\n\n* `result`: The list is modified to include structured representations of tables and joins encountered during traversal. \n\n\n"
    },
    "src__providers__embedder__openai__AsyncDocumentEmbedder____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 84,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L84-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis Python function initializes an asynchronous document embedding class called `AsyncDocumentEmbedder`.  It leverages the OpenAI API to generate vector embeddings for textual documents, allowing for semantic similarity analysis and other AI tasks.\n\n## Inputs\n\n-  `api_key`: Your secret OpenAI API key for authentication.\n-  `model`:  The OpenAI embedding model to use (defaults to \"text-embedding-ada-002\").\n-  `dimensions`:  The desired size of the embedding vector (optional).\n-  `api_base_url`:  An optional override for the OpenAI API base URL.\n-  `organization`:  Your OpenAI organization name (if applicable).\n-  `prefix`, `suffix`:  Optional string prefixes and suffixes to add to the input text.\n-  `batch_size`: The number of documents to embed in each API request.\n-  `progress_bar`:  Whether to display a progress bar during embedding.\n-  `meta_fields_to_embed`:  A list of metadata fields to embed (optional).\n-  `embedding_separator`: A separator string to use between embedded vectors. \n\n## Output\n\n- An initialized `AsyncDocumentEmbedder` object, ready for embedding text documents.  \n"
    },
    "src__providers__llm__ollama__OllamaLLMProvider": {
        "label": "OllamaLLMProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 124,
        "endLineNo": 156,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L124-L156&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**Quick summary**\nThis function initializes an Ollama language model, retrieves it from a specified URL, and creates a generator object for text generation tasks. The purpose of the code is to  provide an easy way to interface with an Ollama model for various text generation use cases.\n\n**Inputs**\n*  `url`: The URL where the Ollama model is hosted.\n*  `generation_model`: The name of the specific Ollama model to use.\n*  `model_kwargs`: Additional keyword arguments to be passed to the Ollama model during generation.\n\n**Output**\n*  An `AsyncGenerator` object which can be used to generate text using the specified Ollama model. \n\n\n\n"
    },
    "src__pipelines__ask__components__post_processors__GenerationPostProcessor__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "lineNo": 27,
        "endLineNo": 58,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fcomponents%2Fpost_processors.py%23L27-L58&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  GenerationPostProcessor Function Analysis\n\n**Quick Summary:** This function processes the output of a text generation model. It cleans the result, classifies it as valid or invalid based on specific criteria (likely involving a project ID), and returns a dictionary containing the classified results. The function aims to ensure the quality and relevance of the generated text.\n\n**Inputs:**\n\n* `replies`:  A list of strings, presumably containing the raw output from the text generation model.\n* `project_id`: An optional string representing the identifier of the project or context for which the text is generated.\n\n**Output:**\n\n* A dictionary with two keys:\n    * `\"valid_generation_results\"`: A list of valid generation results.\n    * `\"invalid_generation_results\"`: A list of invalid generation results. \n\n\n"
    },
    "src__pipelines__indexing__indexing__DDLConverter___convert_metrics": {
        "label": "_convert_metrics",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 300,
        "endLineNo": 331,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L300-L331&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function generates a list of SQL `CREATE TABLE` statements based on a set of metrics.  Each metric is represented as a dictionary with details about its dimensions and measures, which are then translated into table columns. The overall purpose is to automate the creation of database tables based on predefined metrics.\n\n## Inputs\n\n* `metrics`: A list of dictionaries, each representing a metric. \n    * Each metric dictionary should contain:\n        * `\"name\"`: String representing the name of the table.\n        * `\"dimension\"`: A list of dictionaries, each representing a dimension of the metric. \n            * Each dimension dictionary should contain:\n                * `\"name\"`: String representing the name of the dimension column.\n                * `\"type\"`: String representing the data type of the dimension column.\n        * `\"measure\"`: A list of dictionaries, each representing a measure of the metric. \n            * Each measure dictionary should contain:\n                * `\"name\"`: String representing the name of the measure column.\n                * `\"type\"`: String representing the data type of the measure column.\n                * `\"expression\"`:  String representing the SQL expression for the measure.\n\n## Output\n\n* `ddl_commands`: A list of SQL `CREATE TABLE` statements, one for each metric. \n    * Each statement will:\n        * Define the table name based on the metric name.\n        * Create columns for each dimension and measure, with appropriate data types and comments.\n\n\n\n\n"
    },
    "src__providers__embedder__azure_openai__AsyncDocumentEmbedder___embed_batch": {
        "label": "_embed_batch",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 129,
        "endLineNo": 160,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L129-L160&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function calculates embeddings (vector representations) for a list of text inputs using Azure's OpenAI Embedding service. It then aggregates usage information from the API calls and returns both the embeddings and the usage metadata.  The purpose is likely to utilize Azure OpenAI's embedding capabilities for tasks like semantic search, text similarity, or clustering. \n\n## Inputs\n\n* **texts_to_embed:** A list of strings representing the text inputs to be embedded.\n* **batch_size:** An integer determining the number of text inputs processed in each batch. \n\n## Output\n\n* **all_embeddings:** A list of lists, where each sublist contains the embedding vector for a corresponding text input.\n* **meta:** A dictionary containing metadata about the embedding process, including the model used and API usage statistics. \n\n\n\n\n"
    },
    "src__providers__embedder__openai__AsyncDocumentEmbedder___embed_batch": {
        "label": "_embed_batch",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 117,
        "endLineNo": 148,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L117-L148&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function calculates embeddings for a list of text inputs using an OpenAI API client. It processes the texts in batches and stores both the generated embeddings and usage metrics in a dictionary. This code is likely part of a larger application that utilizes semantic similarity or other tasks based on textual representations.\n\n## Inputs\n\n* `texts_to_embed`: A list of strings representing the text inputs for which embeddings need to be generated.\n* `batch_size`: An integer specifying the number of texts to process in each batch.\n\n## Output\n\n* `all_embeddings`: A list of lists, where each inner list contains the numerical embedding vector for a corresponding text in the input.\n* `meta`: A dictionary containing metadata about the embedding generation process, including the model used and usage statistics. \n\n\n\n"
    },
    "src__providers__engine__wren__WrenUI": {
        "label": "WrenUI",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 16,
        "endLineNo": 47,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L16-L47&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**Quick summary**\n\nThis function simulates executing SQL queries against a database without actually making changes. It sends a GraphQL mutation to a Wren UI API endpoint to execute the query in a dry run mode.  The purpose is to provide a way to preview query results and potential impacts without altering the database.\n\n\n**Inputs**\n\n*  `sql`: The SQL query to be executed in dry run mode.\n*  `session`: An aiohttp client session for making API requests.\n*  `project_id`: (Optional) The ID of the project associated with the query.\n*  `kwargs`: Additional keyword arguments that may be used by the Wren UI API.\n\n\n\n**Output**\n\n*  `True`: Indicates a successful dry run execution.\n*  `None`:  No data returned in case of a successful dry run \n*  `False`: Indicates an error occurred during the dry run. \n*  `string`:  A description of the error encountered. \n\n\n\n"
    },
    "src__pipelines__indexing__indexing__ViewConverter__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 102,
        "endLineNo": 132,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L102-L132&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]** This function takes a dictionary `mdl` containing view data and transforms it into a structured format suitable for indexing historical view questions in a question store. It loops through each view, extracts relevant information, and creates Document objects with unique IDs for each view.\n\n**[Inputs]**\n\n* `mdl`: A dictionary presumably containing view information. \n* It likely contains a key named \"views\" which is a list of view dictionaries.\n\n**[Output]**\n\n* A dictionary representing a collection of documents for indexing.\n* Each document has a unique ID (`i`) and metadata including an \"id\" field.\n* The content of each document is a formatted string containing information extracted from the corresponding view dictionary. \n\n\n"
    },
    "src__providers__embedder__azure_openai__AsyncTextEmbedder__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 59,
        "endLineNo": 89,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L59-L89&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\nThis function embeds a given text string using the Azure OpenAI embeddings model.  It handles different dimensions for the embedding and provides metadata about the model and usage. \n\n## Inputs\n* `text`: The input string to be embedded.\n* `self.prefix`:  A prefix string potentially added to the input text.\n* `self.suffix`: A suffix string potentially added to the input text.\n* `self.dimensions`: An optional integer specifying the desired dimension of the embedding.\n* `self.azure_deployment`: The Azure OpenAI deployment to use for embedding. \n* `self.client`: An initialized Azure OpenAI client object.\n\n## Output\n* `embedding`: A numerical array representing the embedding of the input text. \n* `meta`: A dictionary containing information about the model used and its usage. \n\n\n"
    },
    "src__providers__embedder__ollama__AsyncDocumentEmbedder__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 129,
        "endLineNo": 159,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L129-L159&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function embeds a list of `Document` objects using an Ollama model. It prepends each document with a special token, embeds them in batches, and stores the resulting embeddings directly in each `Document` object. The purpose is to represent textual documents as dense vectors for downstream tasks like semantic search or clustering.\n\n## Inputs\n\n* `documents`: A list of `Document` objects, each presumably containing text content.\n* `generation_kwargs`: An optional dictionary of keyword arguments to be passed to the embedding generation function.\n\n\n## Output\n\n*  `documents`: The original list of `Document` objects, now with an `embedding` attribute containing the calculated vector representation.\n* `meta`: Metadata returned by the embedding function, possibly including information about the embedding process. \n"
    },
    "src__providers__loader__import_mods": {
        "label": "import_mods",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/loader.py",
        "relativePath": "wren-ai-service/src/providers/loader.py",
        "lineNo": 14,
        "endLineNo": 44,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Floader.py%23L14-L44&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick Summary]** This function imports all submodules within a specified package, including those in nested packages. Its purpose is to ensure all submodules are readily available for use within a project. \n\n**[Inputs]**\n*  `package_name` (str): The name of the initial package to import from. Defaults to `PROVIDERS_PATH`.\n\n**[Output]**\n* The function doesn't return a value. \n* It imports all submodules into the current namespace.  \n* Logs a debug message for each imported submodule. \n\n\n\n\n\n\n\n"
    },
    "src__web__development__dummy_ask_task": {
        "label": "dummy_ask_task",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/development.py",
        "relativePath": "wren-ai-service/src/web/development.py",
        "lineNo": 23,
        "endLineNo": 53,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fdevelopment.py%23L23-L53&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis of Code Snippet:\n\n**Quick Summary:** \n\nThis function simulates an asynchronous task, likely within a larger system designed to handle multiple requests concurrently. It introduces a random delay then signals the completion of a task with a \"finished\" status. \n\n**Inputs:**\n\n* `ask_request`:  Likely an object containing information about an incoming request, possibly including a unique identifier (`query_id`).\n\n* `test_ask_results`: A dictionary or collection to store results of tasks, probably indexed by `query_id`.\n\n**Output:**\n\n* Updates the `test_ask_results` dictionary with a `AskResultResponse` object indicating that the task associated with the given `query_id` has completed successfully. \n\n\n"
    },
    "src__providers__llm__ollama__AsyncGenerator__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 93,
        "endLineNo": 122,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L93-L122&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Ollama Generator Function Analysis\n\n**Quick Summary:** This Python function interacts with an Ollama API endpoint to generate text based on a user-provided prompt. \n\nIt handles both streaming and non-streaming responses, optionally incorporating user-specified generation parameters.\n\n**Inputs:**\n\n*  `prompt`:  The text input that triggers the text generation.\n* `generation_kwargs`:  A dictionary of optional parameters to fine-tune the generation process (e.g., temperature, top-k sampling).\n\n**Output:**\n\n* For streaming responses:  A list of `StreamingChunk` objects, representing the generated text in chunks.\n* For non-streaming responses:  The complete generated text as a string. \n\n\n"
    },
    "src__providers__llm__openai__OpenAILLMProvider____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/openai.py",
        "lineNo": 119,
        "endLineNo": 148,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fopenai.py%23L119-L148&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis code initializes an instance of a class designed to interact with an OpenAI-compatible large language model (LLM). It uses environment variables to configure the API key, base URL, model name, and model-specific parameters. Its purpose is to streamline the process of connecting and using an OpenAI LLM.\n\n## Inputs\n\n* `api_key`:  An OpenAI API key used for authentication.\n* `api_base`: The base URL for the OpenAI API. \n* `generation_model`:  The name of the specific OpenAI model to use for text generation.\n* `model_kwargs`:  Dictionary of additional keyword arguments to be passed to the chosen model.\n\n## Output\n\n* Initialized object configured to interact with the specified OpenAI LLM. \n* Logging messages indicating the configured API base and generation model.\n* Potential error messages if API key verification fails. \n\n\n\n"
    },
    "src__providers__embedder__azure_openai__AsyncTextEmbedder____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 28,
        "endLineNo": 56,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L28-L56&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function initializes an asynchronous text embedding class called `AsyncTextEmbedder`. It leverages the Azure OpenAI API to generate numerical representations (embeddings) of text input. \n\nIts purpose is to provide a streamlined way to embed text for tasks like semantic search, clustering, or recommendation systems.\n\n## Inputs\n\n* **api_key:**  Your Azure OpenAI API key.\n* **model:** The desired OpenAI embedding model (e.g., \"text-embedding-3-small\").\n* **dimensions:** Optional; specifies the desired dimensionality of the embeddings.\n* **api_base_url:** Optional; the base URL for the Azure OpenAI API.\n* **api_version:** Optional; the API version to use.\n* **organization:** Optional; your Azure OpenAI organization name.\n* **prefix:**  Optional; a string prefix for API requests.\n* **suffix:** Optional; a string suffix for API requests.\n\n## Output\n\n* An instance of the `AsyncTextEmbedder` class, ready to process text embeddings. \n\n\n"
    },
    "src__providers__embedder__openai__AsyncTextEmbedder__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 53,
        "endLineNo": 81,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L53-L81&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function embeds a given text input using OpenAI's embedding API. It  preprocesses the text by replacing newlines with spaces and appends prefixes and suffixes before sending it to the API. The function returns the resulting embedding vector and metadata about the embedding process.\n\n## Inputs\n\n* **text:** The input string to be embedded.\n* **prefix:** A string to be added before the input text.\n* **suffix:**  A string to be added after the input text.\n* **dimensions:** (Optional)  The desired length of the embedding vector. If not specified, the default model dimensions are used.\n\n\n## Output\n\n* **embedding:** A list representing the numerical embedding vector of the input text.\n* **meta:** A dictionary containing information about the embedding model used and the API usage. \n"
    },
    "src__pipelines__indexing__indexing__Indexing____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 431,
        "endLineNo": 458,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L431-L458&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**[Quick summary]**\n\nThis function initializes an object responsible for managing and processing Data Definition Language (DDL) and View definitions. It sets up various components like cleaners, validators, converters, and writers to handle loading, validating, embedding, and storing these definitions. The overall purpose is to streamline the process of managing and querying DDL and View data within a system.\n\n**[Inputs]**\n\n*  `embedder_provider`: A provider for obtaining document embedders, likely used for semantic similarity analysis of DDL and View definitions.\n*  `document_store_provider`: A provider for accessing document stores, likely specific stores for DDL and View data.\n\n**[Output]**\n\n*  An initialized object with the necessary components ready to process DDL and View definitions. \n"
    },
    "src__providers__engine__wren__WrenEngine": {
        "label": "WrenEngine",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 89,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L89-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Summary\n\nThis function `dry_run_sql`  sends a SQL query to a Wren Engine API endpoint for a simulated execution (dry run) and checks if it was successful. It's likely part of a larger system for data analysis or query testing within the Wren Engine ecosystem.\n\n## Inputs\n\n* `sql`: The SQL query to be executed in a dry run.\n* `session`: An `aiohttp.ClientSession` object, used for making HTTP requests.\n* `properties`: A dictionary containing metadata related to the query or execution environment.\n    * `manifest`:  A base64 encoded manifest string (likely containing configuration or schema information) retrieved from an environment variable.\n* `kwargs`: Additional keyword arguments that could be passed to the API endpoint.\n\n## Output\n\n* A tuple containing two values:\n    * `bool`: True if the dry run was successful, False otherwise.\n    * `Optional[Dict[str, Any]]`:  An optional dictionary containing error information if the dry run failed, otherwise `None`. \n\n\n\n"
    },
    "src__providers__loader__provider": {
        "label": "provider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/loader.py",
        "relativePath": "wren-ai-service/src/providers/loader.py",
        "lineNo": 45,
        "endLineNo": 72,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Floader.py%23L45-L72&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## [Quick Summary]\n\nThis function is a decorator that registers a given class as a provider with a specified name in a global `PROVIDERS` dictionary. Its purpose is to create a centralized registry of provider classes, accessible by their unique names.  \n\n## [Inputs]\n\n* **name (str):** \n    * A unique identifier (string) for the provider class.\n\n## [Output]\n\n* **Decorated class:**  The original provider class is returned, now registered in the `PROVIDERS` dictionary. \n\n\n\n"
    },
    "src__pipelines__sql_explanation__generation___compose_sql_expression_of_filter_type": {
        "label": "_compose_sql_expression_of_filter_type",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 36,
        "endLineNo": 62,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L36-L62&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick Summary:** This function recursively transforms a filter analysis object (likely representing a logical expression) into a string representing an SQL expression. It handles different filter types (\"EXPR\", \"AND\", \"OR\") and optionally returns the complete expression or only the expression's constituent parts.\n\n**Purpose:**  The code aims to generate SQL expressions from a structured representation of filter criteria, likely used in data querying or filtering applications. \n\n\n**Inputs:**\n\n* `filter_analysis`: A dictionary containing information about the filter, its type, and potentially left and right sub-filters for logical operations.\n* `top`: A boolean indicating whether to return the full SQL expression or just the individual expression parts.\n\n\n**Output:**\n\n* A dictionary with two keys:\n    * `\"values\"`:  The composed SQL expression as a string.\n    * `\"id\"`:   An optional identifier associated with the filter (if present in the input). \n"
    },
    "src__providers__embedder__azure_openai__AsyncDocumentEmbedder__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 163,
        "endLineNo": 189,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L163-L189&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** This function embeds a list of `Document` objects using an asynchronous OpenAI API call. It modifies the input documents by adding an embedding to each, and returns a dictionary containing the embedded documents and meta-data from the API. The purpose of this code is to provide document embeddings for semantic analysis or similarity search tasks.\n\n**Inputs:**\n\n* `documents`: A list of `Document` objects containing text.\n\n**Output:**\n\n* A dictionary containing:\n    * `documents`: The input list of `Document` objects, now with added `embedding` attributes.\n    * `meta`:  Metadata returned by the OpenAI API. \n\n\n"
    },
    "src__providers__embedder__azure_openai__AzureOpenAIEmbedderProvider____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 192,
        "endLineNo": 218,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L192-L218&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function initializes a class responsible for interacting with the Azure OpenAI embedding API. Its purpose is to  load and configure the necessary parameters for generating embeddings from text using the specified Azure OpenAI model.\n\n## Inputs\n\n* `embed_api_key`:  The API key for accessing the Azure OpenAI embedding service.\n* `embed_api_base`: The base URL of the Azure OpenAI embedding API.\n* `embed_api_version`: The version of the Azure OpenAI embedding API to use.\n* `embedding_model`: The name of the specific embedding model to use (e.g., \"text-embedding-ada-002\").\n* `embedding_model_dim`: The dimension of the embedding vectors to be generated.\n\n## Output\n\n*  A properly initialized object ready to generate embeddings using the Azure OpenAI service. \n\n\n"
    },
    "src__providers__embedder__openai__AsyncDocumentEmbedder__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 151,
        "endLineNo": 177,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L151-L177&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown \n\n**Quick Summary:** This function embeds a list of `Document` objects using the OpenAI API. It ensures the input is a valid list of documents, prepares the text for embedding, batches and embeds the text using `_embed_batch`, assigns the embeddings to the documents, and returns the embedded documents along with metadata from the API. This function is likely part of a system for understanding and processing document content.\n\n**Inputs:**\n\n* `documents`: A list of `Document` objects.\n* `batch_size`: An integer representing the size of batches used for embedding.\n\n**Output:**\n\n* A dictionary containing:\n    * `documents`: The original list of `Document` objects, now with their `embedding` attribute set.\n    * `meta`: Metadata returned by the OpenAI API regarding the embedding process. \n"
    },
    "src__providers__engine__wren__WrenUI__dry_run_sql": {
        "label": "dry_run_sql",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 21,
        "endLineNo": 47,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L21-L47&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick summary:** This asynchronous Python function executes a dry run of a SQL query against a GraphQL API endpoint. It aims to preview the results of the query without actually performing any data modifications.  \n\n**Inputs:**\n* `sql`: The SQL query string to be executed.\n* `session`: An aiohttp ClientSession object for making HTTP requests.\n* `project_id`: (Optional) The ID of the project to which the query belongs.\n\n**Output:**\n* A tuple containing a boolean value indicating success or failure, and an optional dictionary containing either an error message or `None` if successful. \n\n\n\n"
    },
    "src__providers__llm__azure_openai__AsyncGenerator____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/azure_openai.py",
        "lineNo": 32,
        "endLineNo": 58,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fazure_openai.py%23L32-L58&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function initializes an `AsyncGenerator` object, which is designed to interact asynchronously with an Azure OpenAI service. It leverages an API key and specified model to generate text in a streaming fashion.  \n\n## Inputs\n\n* `api_key`: Secret API key for accessing the Azure OpenAI service.\n* `model`: Name of the OpenAI model to use (e.g., \"gpt-4-turbo\").\n* `api_base`: Base URL for the Azure OpenAI API endpoint.\n* `api_version`: API version to be used.\n* `streaming_callback`: Optional function to handle streamed text responses.\n* `system_prompt`: Optional prompt to provide context to the model.\n* `generation_kwargs`: Optional dictionary with additional generation parameters.\n\n## Output\n\n* An `AsyncGenerator` object ready to be used for asynchronous text generation. \n\n\n"
    },
    "src__pipelines__ask__followup_generation__FollowUpGeneration__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/followup_generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/followup_generation.py",
        "lineNo": 194,
        "endLineNo": 219,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Ffollowup_generation.py%23L194-L219&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary**\n\nThis function visualizes the execution flow of a text-to-sql pipeline called \"followup_generation\". It generates a dot file that can be used to create a diagram showing how the pipeline processes a query, documents, and history to generate a response. The purpose is likely for debugging, understanding the pipeline's logic, or documentation.\n\n**Inputs**\n\n*   `query`: The user's text query.\n*   `contexts`: A list of `Document` objects, likely containing relevant background information for the query.\n*   `history`: `AskRequest.AskResponseDetails`, probably containing previous interactions in the conversation.\n\n\n**Output**\n\n*   A dot file named `followup_generation.dot` is created in the `outputs/pipelines/ask` directory. This file represents a visual diagram of the pipeline's execution flow."
    },
    "src__pipelines__ask__generation__Generation__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/generation.py",
        "lineNo": 154,
        "endLineNo": 179,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fgeneration.py%23L154-L179&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis of Code Snippet\n\n**Quick Summary**\n\nThis function visualizes the execution flow of a text-to-SQL pipeline using graphviz. It generates a dot file representing the steps involved in processing a query, including input documents, exclusion rules, and the various components of the pipeline (generator, prompt builder, post-processor). \n\n**Inputs**\n\n* `query`: The natural language query to be converted to SQL.\n* `contexts`: A list of documents that provide context for the query.\n* `exclude`: A list of dictionaries containing criteria to exclude certain results.\n\n**Output**\n\n* A dot file named \"generation.dot\" is generated in the \"outputs/pipelines/ask\" directory.  \n* This dot file can be used to visualize the execution flow of the text-to-SQL pipeline. \n\n\n\n"
    },
    "src__pipelines__sql_explanation__generation__Generation__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 525,
        "endLineNo": 550,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L525-L550&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:**\n\nThis function visualizes the execution flow of a SQL generation pipeline. It takes a user question and information about a pipeline step (that includes generated SQL and analysis results) and generates a DOT file representing the pipeline's steps and data flow. This visualization helps understand how the pipeline processes the question to generate SQL.\n\n**Inputs:**\n\n*  `question`: The user's query or question.\n*  `step_with_analysis_results`: A Pydantic BaseModel containing information about a specific step in the SQL generation pipeline, including:\n    * `sql`: The generated SQL query.\n    * `sql_analysis_results`: Results of analyzing the generated SQL.\n    * `summary`: A summary of the step's execution.\n\n**Output:**\n\n* `.dot` file: Depicts the pipeline's execution flow, showing steps, data flow, and inputs/outputs. \n"
    },
    "src__providers__embedder__ollama__AsyncTextEmbedder__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 42,
        "endLineNo": 66,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L42-L66&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Ollama Embedder Function Analysis:\n\n**Quick Summary:** This Python function sends text to an Ollama API endpoint to generate embeddings. It measures the processing time,  returns the embeddings, and includes metadata about the model and processing duration. The purpose is to utilize Ollama's embedding capabilities for tasks like semantic search or text similarity. \n\n**Inputs:**\n\n* `text`: The input string to be embedded.\n* `generation_kwargs`: Optional dictionary of parameters to be passed to the Ollama API.\n\n**Output:**\n\n* A dictionary containing:\n    * The generated embeddings.\n    * Metadata:\n        * `model`: The name of the Ollama model used.\n        * `duration`: The time taken for embedding generation (in seconds). \n\n\n"
    },
    "src__providers__embedder__openai__AsyncTextEmbedder____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 26,
        "endLineNo": 50,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L26-L50&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## AsyncTextEmbedder Constructor Analysis\n\n**Quick Summary:** This Python function initializes an `AsyncTextEmbedder` object, which is designed to asynchronously embed text using the OpenAI API.  It sets up a connection to the OpenAI API and prepares to receive text input for embedding.\n\n**Inputs:**\n\n* `api_key`:  A secret API key for accessing OpenAI's services.\n* `model`: The name of the OpenAI model to use for text embedding (e.g., \"text-embedding-ada-002\").\n* `dimensions`:  (Optional)  The desired dimensionality of the resulting embeddings.\n* `api_base_url`:  (Optional)  A custom base URL for the OpenAI API.\n* `organization`:  (Optional) The name of the OpenAI organization the key belongs to.\n* `prefix`:  (Optional) A string prefix to add to the input text before embedding.\n* `suffix`:  (Optional) A string suffix to add to the input text after embedding.\n\n**Output:**\n\n* An initialized `AsyncTextEmbedder` object ready to process text embeddings. \n\n\n\n"
    },
    "src__providers__llm__openai__AsyncGenerator____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/openai.py",
        "lineNo": 33,
        "endLineNo": 57,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fopenai.py%23L33-L57&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary** \n\nThis Python function initializes an asynchronous generator for interacting with the OpenAI API. It sets up communication with the OpenAI API using your provided API key and other configuration parameters, allowing you to stream conversation outputs or access other features asynchronously.\n\n**Inputs**\n\n* `api_key`: Your OpenAI API key for authentication\n* `model`: The name of the OpenAI model you want to use (e.g., \"gpt-4o-mini\")\n* `streaming_callback`: An optional function to handle streaming responses from the API\n* `api_base_url`: An optional custom base URL for the OpenAI API\n* `organization`:  Your OpenAI organization (if applicable)\n* `system_prompt`: An optional prompt to provide context to the model\n* `generation_kwargs`:  Optional keyword arguments for customizing text generation\n\n\n**Output**\n\n* An asynchronous generator object ready to be used for interacting with the OpenAI API. \n"
    },
    "src__providers__loader__get_provider": {
        "label": "get_provider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/loader.py",
        "relativePath": "wren-ai-service/src/providers/loader.py",
        "lineNo": 73,
        "endLineNo": 97,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Floader.py%23L73-L97&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Provider Retriever Function Analysis\n\n**Quick Summary:** This function retrieves a provider class by its name. It searches a dictionary `PROVIDERS` containing registered provider classes, using the input `name` as a key.\n\n**Inputs:**\n\n* `name` (str): The unique name of the desired provider class.\n\n**Output:**\n\n* Type: The provider class object corresponding to the given `name`. \n\n\n"
    },
    "src__web__v1__services__ask__AskRequest": {
        "label": "AskRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 21,
        "endLineNo": 45,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L21-L45&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines a Python class named `AskResponseDetails` to represent the details of an AI's response to a query. It structures information like the SQL query executed, a summary of the response, and a detailed explanation of the SQL steps involved.\n\n## Inputs\n\n* `query`: The original user query, presumably in natural language.\n* `project_id`:  Identifies the specific project or dataset to use for the response.\n* `mdl_hash` or `id`: Unique identifier for the specific AI model used in the response.\n* `thread_id`:  Likely a unique identifier for the conversation thread within which the query was asked.\n* `history`:  Potentially a previous `AskResponseDetails` object, indicating context from earlier interactions.\n\n## Output\n\n*  A `AskResponseDetails` object containing:\n    * `sql`: The SQL query generated by the AI to answer the user's query.\n    * `summary`: A concise summary of the AI's response.\n    * `steps`: A list of `SQLExplanation` objects, each providing detailed information about a step in the SQL query execution. \n*  The  `query_id` property, allowing identification of the specific response instance.  \n\n\n"
    },
    "src__pipelines__ask__sql_correction__SQLCorrection__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/sql_correction.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/sql_correction.py",
        "lineNo": 124,
        "endLineNo": 147,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fsql_correction.py%23L124-L147&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:**\n\nThis function visualizes the execution flow of a text-to-SQL pipeline, focusing on the \"post_process\" stage. The purpose is to create a diagram illustrating how invalid generation results are handled by the pipeline components, providing insights into the pipeline's logic and potential bottlenecks.\n\n**Inputs:**\n\n*  `contexts`: A list of `Document` objects, likely representing the context information used by the pipeline.\n*  `invalid_generation_results`: A list of dictionaries containing information about failed SQL generation attempts.\n\n**Output:**\n\n*  A .dot file named `sql_correction.dot` is generated in the `outputs/pipelines/ask` directory.\n*  This .dot file contains a visualization of the pipeline execution, specifically highlighting the \"post_process\" stage and its interactions with the invalid generation results, documents, and other pipeline components. \n\n\n"
    },
    "src__pipelines__indexing__indexing__MDLValidator": {
        "label": "MDLValidator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 64,
        "endLineNo": 87,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L64-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Analysis\n\n**Quick summary:** This function validates a Model Description Language (MDL) input, ensuring it's in valid JSON format and contains the necessary keys (`models`, `views`, `relationships`, and `metrics`). If any required keys are missing, it adds them with empty lists.  Finally, it returns the processed MDL in a dictionary format. \n\n**Inputs:**\n\n*  `mdl`:  A string representing the input MDL.\n\n**Output:**\n\n* A dictionary containing the validated MDL data, key `mdl` maps to the processed MDL as a JSON object.    \n\n\n"
    },
    "src__pipelines__indexing__indexing__DocumentCleaner__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 39,
        "endLineNo": 62,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L39-L62&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## [Quick Summary]\n\nThis function clears old documents from multiple document stores within an indexing pipeline. It aims to keep the data fresh and maintain efficient indexing performance. \n\nThe function first iterates through each document store and then clears documents based on an optional ID provided, effectively deleting documents that match the specified ID or all documents if no ID is specified.\n\n## [Inputs]\n\n*  `self._stores`: A list of document stores to be cleared. \n*  `id`: An optional string representing the ID of the documents to be cleared.\n\n\n## [Output]\n\n* `{\"mdl\": mdl}`:  A dictionary containing a value called 'mdl', likely representing the model object used in the indexing pipeline. \n"
    },
    "src__pipelines__indexing__indexing__Indexing__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 459,
        "endLineNo": 482,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L459-L482&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**[Quick Summary]**\nThis code snippet visualizes the execution flow of a pipeline, likely related to database schema and view generation. It creates a directed graph (DOT file) showing the sequence of operations within the pipeline, including data transformations and outputs. This visualization aids in understanding pipeline structure and dependencies.\n\n\n**[Inputs]**\n\n* `destination`: A string representing the directory path where the visualization output will be saved.\n* `mdl_str`:  Likely a string representing a model definition or configuration.\n* `id`: A unique identifier, possibly related to the specific pipeline instance.\n* `cleaner`: An object presumably responsible for cleaning or preprocessing input data.\n* `validator`: An object likely responsible for validating the data or schema.\n* `ddl_converter`, `ddl_embedder`, `ddl_writer`: Objects involved in converting and writing database definition language (DDL) statements.\n* `view_converter`, `view_converter`, `view_writer`: Objects involved in converting and writing database views.\n\n**[Output]**\n* `indexing.dot`:  A file in DOT format, representing a directed graph visualizing the pipeline execution flow.\n  \n\n\n\n"
    },
    "src__pipelines__sql_regeneration__generation__Generation__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 131,
        "endLineNo": 154,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L131-L154&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**Quick Summary**\n\nThis Python function visualizes the execution flow of a SQL regeneration pipeline using a DOT graph. It takes information about the pipeline's components and their interactions, along with a description and execution steps, to generate an informative diagram. The purpose is to provide a clear and concise representation of how the pipeline processes SQL queries.  \n\n**Inputs**\n\n*  `self`: Likely a reference to the class instance containing the pipeline logic and components.\n*  `description`: A textual description of the overall SQL regeneration process.\n*  `steps`: A list of SQLExplanationWithUserCorrections objects, each representing a step in the pipeline's execution.\n\n**Output**\n\n* A DOT graph file named `generation.dot` saved in the `outputs/pipelines/sql_regeneration` directory. This file can then be rendered using graph visualization tools like Graphviz to produce an image of the pipeline's execution flow. \n\n\n"
    },
    "src__providers__embedder__ollama__AsyncDocumentEmbedder____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 69,
        "endLineNo": 92,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L69-L92&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  AsyncDocumentEmbedder Initialization \n\n**Quick Summary:** \nThis function initializes a class called `AsyncDocumentEmbedder`, which is designed to asynchronously embed documents using a specified language model.  It inherits from another class (not shown), likely providing additional embedding functionalities.  The purpose of the code is to set up the necessary parameters for asynchronously embedding documents.\n\n**Inputs:**\n\n* `model`: Name of the language model to be used for embedding.\n* `url`:  API endpoint for accessing the embedding service.\n* `generation_kwargs`:  Additional keyword arguments to pass to the embedding process.\n* `timeout`:  Maximum time allowed for embedding requests.\n* `prefix`: Text to be added before the document for embedding.\n* `suffix`: Text to be added after the document for embedding.\n* `progress_bar`:  Flag indicating whether to display a progress bar during embedding.\n* `meta_fields_to_embed`: List of metadata fields to be embedded along with the document.\n* `embedding_separator`: Separator used between embedded components (e.g., document and metadata).\n\n**Output:**\n\n*  An initialized `AsyncDocumentEmbedder` object, ready to handle asynchronous document embedding requests.\n\n\n\n"
    },
    "src__providers__llm__azure_openai__AzureOpenAILLMProvider____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/azure_openai.py",
        "lineNo": 119,
        "endLineNo": 142,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fazure_openai.py%23L119-L142&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThe function initializes an Azure OpenAI client, setting up the necessary parameters for interacting with the Azure OpenAI API. It's likely part of a larger application that leverages AI models for tasks such as text generation.  \n\n## Inputs\n\n* `chat_api_key`: An API key for authenticating with the Azure OpenAI service.\n* `chat_api_base`: The base URL for the API endpoint.\n* `chat_api_version`: The specific version of the API to use.\n* `generation_model`:  The name of the desired OpenAI model for text generation.\n* `model_kwargs`: Additional keyword arguments specific to the chosen model, potentially including parameters for fine-tuning or customization.\n\n## Outputs\n\n* An initialized Azure OpenAI client object, ready to be used for interacting with the API.\n\n\n"
    },
    "src__utils__CustomFormatter": {
        "label": "CustomFormatter",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 20,
        "endLineNo": 43,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L20-L43&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function customizes the formatting of log messages based on their severity level. It uses ANSI escape codes to color-code different log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL) for improved readability.\n\n## Inputs\n\n* `record`: A logging record object containing information about the log message, such as its level, timestamp, message content, and filename/line number.\n\n* `self.FORMATS`: A dictionary mapping log levels to formatted strings containing ANSI escape codes for colorization and the desired log message template.\n\n## Output\n\n* A formatted string containing the log message with specific colorization based on its severity level.\n\n\n\n"
    },
    "src__utils__async_timer": {
        "label": "async_timer",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 100,
        "endLineNo": 123,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L100-L123&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**Quick Summary:** This code defines a decorator `wrapper_timer` that measures the execution time of an asynchronous function (`func`). It logs the elapsed time if the environment variable `ENABLE_TIMER` is set to `True`, otherwise it simply executes the function normally. \n\n**Inputs:**\n*  `func`: The asynchronous function to be decorated.\n*  `*args`: Positional arguments to pass to the function.\n*  `**kwargs`: Keyword arguments to pass to the function.\n\n**Output:** \n* The result returned by the decorated function (`func`). \n* A log message containing the function name and execution time (if `ENABLE_TIMER` is `True`). \n\n\n"
    },
    "src__utils__trace_metadata__wrapper": {
        "label": "wrapper",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 176,
        "endLineNo": 199,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L176-L199&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Breakdown of the Code Snippet\n\n**Quick Summary:** This function executes a given function (`func`) with provided arguments and keyword arguments. It then extracts metadata from the input arguments and combines it with metadata potentially returned by `func` to build a comprehensive metadata object for LangFuse context. Finally, it updates the LangFuse trace with this metadata. \n\nThe purpose is to properly capture and track information about the executed function call within the LangFuse framework.\n\n**Inputs:**\n\n* `func`: The function to be executed.\n* `*args`: Positional arguments to be passed to the function.\n* `**kwargs`: Keyword arguments to be passed to the function.\n* `extract`: A function that extracts metadata from the input arguments.\n\n**Output:**\n\n* Returns the result of the executed function (`results`).\n* Updates the LangFuse context with a enriched metadata object (`langfuse_metadata`).  \n"
    },
    "src__pipelines__ask__followup_generation__FollowUpGeneration__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/followup_generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/followup_generation.py",
        "lineNo": 222,
        "endLineNo": 244,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Ffollowup_generation.py%23L222-L244&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown \n\n**Quick Summary:**\n\nThis function processes a follow-up question (`query`) given a set of relevant documents (`contexts`), previous conversation history (`history`), and optional project ID. It utilizes various components like a generator, prompt builder, and post-processor to generate a suitable response. \n\n**Inputs:**\n\n*  `query`: The follow-up question to be answered.\n*  `contexts`: A list of documents containing relevant information.\n*  `history`:  Previous conversation details to provide context.\n*  `project_id`:  An optional identifier for the project.\n\n**Output:**\n\n*  A generated response to the follow-up question. \n\n\n\n"
    },
    "src__pipelines__ask__generation__Generation__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/generation.py",
        "lineNo": 182,
        "endLineNo": 204,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fgeneration.py%23L182-L204&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**[Quick summary]** \nThis function executes a pipeline for generating SQL queries from natural language text.  It processes a given query, a list of relevant documents, and exclusion rules, ultimately producing a SQL query. This code likely serves as part of a larger application that aims to translate user questions into database queries.\n\n**[Inputs]**\n\n* `query`: A string containing the natural language question or request.\n* `contexts`: A list of `Document` objects, likely containing relevant information to help answer the query.\n* `exclude`:  A list of dictionaries specifying information to exclude from the generated SQL query.\n* `project_id`: An optional string identifying the project associated with the query.\n\n**[Output]**\n\n* A generated SQL query string. \n\n\n\n"
    },
    "src__pipelines__indexing__indexing__DDLConverter__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 136,
        "endLineNo": 158,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L136-L158&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick summary]** This function takes a model definition (mdl) and generates a list of Data Definition Language (DDL) commands. It then structures this  list into a format suitable for indexing these commands into a storage system, likely a document store.  The purpose is to efficiently store and retrieve DDL commands associated with a particular model. \n\n**[Inputs]**\n\n* **mdl:**  Likely a dictionary or object representing the definition of a model. \n\n* **id:**  An optional identifier potentially associated with the model or the DDL commands.\n\n*  **logger:**  A logging object to record messages at different levels (info, debug). \n    \n**[Output]**\n\n* A dictionary containing:\n    * **documents:** A list of Document objects.\n    * Each Document object has:\n        * **id:** A unique identifier for the document (likely an index).\n        * **meta:** A dictionary containing metadata, optionally including the 'id' from the input.\n        * **content:** The corresponding DDL command. \n\n\n\n\n"
    },
    "src__providers__engine__wren__WrenEngine__dry_run_sql": {
        "label": "dry_run_sql",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 94,
        "endLineNo": 116,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L94-L116&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**\n\nThis asynchronous function sends a SQL query to a system for a dry-run evaluation. It extracts a manifest from environment variables and API responses related to the query, and checks for successful execution by returning a boolean and a potential error message. It aims to assess the validity and potential impact of a SQL query before actual execution. \n\n**Inputs:**\n\n* `sql`: The SQL query string to be evaluated.\n* `session`: An aiohttp.ClientSession object for making API requests.\n* `properties`: A dictionary of properties, likely containing metadata about the query, with a key \"manifest\" pointing to a base64 encoded manifest string.\n* `kwargs`: Additional keyword arguments, purpose not clear from the snippet.\n\n**Output:**\n\n* A tuple containing:\n    * A boolean value: `True` if the dry-run execution was successful, `False` otherwise.\n    * An optional dictionary containing an error message if the dry-run failed.  \n"
    },
    "src__pipelines__ask__historical_question__OutputFormatter": {
        "label": "OutputFormatter",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 37,
        "endLineNo": 58,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L37-L58&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function, named `run`, processes a list of documents containing question-answer information. It extracts specific fields (question, summary, statement, viewId) from each document and formats them into a list of dictionaries. This formatted data is likely intended for further processing or display.\n\n\n## Inputs\n- `documents`: A list of `Document` objects.\n    - Each `Document` presumably contains a \"content\" attribute which holds structured data (likely a dictionary)\n\n## Output \n- A dictionary with a single key \"documents\".\n- The \"documents\" value is a list of dictionaries, where each dictionary represents a formatted document with fields: \"question\", \"summary\", \"statement\", \"viewId\" \n"
    },
    "src__pipelines__ask__historical_question__HistoricalQuestion__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 114,
        "endLineNo": 135,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L114-L135&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**Quick Summary:**\n\nThis function visualizes the execution pipeline of a question-answering system. It takes a user query as input, generates a diagram representing the flow of information through embedding, retrieval, scoring, and formatting stages, and saves it as a DOT file.  The purpose is to provide a clear visual representation of how the system processes a query to generate a response. \n\n**Inputs:**\n\n* `query: str`:  The user's question or query.\n \n* `self._pipe`: This likely refers to an instance of a pipeline object, encapsulating the entire question-answering process.\n* `self._embedder`:  An object responsible for converting the query into a numerical representation.\n* `self._retriever`:  An object that retrieves relevant documents from a knowledge base based on the query embedding.\n* `self._score_filter`:  An object used to rank retrieved documents by relevance.\n* `self._output_formatter`: An object responsible for formatting the final response from the selected documents.\n\n\n**Output:**\n\n* A DOT file named \"historical_question.dot\" is saved in the \"outputs/pipelines/ask\" directory, representing the visualized execution pipeline. \n"
    },
    "src__pipelines__ask__retrieval__Retrieval__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/retrieval.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/retrieval.py",
        "lineNo": 62,
        "endLineNo": 83,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fretrieval.py%23L62-L83&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary**\n\nThis function visualizes the execution of a retrieval pipeline within a larger system. It generates a flowchart diagram showcasing the data flow and components involved in retrieving relevant information based on a given query. The purpose is to provide a visual understanding of how the pipeline works.\n\n**Inputs**\n\n*  `query`: A string representing the user's search query.\n*  `id`: An optional string, potentially used for identifying a specific instance or document within the retrieval process.\n\n**Output**\n\n*  A DOT file (format `retrieval.dot`) located in the `outputs/pipelines/ask` directory, representing a flowchart visualization of the retrieval pipeline execution.  \n"
    },
    "src__pipelines__sql_explanation__generation__Generation__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 553,
        "endLineNo": 574,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L553-L574&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:**\nThis function generates an SQL explanation for a given question based on existing SQL code and analysis results. It leverages a pipeline of components (`pre_processor`, `prompt_builder`, `generator`, `post_processor`) to process the input and produce the final explanation. The purpose is to provide human-understandable insights into the generated SQL query.\n\n**Inputs:**\n\n* `question`: The natural language question prompting the SQL generation.\n* `step_with_analysis_result`:  A data structure containing:\n    * `sql`: The generated SQL code.\n    * `sql_analysis_results`:  Analysis data related to the SQL code (e.g., explain plan, schema information).\n    * `summary`: A condensed description of the SQL query's functionality.\n    * Additional fields for pre-processor, prompt_builder, generator, and post-processor configurations.\n\n**Output:**\n\n* A formatted SQL explanation string generated by the pipeline. \n\n\n\n"
    },
    "src__providers__llm__ollama__AsyncGenerator____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 26,
        "endLineNo": 47,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L26-L47&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis code defines an `AsyncGenerator` class, which inherits from another class. It's designed to asynchronously generate text using a language model. The parameters allow customization of the model, API endpoint, generation settings, and behavior.  \n\n[Inputs]\n- `model`: The name or identifier of the language model to use (e.g., \"orca-mini\").\n- `url`: The URL of the API endpoint for interacting with the model.\n- `generation_kwargs`: Optional keyword arguments to pass to the model's generation function.\n- `system_prompt`:  An optional system-level prompt to provide context to the model.\n- `template`:  An optional template to structure the generated output.\n- `raw`: A boolean indicating whether to return raw model output or processed text.\n- `timeout`:  The maximum time (in seconds) to wait for a response from the API.\n- `streaming_callback`:  An optional function to handle streaming output from the model.\n\n[Output]\n- Asynchronously generated text from the specified language model.\n- Potentially raw model output if the `raw` flag is set to `True`. \n\n\n"
    },
    "src__utils__service_metadata": {
        "label": "service_metadata",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 207,
        "endLineNo": 228,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L207-L228&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function initializes a service by loading metadata about the generation and embedding models, determining the service version, and logging the version information. It appears to be part of a setup process for a service that uses both text generation and embedding capabilities. \n\n## Inputs\n\n* `llm_provider`:  An object presumably responsible for providing access to the text generation model.\n* `embedder_provider`: An object responsible for providing access to the embedding model.\n* `_`: Used as a placeholder to accept any additional positional arguments that might be needed (though not explicitly defined).\n* `pyproject_path`: A string specifying the path to a \"pyproject.toml\" file containing project metadata. \n\n## Output\n\n* `MODELS_METADATA`:  A dictionary containing information about the generation and embedding models, including their types, parameters, and embedding dimensions. \n* `SERVICE_VERSION`: A string representing the version of the service, derived from the `pyproject.toml` file. \n"
    },
    "src__web__v1__services__ask__remove_duplicates": {
        "label": "remove_duplicates",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 330,
        "endLineNo": 351,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L330-L351&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**[Quick Summary]**\nThis function removes duplicate dictionaries from a list based on the unique combination of 'sql' and 'summary' values within each dictionary. It achieves this by converting each dictionary into a tuple representing these values, using a set to track seen combinations, and appending only unique dictionaries to a new list.\n\nThis is useful for cleaning data and ensuring that each unique 'sql' and 'summary' pairing appears only once in a dataset.\n\n**[Inputs]**\n* `dicts`: A list containing dictionaries as its elements.\n\n**[Output]**\n* A new list of dictionaries, containing only unique entries based on the 'sql' and 'summary' fields.  \n\n\n"
    },
    "src__pipelines__ask__sql_correction__SQLCorrection__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/sql_correction.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/sql_correction.py",
        "lineNo": 150,
        "endLineNo": 170,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fsql_correction.py%23L150-L170&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function, designed for a machine learning pipeline, takes SQL query results that may require corrections and associated context documents.  It then uses a series of processing steps to analyze and potentially fix these input queries, aiming to produce accurate SQL statements.\n\n## Inputs:\n\n* `contexts`: A list of `Document` objects, likely containing relevant information about the data and the queries.\n\n* `invalid_generation_results`: A list of dictionaries, each representing an erroneous SQL generation result and potentially containing details about the problem.\n* `project_id`: A string identifying the project or context in which this processing takes place. Optional.\n\n## Output: \n\n* A processed result (likely from the `post_process` step) that potentially contains corrected SQL queries or information about the correction process. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation__post_process": {
        "label": "post_process",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 486,
        "endLineNo": 506,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L486-L506&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function processes generated content and SQL analysis results using a defined post-processor. It takes generated outputs and preprocessed SQL analysis results as input and returns a processed result. The purpose is likely to refine and integrate the generated content with the understanding of the underlying SQL data.\n\n## Inputs\n\n* `generates`: A list of dictionaries, potentially containing the generated text content.\n* `preprocess`: A dictionary holding preprocessed results from a SQL analysis.\n* `post_processor`: An object of a class `GenerationPostProcessor`, responsible for applying specific processing logic.\n\n## Output\n\n* A dictionary containing the processed result generated by the `GenerationPostProcessor`. \n\n\n\n"
    },
    "src__pipelines__sql_regeneration__generation__Generation__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 157,
        "endLineNo": 177,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L157-L177&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "```python\n        self,\n        description: str,\n        steps: List[SQLExplanationWithUserCorrections],\n        project_id: str | None = None,\n    ):\n        logger.info(\"SQL Regeneration Generation pipeline is running...\")\n        return await self._pipe.execute(\n            [\"sql_regeneration_post_process\"],\n            inputs={\n                \"description\": description,\n                \"steps\": steps,\n                \"sql_regeneration_preprocesser\": self.sql_regeneration_preprocesser,\n                \"sql_regeneration_prompt_builder\": self.sql_regeneration_prompt_builder,\n                \"sql_regeneration_generator\": self.sql_regeneration_generator,\n                \"sql_regeneration_post_processor\": self.sql_regeneration_post_processor,\n                \"project_id\": project_id,\n            },\n        )\n```\n\n**Quick Summary**\n\nThis function is part of a pipeline designed for regenerating SQL queries. \n\nIt takes in pre-processed information about SQL steps and user corrections, along with a description, and uses a series of components to generate a revised SQL query. The `project_id` is likely used for context or tracking.\n\n**Inputs**\n\n*  `description`: A textual description of the desired outcome or context for the SQL query.\n*  `steps`: A list of `SQLExplanationWithUserCorrections` objects, representing individual steps in the SQL query process with potential user-made corrections.\n* `project_id`: An identifier for the project associated with the SQL query.\n\n**Output**\n\n* A newly generated SQL query string. \n\n\n"
    },
    "src__providers__engine__wren__WrenIbis__dry_run_sql": {
        "label": "dry_run_sql",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 67,
        "endLineNo": 87,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L67-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n** Quick Summary:** This function attempts to execute a SQL query against a data source in a dry-run fashion. It checks for a successful dry-run using an HTTP POST request, and returns a boolean indicating success and optionally an error message if the dry-run fails.\n\n** Inputs:**\n\n* `sql`: The SQL query string to be executed.\n* `session`: An aiohttp ClientSession object used to make HTTP requests.\n* `_endpoint`: Internal variable likely representing the base URL for the API. \n* `_source`: Internal variable likely representing the name of the data source.\n* `_manifest`: Internal variable likely containing metadata about the data source.\n* `_connection_info`: Internal variable likely containing connection details for the data source.\n* `**kwargs`:  Additional keyword arguments, potentially for customization.\n\n** Output:**\n* `bool`: `True` if the dry-run was successful, `False` otherwise.\n* `Optional[Dict[str, Any]]`:  `None` if the dry-run was successful, otherwise a dictionary containing potential error information from the server's response.  \n\n\n\n\n"
    },
    "src__providers__embedder__ollama__OllamaEmbedderProvider____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 162,
        "endLineNo": 181,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L162-L181&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Summary\n\nThis function initializes an Ollama embedding model by fetching it from a specified URL and setting its dimensions. It logs the chosen model and URL for information purposes. The overall purpose of this code is to configure and prepare an Ollama embedding model for use in a downstream application.\n\n## Inputs\n\n* `url`:  The URL where the Ollama embedding model is hosted.\n* `embedding_model`: The name or identifier of the desired Ollama embedding model.\n* `embedding_model_dim`: The dimensionality of the embedding vectors generated by the model.\n\n\n## Output\n\n* A configured and ready-to-use Ollama embedding model object. \n* Logging messages indicating the chosen model and its URL. \n\n\n\n\n"
    },
    "src__providers__llm__openai__OpenAILLMProvider__get_generator": {
        "label": "get_generator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/openai.py",
        "lineNo": 149,
        "endLineNo": 168,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fopenai.py%23L149-L168&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:** This function creates an asynchronous generator for text generation using an OpenAI API or a compatible API. It initializes the generator with the specified API key, base URL, model, system prompt, and generation parameters. The purpose is to provide an object for streamlined and asynchronous text generation.\n\n\n**Inputs:**\n\n*  `system_prompt: Optional[str] = None` : A prompt that sets the context and instructions for the generator.\n\n\n**Output:**\n\n*  An `AsyncGenerator` object ready for text generation. \n"
    },
    "src__utils__timer": {
        "label": "timer",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 80,
        "endLineNo": 99,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L80-L99&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function is a decorator that adds timing functionality to any decorated function. It measures the execution time of a function if the environment variable \"ENABLE_TIMER\" is set to True.  Otherwise, it simply calls the original function without timing.\n\n## Inputs\n\n* `func`: The function to be decorated.\n* `*args`: Positional arguments passed to the decorated function.\n* `**kwargs`: Keyword arguments passed to the decorated function.\n\n## Output\n\n*  If \"ENABLE_TIMER\" is True:\n    * Executes the decorated function.\n    * Logs the elapsed time taken by the function along with its name.\n    * Returns the result of the decorated function.\n* If \"ENABLE_TIMER\" is False:\n    * Executes the decorated function without timing.\n    * Returns the result of the decorated function. \n\n\n\n\n"
    },
    "src__web__v1__services__ask__AskResultResponse": {
        "label": "AskResultResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 73,
        "endLineNo": 92,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L73-L92&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis code defines the structure of a response object for an AI system that answers questions based on data. It includes the status of the query processing and possible results or errors. \n\n## Inputs\n\n* **Not Explicit:**  There isn't direct \"input\" definition within this code snippet. \n\nThis structure likely represents the output **of** a function that processes a user query, not the input it takes.\n\n## Output\n\n* **status:**  A string indicating the current stage of the query processing (e.g., \"searching\", \"finished\").\n* **response:** (Optional) A list of `AskResult` objects, each containing the SQL query used and a summary of the answer.\n* **error:** (Optional) An `AskError` object detailing any issues encountered during processing.  \n\n\n"
    },
    "src__web__v1__services__indexing__IndexingService__get_prepare_semantics_status": {
        "label": "get_prepare_semantics_status",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 90,
        "endLineNo": 109,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L90-L109&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**Quick Summary:** This function retrieves the status of a semantics preparation task based on its unique identifier (MDL hash). If the task is found, it returns the preparation status. Otherwise, it returns an error indicating the task was not found. \n\nThe code is likely part of a system that manages the preparation of semantic models (e.g., for natural language understanding).\n\n**Inputs:**\n\n*  `prepare_semantics_status_request`: An object containing the `mdl_hash`, which is the unique identifier of the semantics preparation task.\n\n**Output:**\n\n* `SemanticsPreparationStatusResponse`:  An object containing:\n    * `status`: Either \"failed\" (if the task was not found) or the actual status of the preparation task.\n    * `error`: An object containing error information if the status is \"failed\". \n       * `code`:  A code indicating the type of error.\n       * `message`: A human-readable description of the error. \n\n\n\n"
    },
    "src__pipelines__ask__generation__prompt": {
        "label": "prompt",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/generation.py",
        "lineNo": 96,
        "endLineNo": 114,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fgeneration.py%23L96-L114&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:** This function prepares a query and related data for processing by a `PromptBuilder` object. The purpose is likely to construct prompts for a language model to answer questions based on provided documents while excluding specific information.\n\n**Inputs:**\n\n* `query`: The user's question or request.\n* `documents`: A list of documents relevant to the query.\n* `exclude`: A list of dictionaries, potentially containing keywords or IDs to be excluded from the prompt.\n* `alert`: A string, possibly indicating an alert or specific context for the query.\n* `prompt_builder`: An object responsible for generating the final prompt for the language model.\n\n**Output:**\n\n* A dictionary containing the generated prompt, likely formatted for use with a language model. \n\n\n"
    },
    "src__pipelines__ask__sql_correction__prompt": {
        "label": "prompt",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/sql_correction.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/sql_correction.py",
        "lineNo": 64,
        "endLineNo": 82,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fsql_correction.py%23L64-L82&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown \n\n**[Quick Summary]** \nThis function takes a list of documents, some flagged invalid generation results, an alert message, and a `PromptBuilder` object. It then utilizes the `PromptBuilder` to process this information, likely for the purpose of refining or adapting prompts for further text generation tasks.  \n\n**[Inputs]**\n\n* `documents`: A list of documents, possibly containing text data relevant to the generation process.\n* `invalid_generation_results`: A list of dictionaries, likely containing information about previously generated text that was deemed unsatisfactory.\n* `alert`: A string message, potentially indicating an issue or providing context for the processing.\n* `prompt_builder`: An object responsible for constructing or modifying prompts used in text generation.\n\n**[Output]**\n\n* A dictionary, potentially containing modified or generated prompts, or other results based on the `PromptBuilder`'s logic.  \n\n\n"
    },
    "src__pipelines__indexing__indexing__Indexing__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 485,
        "endLineNo": 503,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L485-L503&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary:**\n\nThis function orchestrates a document indexing pipeline using a modular approach. It utilizes various components (`cleaner`, `validator`, `converter`, `embedder`, `writer`) to process a document described by `mdl_str` and `id`. The purpose is to generate and store database schema (DDL) and materialized views based on the document.\n\n**Inputs:**\n\n* **mdl_str:** likely a string representing the metadata or structure of the document.\n* **id:**  a unique identifier for the document.\n* **cleaner:** Function/object responsible for cleaning and preprocessing the document data.\n* **validator:**  Function/object responsible for validating the document's structure and content.\n* **ddl_converter:** Function/object that converts document information into DDL statements.\n* **ddl_embedder:** Function/object that embeds DDL statements into a specific format (e.g., for storage).\n* **ddl_writer:** Function/object that writes the DDL statements to a database.\n* **view_converter:** Function/object that converts document information into materialized view definitions.\n* **view_embedder:** Function/object that embeds materialized view definitions into a specific format.\n* **view_writer:** Function/object that writes the materialized view definitions to the database.\n* **self._pipe:** Object representing the document indexing pipeline itself. \n\n**Output:**\n\n*  A result or status message from the execution of the document indexing pipeline. \n\n\n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantEmbeddingRetriever__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 309,
        "endLineNo": 327,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L309-L327&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function performs semantic search by querying a document store using an embedding. It retrieves documents most similar to the given query embedding, optionally applying filters, limiting the number of results, scaling scores, and optionally returning the embeddings themselves. The purpose is to efficiently search for relevant documents based on their semantic meaning rather than exact keyword matches.\n\n## Inputs\n\n* **query_embedding:** A list of floats representing the embedding of the query.\n* **filters:** An optional dictionary of filters to narrow down the search results.\n* **top_k:**  An optional integer specifying the maximum number of results to return.\n* **scale_score:** An optional boolean indicating whether to scale the similarity scores.\n* **return_embedding:** An optional boolean indicating whether to return the document embeddings along with the results.\n\n## Output\n\n* **documents:** A list of documents, each containing the necessary information extracted from the retrieved documents. \n\n\n"
    },
    "src__providers__llm__ollama__OllamaLLMProvider____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 125,
        "endLineNo": 143,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L125-L143&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis Python function initializes a connection with an Ollama language model. It downloads the specified model from the given URL and sets up the necessary parameters for using it. The purpose is to provide a straightforward way to integrate Ollama's capabilities into other applications.\n\n## Inputs\n\n* `url`:  The URL where the Ollama model is hosted (defaults to a predefined environment variable).\n* `generation_model`:  The name of the specific Ollama model to use (defaults to a predefined environment variable).\n* `model_kwargs`:  Additional keyword arguments for configuring the model (defaults to a predefined dictionary or an environment variable).\n\n## Output\n\n*  Successfully initializes the Ollama language model for use.\n* Logs information about the model and URL being used.  \n\n\n\n"
    },
    "src__web__v1__routers__ask_details": {
        "label": "ask_details",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 107,
        "endLineNo": 125,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L107-L125&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis:\n\n**Quick Summary:** \nThis function initiates a background task to retrieve details based on an `AskDetailsRequest` object. It assigns a unique query ID, stores a placeholder result indicating that the request is being understood, and schedules the `ask_details` method to process the request asynchronously.\n\n**Inputs:**\n\n* `ask_details_request`: An object containing the details request (likely including the type of details needed, relevant context, etc.).\n* `background_tasks`: An object responsible for managing background tasks (potentially a task queue or scheduler).\n\n**Output:**\n\n*  `AskDetailsResponse`:  A response object including a unique `query_id` that can be used to track the progress or result of the background task. \n\n\n\n\nLet me know if you'd like a deeper dive into any specific aspect of the code! \n"
    },
    "src__web__v1__services__ask__AskService__get_ask_result": {
        "label": "get_ask_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 311,
        "endLineNo": 329,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L311-L329&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick summary:** This Python function retrieves an AskResult from a cache (`self._ask_results`) based on a provided query ID. If the query ID is not found in the cache, it returns an error response.  The purpose is likely to efficiently handle result retrieval for previously asked questions.\n\n**Inputs:**\n\n* `ask_result_request`: An object containing information about the requested result, specifically the `query_id`.\n\n**Output:**\n\n* `AskResultResponse`: \n    * A successful response containing the retrieved AskResult if the query ID is found in the cache.\n    * An error response with a `status` of \"failed\" and a specific `AskError` indicating the query ID was not found if the query ID is not present in the cache. \n\n\n"
    },
    "src__web__v1__services__ask_details__AskDetailsService__get_ask_details_result": {
        "label": "get_ask_details_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 143,
        "endLineNo": 161,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L143-L161&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\n\nThis function retrieves a previously stored result from a cache based on a query ID. It checks if a result exists for the provided query ID in a `_ask_details_results` cache. If found, it returns the result as a `AskDetailsResultResponse`. If not found, it returns an error response indicating the query ID was not found.\n\n[Inputs]\n\n* `ask_details_result_request`: Likely a request object containing the `query_id` used to identify the result to be retrieved from the cache.\n\n[Output]\n\n* `AskDetailsResultResponse`: This response could contain:\n    * `status`:  A success or failure status.\n    * `error`:  An error object containing code and message if the retrieval failed.\n    * The actual result data if the retrieval was successful.\n"
    },
    "src__pipelines__ask__historical_question__OutputFormatter__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 41,
        "endLineNo": 58,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L41-L58&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary:** This Python function processes a list of documents, extracts specific information (question, summary, statement, viewId) from each document, and formats it into a standardized output structure. \n\nThe purpose of this code is likely to prepare historical question-answering data for further processing or analysis, ensuring a consistent and structured format for representation.\n\n**Inputs:**\n\n* `documents`: A list of documents, where each document likely contains a dictionary-like structure with fields like \"question\", \"summary\", \"statement\", and \"viewId\".\n\n**Output:**\n\n* A dictionary with a \"documents\" key containing a list of dictionaries. \n* Each dictionary in the list represents a formatted document with the extracted \"question\", \"summary\", \"statement\", and \"viewId\". \n\n\n\n"
    },
    "src__pipelines__ask_details__generation__Generation__visualize": {
        "label": "visualize",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask_details/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask_details/generation.py",
        "lineNo": 96,
        "endLineNo": 113,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask_details%2Fgeneration.py%23L96-L113&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary** This function visualizes the execution flow of a pipelined process (`self._pipe`). It generates a DOT file (`generation.dot`) depicting the pipeline's components (like \"post_process\") and their relationships, highlighting how data flows between them. This visualization aids in understanding the pipeline's logic and debugging. \n\n**Inputs**\n\n* `sql`: Likely the input SQL query processed by the pipeline.\n* `generator`: An object responsible for generating some output based on the input (e.g., a text generation model).\n* `prompt_builder`: An object that constructs prompts for the generator.\n* `post_processor`: An object that processes the generator's output, potentially refining or transforming it.\n\n**Output**\n\n* `generation.dot`: A DOT file containing a visual representation of the pipeline execution. \n\n\n\n"
    },
    "src__pipelines__indexing__indexing__DocumentCleaner__run___clear_documents": {
        "label": "_clear_documents",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 40,
        "endLineNo": 57,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L40-L57&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis\n\n**Quick Summary:**\n\nThis function deletes documents from a document store. It accepts an optional document ID as input and deletes all documents matching that ID or all documents if no ID is provided.\n\n**Inputs:**\n\n*  `store`:  A DocumentStore object, representing the database where documents are stored.\n*  `id`: An optional string representing the ID of a specific document to delete.\n\n**Output:** \n\n* This function does not explicitly return a value. \n* It performs the action of deleting documents from the store. \n\n\n"
    },
    "src__pipelines__indexing__indexing__MDLValidator__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 70,
        "endLineNo": 87,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L70-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis Python function parses a JSON string (`mdl`) representing a model definition. It ensures the JSON structure includes necessary sections for models, views, relationships, and metrics, and returns a dictionary containing the processed JSON.\n\n## Inputs\n\n* `mdl`: A JSON string representing a model definition.\n\n## Output\n\n* A dictionary with a key `\"mdl\"` containing the processed JSON model definition. \n\n\n\n\n"
    },
    "src__pipelines__sql_regeneration__generation__SQLRegenerationRreprocesser": {
        "label": "SQLRegenerationRreprocesser",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 36,
        "endLineNo": 53,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L36-L53&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function `run`  takes a description and a list of SQL explanation steps (potentially with user corrections) as input. It returns a dictionary containing the description and the list of steps. This function likely serves as a component within a larger pipeline for SQL query debugging or explanation, encapsulating the storage and retrieval of relevant information. \n\n## Inputs\n* `description`: A string providing context or a summary of the situation.\n* `steps`: A list of  `SQLExplanationWithUserCorrections` objects. Each object likely represents a step in the SQL query explanation process, potentially including user-provided corrections to the explanation. \n\n## Output\n*  A dictionary with a \"results\" key. \n* The \"results\" value is another dictionary containing:\n    * `\"description\"`:  The input `description` string.\n    * `\"steps\"`: The input `steps` list. \n"
    },
    "src__pipelines__sql_regeneration__generation__Generation____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 113,
        "endLineNo": 130,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L113-L130&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown\n\n**Quick Summary:** This code initializes a new instance of a class designed for SQL regeneration. It sets up components for preprocessing, prompt building, generation using a large language model (LLM), and post-processing the generated SQL. The overall purpose is to leverage an LLM to help rewrite or reformulate existing SQL queries.\n\n**Inputs:**\n\n* `llm_provider: LLMProvider`: An object responsible for providing access to the LLM to be used for SQL regeneration.\n* `engine: Engine`: An object likely representing the database engine or environment where the generated SQL will be executed.\n\n**Output:**\n\n* A new instance of the SQL regeneration class is created and ready to process SQL queries. \n\n\nLet me know if you'd like me to elaborate on any specific aspect!"
    },
    "src__providers__llm__ollama__AsyncGenerator___create_json_payload": {
        "label": "_create_json_payload",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 74,
        "endLineNo": 91,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L74-L91&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary:** This function constructs a dictionary of arguments for a POST request sent to an Ollama AI service. It takes a user prompt, indicates whether the response should be streamed, and optionally allows customization of generation parameters.\n\n**Inputs:**\n* `prompt`: The user's input text for the AI to process.\n* `stream`: A boolean indicating whether the AI's response should be sent in a stream format.\n* `generation_kwargs`: A dictionary containing optional parameters to influence the AI's generation process.\n\n**Output:**\n* A dictionary containing formatted JSON arguments for the Ollama API request.   \n\n\n"
    },
    "src__utils__init_providers": {
        "label": "init_providers",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 62,
        "endLineNo": 79,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L62-L79&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:**  This function initializes and returns four key components for a language model application: a Language Model Provider, an Embedder Provider, a Document Store Provider, and an Engine. It aims to set up the infrastructure for question answering or other tasks involving large language models and external data. \n\n**Inputs:**\n\n*  `engine_config`:  An object configuring the type and parameters of the engine used for processing.\n* `os.getenv(\"LLM_PROVIDER\", \"openai_llm\")`: An environment variable determining the type of Language Model Provider to use (defaults to \"openai_llm\").\n* `os.getenv(\"EMBEDDER_PROVIDER\", \"openai_embedder\")`: An environment variable determining the type of Embedder Provider to use (defaults to \"openai_embedder\").\n* `os.getenv(\"DOCUMENT_STORE_PROVIDER\", \"qdrant\")`: An environment variable determining the type of Document Store Provider to use (defaults to \"qdrant\"). \n* `loader`: An object likely responsible for loading and instantiating different provider modules.\n\n**Output:**\n\n* `llm_provider`: A configured instance of the chosen Language Model Provider.\n* `embedder_provider`:  A configured instance of the chosen Embedder Provider.\n* `document_store_provider`: A configured instance of the chosen Document Store Provider.\n* `engine`: A configured instance of the chosen Engine based on the `engine_config`. \n\n\n"
    },
    "src__web__v1__services__ask_details__AskDetailsRequest": {
        "label": "AskDetailsRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 21,
        "endLineNo": 38,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L21-L38&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**Quick Summary**\n\nThis Python code defines a class likely representing a query record. It stores information about a query, including its identifier, text, SQL equivalent, summary, and optional metadata like model hash, thread ID, and project ID. The purpose is likely to manage and structure data related to SQL queries within a system.\n\n**Inputs**\n\n* `_query_id`:  Internal unique identifier for the query (string).\n* `query`: Textual representation of the user's query (string).\n* `sql`: SQL statement equivalent to the user's query (string).\n* `summary`:  Short description or summary of the query (string).\n* `mdl_hash`: Optional hash identifying the machine learning model used (string).\n* `thread_id`: Optional identifier for the thread where the query originated (string).\n* `project_id`: Optional identifier for the project associated with the query (string).\n\n**Output**\n\n* `query_id`:  Returns the internal query identifier as a string. \n\n\n"
    },
    "src____main____lifespan": {
        "label": "lifespan",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/__main__.py",
        "relativePath": "wren-ai-service/src/__main__.py",
        "lineNo": 34,
        "endLineNo": 50,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2F__main__.py%23L34-L50&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let me break down that code snippet.\n\n**Quick Summary**\n\nThis Python function appears to manage the lifecycle of a LangFuse application. It initializes providers, sets up global variables, and inits LangFuse,  likely related to a containerized setup. During shutdown, it flushes any pending context from the LangFuse system. \n\n**Inputs**\n\n* `engine_config`: An object defining the engine configuration, possibly specifying a backend provider based on the `ENGINE` environment variable.\n* `should_force_deploy`: A boolean flag determined by the value of the `SHOULD_FORCE_DEPLOY` environment variable, likely controlling whether to forcibly redeploy components during initialization.\n\n**Output**\n\n* No explicit output is defined in this code snippet.\n* The function likely manipulates application state behind the scenes, managing initialization and cleanup for LangFuse. \n\n\nLet me know if you'd like a deeper dive into specific parts or have more code to analyze!\n"
    },
    "src__pipelines__ask__followup_generation__prompt": {
        "label": "prompt",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/followup_generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/followup_generation.py",
        "lineNo": 136,
        "endLineNo": 152,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Ffollowup_generation.py%23L136-L152&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick summary]**\n\nThis Python function processes a user query alongside relevant documents and previous interactions (history) to generate a prompt for a larger language model. It utilizes a `prompt_builder` object to construct this prompt, incorporating context like alerts and past exchanges. \n\n**[Inputs]**\n\n*  `query: str`:  The user's current question or request.\n*  `documents: List[Document]`: A collection of documents potentially relevant to the query.\n*  `history: AskRequest.AskResponseDetails`:  Information about past interactions with the user, likely including previous queries and responses.\n*  `alert: str`:  A notification or warning message that might be relevant to the context.\n*  `prompt_builder: PromptBuilder`: An object responsible for assembling the final prompt based on the provided inputs.\n\n**[Output]**\n\n*  A dictionary: This likely contains the structured prompt designed to be fed into a language model. \n\n\n"
    },
    "src__pipelines__ask__followup_generation__FollowUpGeneration____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/followup_generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/followup_generation.py",
        "lineNo": 177,
        "endLineNo": 193,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Ffollowup_generation.py%23L177-L193&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**[Quick summary]** This Python function initializes a Text-to-SQL system by setting up components for generating SQL from natural language. It uses an LLM provider to get a text generation model, a prompt builder for crafting effective input prompts, and a post-processor to refine the generated SQL. The overall purpose is to enable a system that can translate human-readable text into executable SQL queries.\n\n**[Inputs]**\n\n*  `llm_provider`: An object responsible for providing access to a Large Language Model (LLM) capable of text generation.\n*  `engine`: An object likely representing a database engine or connection, suggesting the target database for the generated SQL.\n\n**[Output]**\n\n* An instantiated object of the system, ready to process natural language text and generate SQL queries. \n\n\n"
    },
    "src__pipelines__ask__historical_question__HistoricalQuestion____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 97,
        "endLineNo": 113,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L97-L113&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**Quick Summary:**  This function initializes an instance of a question-answering system. It sets up an embedding model (`_embedder`), a retriever (`_retriever`) to search for relevant documents, a score filter (`_score_filter`) to rank results, and an output formatter (`_output_formatter`) to present the answers.\n\n**Inputs:**\n\n* `embedder_provider`: An object providing access to a text embedding model.\n* `store_provider`: An object providing access to a document store and a retriever.\n* `dataset_name`: The name of the dataset containing the documents for retrieval.\n\n**Output:**\n\n* A fully initialized instance of the question-answering system ready to process queries. \n\n\n"
    },
    "src__pipelines__ask__sql_correction__SQLCorrection____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/sql_correction.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/sql_correction.py",
        "lineNo": 107,
        "endLineNo": 123,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fsql_correction.py%23L107-L123&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]**\n\nThis Python function initializes a class designed to translate natural language into SQL queries, incorporating error correction and post-processing steps. It leverages a language model (LLM) for query generation and a template for constructing user prompts.\n\n**[Inputs]**\n\n* `llm_provider`: An object responsible for providing access to a large language model (LLM) for text-to-SQL conversion.\n* `engine`: An object representing a database engine or system for execution of generated SQL queries.\n\n **[Output]**\n\n* An initialized class instance capable of:\n    * Generating SQL queries from natural language inputs.\n    * Correcting potential errors in generated queries.\n    * Post-processing the generated SQL for compatibility with the specified database engine. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation__Generation____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 508,
        "endLineNo": 524,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L508-L524&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down this code snippet:\n\n**[Quick Summary]**\n\nThis Python function initializes a class designed for generating SQL query explanations using a Large Language Model (LLM). It sets up components like pre-processing, prompt construction, LLM interaction, and post-processing to handle the entire workflow of explaining SQL queries. \n\n**[Inputs]**\n\n*  `llm_provider: LLMProvider`:  An object presumably responsible for providing access to a specific LLM (e.g., OpenAI's GPT-3) and managing its interaction.\n\n **[Output]**\n\n*  An instance of the class itself, likely ready to process SQL queries and produce explanations. \n\n\nLet me know if you'd like a deeper dive into any specific aspect of the code!\n"
    },
    "src__pipelines__sql_regeneration__generation__sql_regeneration_post_process": {
        "label": "sql_regeneration_post_process",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 95,
        "endLineNo": 111,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L95-L111&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** This function processes SQL regeneration data using a post-processor. It takes the generated SQL statements, optionally a project ID, and returns the processed results. The purpose is likely to refine or transform the raw SQL output from an earlier stage of a data processing pipeline.\n\n**Inputs:**\n\n*  `sql_regeneration_generate`: A dictionary containing SQL generation data.\n*  `sql_regeneration_post_processor`: A custom post-processing object responsible for refining SQL.\n*  `project_id`: (Optional) A string identifier for the project.\n\n**Output:**\n\n*   A dictionary containing the processed results from the post-processor. \n\n\n"
    },
    "src__providers__engine__wren__WrenIbis____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 50,
        "endLineNo": 66,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L50-L66&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## wren_ibis Initialization Function Summary\n\nThis function initializes a Wren Ibis engine client, setting up its connection parameters.  The function likely intends to connect to an Ibis database  and perform data-related operations.  \n\n## Inputs\n\n* **`endpoint`**: The URL or address of the Ibis database.\n* **`source`**:  Likely a identifier or label for the data source being accessed.\n* **`manifest`**: A file or configuration specifying the structure and location of the data.\n* **`connection_info`**: A dictionary containing credentials or connection settings for the Ibis database (potentially username, password, etc.).\n\n## Output\n\n* The function doesn't explicitly return a value. Instead, it initializes internal attributes (`_endpoint`, `_source`, `_manifest`, `_connection_info`) that can be used within the class to interact with the Ibis database.  \n\n\n\n"
    },
    "src__web__development__dummy_ask": {
        "label": "dummy_ask",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/development.py",
        "relativePath": "wren-ai-service/src/web/development.py",
        "lineNo": 84,
        "endLineNo": 100,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fdevelopment.py%23L84-L100&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary\n\nThis function simulates a response to an AskRequest, indicating that the system is currently understanding the request. It also adds a dummy task to a `BackgroundTasks` object, likely for further processing in the background.  This is likely part of a larger system designed for handling user requests and running background processes.\n\n## Inputs\n\n*  `ask_request`: An object presumably containing the user's query or request.\n* `background_tasks`: An object capable of adding and managing background tasks.\n\n## Output\n\n*  `AskResponse`: An object likely containing a `query_id`, used for tracking the request's status and potentially receiving future responses related to this request. \n\n\n"
    },
    "src__web__v1__routers__ask": {
        "label": "ask",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 70,
        "endLineNo": 86,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L70-L86&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown \n\n**[Quick summary]** This function handles incoming `AskRequest` objects, assigns them unique IDs, and queues them for processing by the `ASK_SERVICE`. It returns an `AskResponse` indicating the request has been received and is being processed. The purpose is to manage asynchronous processing of user requests.\n\n**[Inputs]**\n\n* **`ask_request`: **\nAn  object containing the user's query.\n* **`background_tasks`**:  \nAn object that manages background tasks, likely a task queue or scheduler.\n\n**[Output]**\n\n* **`AskResponse`**:\n  A response object containing the unique `query_id` assigned to the request. \n\n\n\n"
    },
    "src__web__v1__routers__prepare_semantics": {
        "label": "prepare_semantics",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 43,
        "endLineNo": 59,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L43-L59&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** This Python function manages the preparation of semantics (likely meaning or intent) for a given Model Development Language (MDL) hash. It queues the task for asynchronous processing and returns a confirmation response. \n\n**Inputs:**\n\n* `prepare_semantics_request`: Likely contains details about the MDL to process (e.g., hash, type, etc.)\n* `background_tasks`: A mechanism for managing asynchronous tasks. \n\n**Output:**\n\n* `SemanticsPreparationResponse`:  Likely contains confirmation of the task request, including the MDL hash. \n\n\n\n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationRequest": {
        "label": "SQLExplanationRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 20,
        "endLineNo": 36,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L20-L36&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary**\n\nThis Python code defines a class (likely named after the class declaration, e.g.,  `Query`) to store information about a query submitted to a system, like a question answering service. It includes details about the query's identifier, content, processing steps with their results, and optional identifiers for the model, thread, and project associated with the query. \n\n**Inputs**\n\n*  `_query_id`: A unique identifier for the query, potentially used for referencing it within the system. \n*  `question`: The actual text of the query posed by the user.\n*  `steps_with_analysis_results`: A list of objects (`StepWithAnalysisResult`) likely detailing the steps taken to process the query and the output of each step.\n*  `mdl_hash`:  A hash or identifier for the machine learning model used to process the query.\n*  `thread_id`:  An identifier for the thread or conversation where the query originated.\n*  `project_id`: An identifier for the project or context related to the query.\n\n**Output**\n\n*  `query_id`:  A property allowing access to the `_query_id` variable, providing a way to retrieve the query's unique identifier.\n\n\n\nLet me know if you have any more code snippets you'd like me to analyze!\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationRequest": {
        "label": "SQLRegenerationRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 37,
        "endLineNo": 53,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L37-L53&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines a Python class that likely represents a database query or an explanation of a SQL query. It stores information about the query, its steps, associated metadata, and potentially links to a thread or project. \n\n## Inputs\n\n* `_query_id`: Unique identifier for the query.\n\n\n* `description`: A textual description of the query.\n\n* `steps`: A list of  `SQLExplanationWithUserCorrections` objects, likely detailing the query's execution breakdown.\n\n* `mdl_hash`: Optional hash value, potentially related to the model used to generate the query.\n\n* `thread_id`:  Optional identifier for a thread or discussion where the query is related to.\n\n* `project_id`: Optional identifier for a project the query belongs to.\n\n\n## Output\n\n* The class instance itself, containing the stored query information.\n"
    },
    "src__core__provider__EmbedderProvider": {
        "label": "EmbedderProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 18,
        "endLineNo": 33,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L18-L33&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**Quick Summary:** This code defines an abstract base class for embedding models, likely used for various natural language processing (NLP) tasks. It enforces the implementation of `get_text_embedder` and `get_document_embedder` methods for text and document embedding, respectively.\n\n**Inputs:**\n\n* `*args`:  Arbitrary positional arguments potentially used for customizing embedding models.\n* `**kwargs`: Arbitrary keyword arguments potentially used for customizing embedding model parameters.\n\n**Output:**\n\n* This code does not directly produce any output. It defines an interface for embedding models to be implemented by subclasses.\n\n\n\n"
    },
    "src__pipelines__common__GenerationPostProcessor___check_if_sql_executable": {
        "label": "_check_if_sql_executable",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/common.py",
        "relativePath": "wren-ai-service/src/pipelines/common.py",
        "lineNo": 83,
        "endLineNo": 98,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fcommon.py%23L83-L98&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick summary:**\n\nThis function checks if a given SQL query is executable within a database system without actually executing it. It leverages a 'dry_run' method provided by a database engine (`self._engine`) and logs any errors preventing successful execution. \n\n**Inputs:**\n\n*  `sql`: A string containing the SQL query to be checked.\n*  `project_id`: An optional string representing a project identifier.\n\n**Output:**\n\n*  A Boolean value indicating whether the SQL query is executable or not. \n\n\n\n\n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantEmbeddingRetriever____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 292,
        "endLineNo": 307,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L292-L307&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## AsyncQdrantEmbeddingRetriever Initialization  \n\n**[Quick Summary]**\n This code defines an initialization method for a class `AsyncQdrantEmbeddingRetriever`, which is designed to retrieve documents from a Qdrant database based on embeddings. It takes various parameters to control the retrieval process, such as the dataset, filters, and the number of top results.\n\n**[Inputs]**\n\n* `document_store: AsyncQdrantDocumentStore`:  An asynchronous document store instance connected to Qdrant.\n* `filters: Optional[Dict[str, Any]] = None`: Optional dictionary of filters to narrow down the search results. \n* `top_k: int = 10`: The maximum number of documents to return.\n* `scale_score: bool = True`: Whether to scale the similarity scores.\n* `return_embedding: bool = False`: Whether to return the document embeddings along with the results.\n\n**[Output]** \nNone (This is an initialization method). The method sets the internal state of the object based on the provided parameters. \n"
    },
    "src__web__v1__routers__sql_explanation": {
        "label": "sql_explanation",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 134,
        "endLineNo": 149,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L134-L149&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**[Quick Summary]**\nThis function initiates the process of explaining a SQL query.  It assigns a unique ID to the request, marks it as \"understanding\" in a result store, and schedules a background task to perform the actual explanation.  \n\n**[Inputs]**\n\n*  `sql_explanation_request`: Likely a data structure containing the SQL query to be explained and possibly other relevant information.\n* `background_tasks`: An object responsible for managing background tasks, such as processing the SQL query explanation. \n\n\n**[Output]**\n\n* `SQLExplanationResponse`: A response object containing the unique ID assigned to the query, which can be used to track the explanation process.  \n\n\n\n"
    },
    "src__web__v1__routers__sql_regeneration": {
        "label": "sql_regeneration",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 160,
        "endLineNo": 175,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L160-L175&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]** This function handles incoming SQL regeneration requests. It assigns a unique ID to the request, stores it in a results dictionary, and schedules a background task to perform the actual regeneration. Finally, it returns a response confirming the request has been received. This function likely serves as an entry point for managing SQL regeneration operations within a larger system.\n\n**[Inputs]**\n* `sql_regeneration_request`:  This likely contains the actual SQL code or query to be regenerated, along with any associated metadata.\n* `background_tasks`: This object likely manages a queue of background tasks, allowing the function to offload the computationally expensive regeneration process.\n\n**[Output]**\n* `SQLRegenerationResponse`: This response confirms that the regeneration request has been received and provides a unique `query_id` for tracking the progress of the task. \n\n\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationService__get_sql_regeneration_result": {
        "label": "get_sql_regeneration_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 141,
        "endLineNo": 156,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L141-L156&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick summary**\n\nThis function retrieves the result of a previously executed SQL query regeneration request. It checks if the requested query ID exists in a stored results dictionary. If found, it returns the corresponding result; otherwise, it returns an error response.\n\n**Inputs:**\n\n*  `sql_regeneration_result_request`:  Likely an object containing the `query_id` of the SQL query regeneration request to retrieve.\n\n**Output:**\n\n*  `SQLRegenerationResultResponse`:  An object containing either the retrieved SQL query regeneration result or an error message if the query ID is not found. \n\n\n"
    },
    "src__core__engine__clean_generation_result": {
        "label": "clean_generation_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/engine.py",
        "relativePath": "wren-ai-service/src/core/engine.py",
        "lineNo": 29,
        "endLineNo": 43,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fengine.py%23L29-L43&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function cleans up messy SQL code by normalizing whitespace, removing newlines, backticks, quotes, and semicolons. The purpose is likely to prepare SQL code for further processing or analysis, ensuring consistency and removing unnecessary formatting.\n\n\n## Inputs\n\n*  **`s: str`**:  This is the input string containing potentially messy SQL code. \n\n## Output\n\n* **Cleaned SQL String**: The function returns the `s` string modified with whitespace standardized, unnecessary characters and line breaks removed.  \n"
    },
    "src__pipelines__ask__generation__Generation____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/generation.py",
        "lineNo": 139,
        "endLineNo": 153,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fgeneration.py%23L139-L153&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary:**\n\nThis code initializes a new class for converting natural language text into SQL queries. It leverages a pre-defined system prompt, a customizable user prompt template, and a post-processor to refine the generated SQL.  The final goal is to provide a structured way to translate user requests into executable SQL.\n\n**Inputs:**\n\n*  `llm_provider`: An object responsible for interacting with a Large Language Model (LLM) to generate SQL queries.\n*  `engine`: An object representing the database engine (e.g., MySQL, PostgreSQL) that the generated SQL will be executed against.\n\n\n**Output:**\n\n*  An instance of the class, ready to accept natural language text and generate corresponding SQL queries. \n"
    },
    "src__pipelines__ask_details__generation__Generation____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask_details/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask_details/generation.py",
        "lineNo": 81,
        "endLineNo": 95,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask_details%2Fgeneration.py%23L81-L95&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This code initializes an object designed to interact with an LLM (Large Language Model) to gather specific details through a question-answering dialogue. The object uses a system prompt to guide the LLM's behavior and a prompt builder to construct user questions. \n\n**Inputs:**\n\n* `llm_provider`: An object responsible for providing access to the chosen LLM and its functionalities.\n* `engine`: An object likely managing the execution and processing of the LLM's responses.\n\n**Output:**\n\n* An initialized object ready to prompt the LLM and process its generated responses. \n\n\n\n"
    },
    "src__pipelines__indexing__indexing__AsyncDocumentWriter": {
        "label": "AsyncDocumentWriter",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 333,
        "endLineNo": 347,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L333-L347&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown \n\n**Quick summary:**\nThis function writes a list of documents to a document store. It takes a  list of documents and an optional duplicate policy, using a default policy if none is provided. It then returns the number of documents successfully written.  \n\n**Inputs:**\n*  `documents`: A list of  `Document` objects representing the data to be stored.\n* `policy`: An optional `DuplicatePolicy` object that determines how to handle duplicate documents.\n\n**Output:**\n*  `documents_written`: An integer representing the number of documents successfully written to the store. \n\n\n"
    },
    "src__providers__llm__azure_openai__AzureOpenAILLMProvider__get_generator": {
        "label": "get_generator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/azure_openai.py",
        "lineNo": 143,
        "endLineNo": 157,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fazure_openai.py%23L143-L157&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary:** This Python function creates and returns an asynchronous text generation object using the Azure OpenAI API.  It initializes an  `AsyncGenerator`  with provided API key, model, and optional system prompt. The function is likely part of a larger project utilizing Azure's OpenAI capabilities for text generation tasks.\n\n**Inputs:**\n\n*  `system_prompt`: (Optional) A string containing a set of instructions or context for the model.\n*  `self._generation_api_key`:  API key for authenticating with the Azure OpenAI service.\n*  `self._generation_model`:  The specific OpenAI model to be used for text generation. \n*  `self._generation_api_base`:  Base URL for the Azure OpenAI API.\n*  `self._generation_api_version`:  API version being used.\n*  `self._model_kwargs`: A dictionary containing additional model-specific parameters. \n\n**Output:**\n*  An `AsyncGenerator` object ready to be used for asynchronous text generation. \n\n\n\n\n\n"
    },
    "src__utils__init_langfuse": {
        "label": "init_langfuse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 128,
        "endLineNo": 142,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L128-L142&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This code snippet configures an instance of a LangFuse client, a service for programmatic AI model access. It determines whether LangFuse is enabled based on environment variables, sets up API credentials, and logs the configuration details. \n\nThis helps in integrating LangFuse functionalities into the application based on user-defined settings.\n\n**Inputs:**\n\n* **LANGFUSE_ENABLE:** A string variable (can be \"true\" or \"false\") determining whether LangFuse is enabled.\n* **LANGFUSE_HOST:** A string variable specifying the host URL for the LangFuse API.\n* **LANGFUSE_PUBLIC_KEY:** A string variable holding the public API key for authentication.\n* **LANGFUSE_SECRET_KEY:** A string variable holding the secret API key for authentication.\n\n**Output:**\n\n\n* No direct output is produced. \n* Logging statements will output information about the enabled state and the host URL used for LangFuse. The logs provide insights into the configuration. \n"
    },
    "src__utils__async_timer__wrapper_timer": {
        "label": "wrapper_timer",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 106,
        "endLineNo": 120,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L106-L120&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown \n\n**Quick Summary:**\n\nThis code snippet defines a wrapper function that potentially times the execution of another function. If the `ENABLE_TIMER` environment variable is set to `True`, it records the start and end times of the function call, calculates the elapsed time, and logs it.  Otherwise, it simply executes the provided function directly.\n\n**Inputs:**\n\n* `func`: The function to be executed.\n* `*args`:  Positional arguments to be passed to the function.\n* `**kwargs`: Keyword arguments to be passed to the function.\n\n**Output:**\n\n* The result of the executed function `func`.\n\n\n"
    },
    "src__utils__timer__wrapper_timer": {
        "label": "wrapper_timer",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 82,
        "endLineNo": 96,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L82-L96&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**Quick Summary:** This Python function wraps another function (`func`) to measure its execution time. If the `ENABLE_TIMER` environment variable is set to True, it records the start and end times, calculates the elapsed time, and logs it. Otherwise, it simply executes the wrapped function without timing.\n\n**Inputs:**\n\n* `func`: The function to be wrapped and timed.\n* `*args`:  Arbitrary positional arguments to be passed to the wrapped function.\n* `**kwargs`: Arbitrary keyword arguments to be passed to the wrapped function.\n\n**Output:**\n\n* The result returned by the wrapped function (`func`).  \n\n\n\n"
    },
    "src__web__development__get_dummy_ask_task_result": {
        "label": "get_dummy_ask_task_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/development.py",
        "relativePath": "wren-ai-service/src/web/development.py",
        "lineNo": 54,
        "endLineNo": 68,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fdevelopment.py%23L54-L68&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function retrieves a pre-computed result based on a query ID. It searches for the result in a dictionary `test_ask_results` and returns the corresponding result if found, otherwise, it returns an error response. This function simulates a simple result retrieval system.\n\n## Inputs\n\n* **ask_result_request**: An object (likely a class) containing a `query_id` field, representing a unique identifier for the requested result.\n\n## Output\n\n*  **AskResultResponse**: An object (likely a class) containing:\n    * `status`: A string indicating success or failure (\"failed\" if not found).\n    * `error`: An optional object containing error details,  including a `code` and `message`.  \n\n\n"
    },
    "src__pipelines__ask__followup_generation__post_process": {
        "label": "post_process",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/followup_generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/followup_generation.py",
        "lineNo": 162,
        "endLineNo": 175,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Ffollowup_generation.py%23L162-L175&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick summary:** This function takes a dictionary containing generated text (`generate`), processes it using a specified post-processor, and returns the processed output. It likely functions as part of a text generation pipeline, refining the initial output. \n\n**Purpose:** The purpose of this code is to process and potentially modify text generated by a previous stage in a machine learning pipeline.\n\n**Inputs:**\n* `generate`: A dictionary containing generated text data.\n* `post_processor`: An object (presumably a class instance) responsible for processing the generated text.\n* `project_id`:  An optional string identifier for the specific project.\n\n**Output:**\n* A dictionary containing the processed text data.\n\n\n"
    },
    "src__pipelines__ask__generation__post_process": {
        "label": "post_process",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/generation.py",
        "lineNo": 124,
        "endLineNo": 137,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fgeneration.py%23L124-L137&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis\n\n**[Quick Summary]**\n\nThis function processes a generated response, likely from a language model, using a `GenerationPostProcessor`. It takes the generated content, an optional project ID, and returns a processed output dictionary. The overall purpose is to refine or modify the initial generation before it's presented to the user. \n\n**[Inputs]**\n\n*  `generate`: A dictionary containing the generated response (likely from a language model).\n*  `post_processor`: An object responsible for processing the generated response.\n* `project_id`: An optional string identifying a specific project.\n\n**[Output]**\n\n* A dictionary containing the processed and potentially modified generated response. \n\n\n"
    },
    "src__pipelines__ask__historical_question__HistoricalQuestion__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 138,
        "endLineNo": 151,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L138-L151&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary:** This Python function executes a question answering pipeline designed for historical queries. It takes a user's question, processes it through various stages (embedding, retrieval, scoring, formatting), and returns a formatted answer based on historical data.\n\n**Inputs:**\n\n* `formatted_output`:  Likely a string indicating the desired output format.\n* `query`: The user's question in text format.\n* `embedder`: A tool for transforming text into numerical representations (embeddings).\n* `retriever`: A system for searching a historical dataset based on the query's embedding.\n* `score_filter`: A mechanism for ranking retrieved answers based on relevance.\n* `output_formatter`:  A function to structure the final answer in the specified format. \n\n**Output:**\n\n* A string containing the formatted answer derived from the historical dataset. \n"
    },
    "src__pipelines__ask__retrieval__Retrieval____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/retrieval.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/retrieval.py",
        "lineNo": 48,
        "endLineNo": 61,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fretrieval.py%23L48-L61&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**Quick Summary:**\n\nThis code initializes a class likely intended for semantic search. It obtains an embedder (for text representation) from a provider and a retriever (for finding relevant documents) from a document store provider. Finally, it sets up an asynchronous driver for handling search operations. The overall purpose appears to be building a system for efficient text retrieval based on semantic similarity.\n\n**Inputs:**\n\n* **`embedder_provider`**: A provider object responsible for fetching a text embedder (model).\n* **`document_store_provider`**: A provider object responsible for fetching a retriever and a document store.\n\n**Output:**\n\n* An initialized class instance capable of performing semantic search. \n"
    },
    "src__pipelines__ask__sql_correction__post_process": {
        "label": "post_process",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/sql_correction.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/sql_correction.py",
        "lineNo": 92,
        "endLineNo": 105,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fsql_correction.py%23L92-L105&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** \n\nThis function processes a dictionary called \"generate\", likely containing model output, through a `GenerationPostProcessor`. It then returns the result of the post-processing, potentially modifying or enriching the original generate data.  The purpose is to refine and prepare model outputs for further use.\n\n**Inputs:**\n\n* `generate`: A dictionary containing model-generated content.\n* `post_processor`: An object with a `run` method capable of processing the \"generate\" data.\n* `project_id`: An optional string identifying a project or context.\n\n**Output:**\n\n* A dictionary resulting from the  post-processing step, potentially containing modified or enriched content from the \"generate\" input. \n\n\n"
    },
    "src__pipelines__ask_details__generation__post_process": {
        "label": "post_process",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask_details/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask_details/generation.py",
        "lineNo": 66,
        "endLineNo": 79,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask_details%2Fgeneration.py%23L66-L79&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:** \n\nThis function processes a dictionary `generate`  (likely containing generated text or code) using a `GenerationPostProcessor` object. It logs the `generate` dictionary for debugging and then calls the `run` method of the `GenerationPostProcessor` to further process the output. Finally, it returns the result from the `post_processor`.\n\n**Inputs:**\n\n- `generate`: A dictionary containing generated content. \n- `post_processor`: An object implementing a `GenerationPostProcessor` interface.\n- `project_id`: An optional string identifier for the project.\n\n**Output:**\n\n- A dictionary returned by the `GenerationPostProcessor.run` method. \n"
    },
    "src__pipelines__ask_details__generation__Generation__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask_details/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask_details/generation.py",
        "lineNo": 116,
        "endLineNo": 129,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask_details%2Fgeneration.py%23L116-L129&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:** This function executes a pipeline named \"Ask_Details Generation\" which processes SQL queries to generate textual results. It utilizes various components like a generator, prompt builder, and post-processor to refine the output. \n\n**Inputs:**\n\n* `sql`: A SQL query.\n* `generator`: A component responsible for generating text based on the SQL query.\n* `prompt_builder`: A component that constructs prompts for the text generator based on the SQL query and other inputs.\n* `post_processor`: A component that processes the generated text to ensure accuracy and clarity.\n* `project_id`:  An identifier for a specific project or environment.\n\n**Output:**\n\n* The processed, refined textual output generated from the SQL query.  \n\n\n\n"
    },
    "src__pipelines__sql_regeneration__generation__SQLRegenerationRreprocesser__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 40,
        "endLineNo": 53,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L40-L53&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**\n\nThis function likely orchestrates the presentation of SQL query explanations.  It takes a description and a list of  \"SQLExplanationWithUserCorrections\" objects, packaging them into a structured dictionary format suitable for display or further processing.  The purpose is to provide a clear and user-friendly representation of SQL query steps and potential edits.\n\n**Inputs:**\n\n*  `description`:  A string describing the overall SQL query or query logic.\n* `steps`: A list of objects, each containing information about a single step in the SQL query execution, potentially including user-made corrections. \n\n**Output:**\n\n* A dictionary with a \"results\" key containing:\n    *  `\"description\"`:  The provided description of the SQL query.\n    * `\"steps\"`: The list of \"SQLExplanationWithUserCorrections\" objects.\n\n\n"
    },
    "src__providers__embedder__ollama__AsyncTextEmbedder____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 27,
        "endLineNo": 40,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L27-L40&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  AsyncTextEmbedder Function Analysis\n\n**[Quick Summary]** This Python function initializes an object called `AsyncTextEmbedder`, which is designed to asynchronously embed text using a specified model and API endpoint. It leverages asynchronous programming techniques for efficient text embedding generation. This code likely provides a framework for integrating a text embedding model into an application, possibly for tasks like semantic search or text analysis. \n\n**[Inputs]**\n\n* `model`: The name or identifier of the text embedding model to use.\n* `url`: The base URL of the API endpoint for accessing the embedding model.\n* `generation_kwargs`: (Optional) Additional keyword arguments to pass to the model during embedding generation.\n* `timeout`: (Optional) The maximum time (in seconds) to wait for a response from the API.\n\n**[Output]**\n\n* A new instance of the `AsyncTextEmbedder` object, ready to be used for embedding text asynchronously. \n\n\n\n\n"
    },
    "src__providers__llm__ollama__AsyncGenerator___convert_to_response": {
        "label": "_convert_to_response",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 60,
        "endLineNo": 73,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L60-L73&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function takes a response from the Ollama API and transforms it into a format suitable for use with the Haystack framework. Its purpose is to bridge the communication gap between these two systems, enabling Haystack to process and utilize information from Ollama. \n\n## Inputs\n\n- `ollama_response`: An `aiohttp.ClientResponse` object, representing the raw response received from the Ollama API.\n\n## Output\n\n- A dictionary containing two keys:\n    - `\"replies\"`: A list containing a single dictionary representing the Ollama API's generated response.\n    - `\"meta\"`: A list containing a single dictionary containing metadata from the Ollama API response (excluding the \"response\" field). \n\n\n"
    },
    "src__providers__loader__pull_ollama_model": {
        "label": "pull_ollama_model",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/loader.py",
        "relativePath": "wren-ai-service/src/providers/loader.py",
        "lineNo": 105,
        "endLineNo": 118,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Floader.py%23L105-L118&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick summary:** This Python function checks if a specified Ollama model (`model_name`) exists locally. If not, it downloads the model from a remote server using the Ollama library, providing progress updates. \n\n**Inputs:**\n\n* `url`:  A string representing the URL of the Ollama server.\n* `model_name`: A string indicating the name of the Ollama model to be checked and downloaded.\n* `logger`:  An object presumably used for logging messages (like information about the download progress).\n\n**Output:**\n\n* If the model exists locally: A log message indicating that the model already exists.\n* If the model needs to be downloaded:\n    * A log message stating the download process has started with the initial percentage (0%).\n    * Periodic log messages updating the download progress percentage. \n\n\n\n\n\n\n\nLet me know if you'd like me to elaborate on any specific aspect.\n"
    },
    "src__web__v1__services__ask_details__AskDetailsResultResponse": {
        "label": "AskDetailsResultResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 48,
        "endLineNo": 61,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L48-L61&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Summary\n\nThis code defines a Pydantic model to represent the response structure for an API endpoint related to understanding and executing SQL queries. It outlines the possible statuses (e.g., \"understanding\", \"finished\", \"failed\"), a potential response containing query details, and error types that might occur.\n\n## Inputs\n\n* **status:**  Indicates the current state of the query processing.\n* **response:** Contains detailed information about the query if the status is \"finished\" and successful.\n\n## Outputs\n\n* ** response**: An optional dictionary of query details, including a description and steps involved in the SQL explanation.\n* **error**: An optional dictionary containing an error code and message if the query process failed. \n\n\n\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationResultResponse": {
        "label": "SQLRegenerationResultResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 69,
        "endLineNo": 82,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L69-L82&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis code defines a data structure to represent the status and results of a SQL code regeneration process.  It indicates whether the process is understanding, generating, finished, or failed, and provides details about the response or any encountered errors.  \n\n## Inputs \n\n*  **No explicit inputs** are defined in the provided snippet. This likely represents a response object from a function or API call that performs SQL regeneration.\n\n## Output \n\n*   **status:** a string indicating the current stage of the regeneration process (understanding, generating, finished, or failed).\n*   **response:** an optional object containing details about the regenerated SQL code.\n*   **error:** an optional object containing information about any errors encountered during the process. \n"
    },
    "src__core__engine__add_quotes": {
        "label": "add_quotes",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/engine.py",
        "relativePath": "wren-ai-service/src/core/engine.py",
        "lineNo": 51,
        "endLineNo": 63,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fengine.py%23L51-L63&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**[Quick summary]** This function attempts to convert a SQL query (presumably user-inputted) into a Trino (formerly Presto)-compatible format using the `sqlglot` library. \n\nIt logs both the original and modified SQL for debugging. If the conversion fails, it logs the error and returns an empty string and `False`. Otherwise, it returns the converted SQL and `True`.\n\n\n**[Inputs]**\n\n* `sql`: A string representing the SQL query to be converted.\n\n*   `logger`: An object likely used for logging messages (the exact nature depends on the programming framework).\n\n**[Output]**\n\n*   A string containing the Trino-compatible version of the SQL query.\n*   A boolean value (`True` if the conversion was successful, `False` otherwise). \n\n\n\n"
    },
    "src__pipelines__ask__retrieval__Retrieval__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/retrieval.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/retrieval.py",
        "lineNo": 86,
        "endLineNo": 98,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fretrieval.py%23L86-L98&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown \n\n**Quick Summary:**\n\nThis function executes a text retrieval pipeline. It takes a user query and a unique identifier (optional), uses an embedding model to understand the query and a retriever to find relevant documents, and returns the retrieved information.  \n\n **Inputs:**\n\n* `query`: The text query from the user.\n* `id`: An optional unique identifier for the query or context.\n* `embedder`: An object representing the embedding model used to understand the query.\n* `retriever`: An object representing the retriever used to find documents.\n\n**Output:**\n\n* The result of the text retrieval pipeline execution, likely containing relevant documents or information based on the query. \n\n\nLet me know if you'd like a deeper explanation of any specific part!\n"
    },
    "src__pipelines__indexing__indexing__AsyncDocumentWriter__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 335,
        "endLineNo": 347,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L335-L347&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function writes a list of documents to a document store, using a specified duplicate policy. It's likely part of a larger system for managing and storing documents.\n\n## Inputs\n\n* `documents`: A list of `Document` objects to be written to the document store.\n* `policy`: An optional `DuplicatePolicy` object that dictates how the system handles duplicate documents. If not provided, it defaults to the pipeline's configured policy.\n\n## Output\n\n*  `documents_written`: An integer representing the number of documents successfully written to the document store.  \n\n\n"
    },
    "src__pipelines__sql_explanation__generation___compose_sql_expression_of_groupby_type": {
        "label": "_compose_sql_expression_of_groupby_type",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 63,
        "endLineNo": 75,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L63-L75&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary**  This function takes a list of lists of dictionaries, each dictionary likely representing a grouping key with an expression and optional ID. It iterates through these dictionaries and constructs a list of dictionaries, each containing the \"expression\" value and the \"id\" value from the input dictionaries. This suggests the function aims to prepare grouping information for use in another part of the application.\n\n**Inputs** \n* `groupby_keys`: A list of lists of dictionaries.\n\n**Output**\n* A list of dictionaries.\n   * Each dictionary contains:\n      * `\"values\"`: The  \"expression\" value from an input dictionary.\n      * `\"id\"`: The \"id\" value from an input dictionary, defaulting to an empty string if not present. \n\n\n"
    },
    "src__pipelines__sql_regeneration__generation__preprocess": {
        "label": "preprocess",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 56,
        "endLineNo": 68,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L56-L68&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**Quick Summary** \n\nThis function processes SQL code regeneration steps. It takes a description of what the generated SQL code is about and a list of steps involved in the regeneration process, along with a preprocessing function. The function then applies this preprocessing function to generate a result. \n\n**Inputs**\n\n* `description`: A string describing the context or purpose of the SQL code being generated.\n* `steps`: A list of `SQLExplanationWithUserCorrections` objects, which likely contain details about each step in the SQL code generation process.\n* `sql_regeneration_preprocesser`: A custom object (likely a class instance) responsible for preprocessing the SQL code regeneration data.\n\n**Output**\n\n* A dictionary containing the processed SQL code regeneration information. \n\n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantDocumentStore__delete_documents": {
        "label": "delete_documents",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 218,
        "endLineNo": 230,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L218-L230&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## QdrantDocumentStore.delete_documents Function Analysis\n\n**[Quick Summary]** This code snippet deletes multiple documents from a Qdrant index. It takes a list of document IDs, converts them to a compatible format for the Qdrant API, and then uses the `async_client.delete` method to remove the specified documents.\n\n**[Inputs]**\n\n* `ids`: A list of document IDs to be deleted.\n* `self.index`: The name of the Qdrant index where the documents reside.\n* `self.wait_result_from_api`: A boolean flag determining whether to wait for the API call to complete before returning.\n\n**[Output]**\n\n* Success:  The documents with the specified IDs are deleted from the Qdrant index.\n* Failure: A `KeyError` is raised if no document with the given ID exists in the index.  \n\n\n"
    },
    "src__providers__llm__ollama__OllamaLLMProvider__get_generator": {
        "label": "get_generator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 144,
        "endLineNo": 156,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L144-L156&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function creates a generator for text generation using the  hosted Ollama model. It takes model-specific parameters and an optional system prompt and returns an asynchronous generator object ready to be used for text generation.  The purpose is to streamline the process of interacting with the Ollama API for text generation tasks.\n\n## Inputs\n\n*  `self._model_kwargs`: Dictionary of keyword arguments specific to the Ollama model being used.\n*  `system_prompt`: Optional string containing a system instruction for the model.\n\n## Output\n\n*  `AsyncGenerator` object configured to generate text from the Ollama API. \n* The generator is initialized with the provided model parameters, API endpoint, and system prompt. \n\n\n"
    },
    "src__utils__trace_metadata__extract": {
        "label": "extract",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 162,
        "endLineNo": 174,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L162-L174&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**\n\nThis function extracts metadata from a request object, populating a dictionary with project ID, thread ID, and model hash if those attributes are available on the request. This metadata likely aids in tracking and identifying requests within a larger system.\n\n**Inputs:**\n\n* `args`: Likely a tuple containing positional arguments passed to the function. \n* `request`: An object presumably containing information about the incoming request.\n\n**Output:**\n\n* `metadata`: A dictionary containing the extracted metadata keys (\"project_id\", \"thread_id\", \"mdl_hash\") and their corresponding values from the request object. \n\n\n"
    },
    "src__web__development__dummy": {
        "label": "dummy",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/development.py",
        "relativePath": "wren-ai-service/src/web/development.py",
        "lineNo": 70,
        "endLineNo": 82,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fdevelopment.py%23L70-L82&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown of the code snippet:\n\n**Quick Summary**\n\nThis function simulates asynchronous behavior by sleeping for a specified duration. It distinguishes between asynchronous (`is_async=True`) and synchronous (`is_async=False`) execution modes and uses `asyncio.sleep()` for the former and `time.sleep()` for the latter. The purpose is likely for testing or demonstrating the differences in handling delays in asynchronous applications.\n\n**Inputs**\n\n-  `should_sleep`: A boolean indicating whether the function should sleep.\n-  `is_async`:  A boolean indicating whether the execution context is asynchronous.\n-  `sleep`: An integer representing the number of seconds to sleep.\n\n**Output**\n\n-  A dictionary containing the key `\"dummy\"` and a value `\"dummy\"`. \n\n\n"
    },
    "src__web__v1__routers__stop_ask": {
        "label": "stop_ask",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 88,
        "endLineNo": 100,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L88-L100&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**[Quick Summary]** This function handles stopping an ongoing \"ask\" request. It takes a unique identifier for the request, a request object containing stopping instructions, and a task manager.  It adds a 'stop_ask' task to the task manager to be executed by the ASK_SERVICE, essentially signaling the request to be halted.\n\n**[Inputs]**\n*  `query_id: str`: A unique identifier for the ask request being stopped.\n*  `stop_ask_request: StopAskRequest`: An object containing details about why and how to stop the ask request.\n*  `background_tasks: BackgroundTasks`: A system for managing background tasks, likely responsible for executing the stop request. \n\n**[Output]**\n*  `StopAskResponse(query_id=query_id)`: A response object, likely used for confirmation or to provide status updates, containing the original query ID. \n\n\n\n"
    },
    "src__web__v1__services__ask__StopAskRequest": {
        "label": "StopAskRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 51,
        "endLineNo": 63,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L51-L63&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown\n\n**Quick Summary:**\n\nThis Python code defines a class (likely a representation of a task or operation) with attributes for a unique query identifier (`query_id`) and its current status (`stopped`). It provides access and modification methods for the `query_id`.  \n\n**Inputs:**\n\n*  `query_id`:  (string) A unique identifier for the query or task.\n\n**Output:**\n\n*  `query_id`: (string) The assigned unique identifier of the query or task. \n\n\n\n\nLet me know if you have any other code snippets you'd like me to analyze!"
    },
    "src__core__provider__LLMProvider": {
        "label": "LLMProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 6,
        "endLineNo": 17,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L6-L17&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This code defines an abstract base class likely for text generation models. It outlines the structure for subclasses to inherit from, requiring them to implement a `get_generator` method to produce a text generation component. The class also provides methods to access the underlying model and its construction parameters. The purpose is to standardize the interface for various text generation models, promoting reusability and interchangeability.\n\n**Inputs:**\n\n*  `*args`: Variable number of positional arguments passed to the `get_generator` method.\n*  `**kwargs`: Variable number of keyword arguments passed to the `get_generator` method.\n\n**Output:**\n\n* `get_generator(*args, **kwargs)`: Returns a text generation component (likely a generator) tailored to the provided arguments.\n* `get_model()`: Returns the instantiated model object used for text generation.\n* `get_model_kwargs()`: Returns a dictionary containing the keyword arguments used to construct the model. \n\n\n\n"
    },
    "src__pipelines__ask__historical_question__ScoreFilter": {
        "label": "ScoreFilter",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 24,
        "endLineNo": 35,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L24-L35&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Component Function Analysis \n\n**[Quick Summary]** This Python function filters a list of `Document` objects, keeping only those with a score greater than or equal to a given threshold. It utilizes a lambda function within the `filter` method for concise filtering logic. The purpose is to selectively retrieve documents based on their relevance scores.\n\n**[Inputs]**\n*  `documents`: A list of `Document` objects.\n* `score`: A float representing the minimum score threshold for document inclusion (defaulting to 0.8).\n\n**[Output]**\n* `documents`: A new list containing only `Document` objects whose `score` attribute meets or exceeds the specified threshold.  \n\n\n"
    },
    "src__pipelines__ask__historical_question__formatted_output": {
        "label": "formatted_output",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 84,
        "endLineNo": 95,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L84-L95&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Pipeline Function Analysis \n\n**[Quick Summary]** \nThis function processes `filtered_documents`, likely containing extracted text data, and applies a specified `output_formatter` to structure the output. Its purpose is to prepare the processed documents for presentation or further processing in a user-defined format.  \n\n**[Inputs]**\n* `filtered_documents`: A dictionary containing processed document data.\n* `output_formatter`: An object implementing the `OutputFormatter` class, responsible for formatting the output.\n\n**[Output]**\n* A dictionary containing the formatted documents, extracted from the `filtered_documents`. \n\n\n\n"
    },
    "src__pipelines__sql_explanation__generation__generates": {
        "label": "generates",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 472,
        "endLineNo": 483,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L472-L483&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis asynchronous function takes a list of prompts and a generator object, processes each prompt with the generator, and returns the results. Its purpose is to efficiently run multiple prompts through a generator in parallel. \n\n## Inputs\n\n*  `prompts`: A list of dictionaries, each containing at least a \"prompt\" key.  \n* `generator`: An object with a `run` method that accepts a prompt and returns a result. \n\n## Output\n\n* A list of results, each corresponding to a prompt in the input list. \n\n\n\n,\n"
    },
    "src__pipelines__sql_regeneration__generation__sql_regeneration_generate": {
        "label": "sql_regeneration_generate",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 81,
        "endLineNo": 92,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L81-L92&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis function takes a dictionary containing SQL regeneration prompt information and runs it through a specified generator (likely a large language model). The goal is to regenerate SQL queries based on the provided prompt. This helps in tasks like rewriting existing queries or creating new ones based on natural language descriptions.\n\n\n[Inputs]\n- `sql_regeneration_prompt`: A dictionary containing details about the SQL query regeneration request, possibly including the original query, desired modifications, and context.\n- `sql_regeneration_generator`: An object (likely an instance of a model class) responsible for generating the regenerated SQL query.\n\n[Output]\n- A dictionary containing the regenerated SQL query and potentially other generated outputs from the generator. \n\n\n"
    },
    "src__providers__llm__ollama__AsyncGenerator___handle_streaming_response": {
        "label": "_handle_streaming_response",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/ollama.py",
        "relativePath": "wren-ai-service/src/providers/llm/ollama.py",
        "lineNo": 48,
        "endLineNo": 59,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Follama.py%23L48-L59&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick Summary:** \n\nThis function handles streaming responses by iterating through each chunk of data received and processing it. It builds a representation of each chunk (`StreamingChunk`) and optionally calls a user-defined callback (`streaming_callback`) for each chunk. Finally, it returns a list of all processed chunks. Essentially, it manages the streaming response flow and allows for flexible processing of data as it arrives.\n\n**Inputs:**\n* `response`: A streaming response object.\n* `self._build_chunk(chunk)`: A method likely responsible for transforming raw response chunks into the desired `StreamingChunk` format.\n* `self.streaming_callback`: An optional callback function that will be called for each `StreamingChunk`.\n\n**Output:**\n* `chunks`: A list of `StreamingChunk` objects, representing all processed chunks of the streaming response.  \n\n\n"
    },
    "src__pipelines__indexing__indexing__validate_mdl": {
        "label": "validate_mdl",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 360,
        "endLineNo": 370,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L360-L370&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown \n\n**[Quick Summary]** \n\nThis function `validate_mdl` takes a cleaned document store containing model definition (mdl) and validates it against a predefined MDLValidator. It then returns a dictionary containing the validated mdl.\n\nThe purpose of this code is to ensure the  correctness and compliance of model definitions before they are used. \n\n\n**[Inputs]**\n\n* `clean_document_store`:  A dictionary presumably holding structured information about a machine learning model, including the model definition itself.\n* `validator`: An instance of a class called `MDLValidator` expected to have functionality to validate machine learning model definitions. \n\n**[Output]**\n\n* A dictionary containing a validated `mdl` (presumably updated based on the validator's feedback). \n\n\n\n\nLet me know if you have any other code snippets you'd like me to analyze!"
    },
    "src__pipelines__indexing__indexing__ViewConverter__run___format": {
        "label": "_format",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 103,
        "endLineNo": 113,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L103-L113&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick summary:** This function extracts key information (question, summary, statement, and view ID) from a data structure named `view`. It assumes `view` has a \"properties\" key containing these details and returns a JSON-formatted string representation of this extracted data. The purpose seems to be preparing view metadata for display or further processing. \n\n**Inputs:**\n\n* `view`: This is likely a dictionary-like structure containing information about a view. \n\n**Output:**\n\n* A string containing a JSON representation of:\n    * `\"question\"`:  Text content of the view's question (if available).\n    * `\"summary\"`: A brief summary of the view's content.\n    * `\"statement\"`:  The main statement or description associated with the view.\n    * `\"viewId\"`: A unique identifier for the view. \n"
    },
    "src__pipelines__sql_explanation__generation___compose_sql_expression_of_relation_type___is_subquery_or_has_subquery_child": {
        "label": "_is_subquery_or_has_subquery_child",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 77,
        "endLineNo": 87,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L77-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[**Quick summary**]\n\nThis function determines if a given relational expression (likely part of a database query) involves a subquery. It checks directly if the relation type is \"SUBQUERY\" or if it's a type of join containing a subquery on either side. \n\n[**Inputs**]\n* `relation`: A dictionary representing a relational expression in a query.\n\n[**Output**]\n*  `True`: If the relational expression involves a subquery.\n*  `False`: Otherwise. \n\n\n"
    },
    "src__pipelines__sql_explanation__generation___compose_sql_expression_of_sortings_type": {
        "label": "_compose_sql_expression_of_sortings_type",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 162,
        "endLineNo": 171,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L162-L171&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown\n\n**[Quick Summary]**\n\nThis Python function processes a list of `sortings` dictionaries. Each dictionary likely represents a sorting criteria (e.g., sorting by a specific field in ascending or descending order). The function transforms these dictionaries into a list of values formatted as strings,  including the sorting expression and order, along with an optional unique ID.\n\n**[Inputs]**\n\n* `sortings`: A list of dictionaries.  \n    * Each dictionary likely has keys like \"expression\" (field to sort by), \"ordering\" (ascending/descending), and potentially an \"id\".\n\n**[Output]**\n\n* A list where each element is a dictionary containing:\n    * `\"values\"`: A string combining the sorting expression and order \n    * `\"id\"`: The \"id\" value from the corresponding dictionary in `sortings`, or an empty string if \"id\" is missing. \n\n\n"
    },
    "src__providers__document_store__qdrant__QdrantProvider____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 330,
        "endLineNo": 339,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L330-L339&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**Quick Summary:**\n\nThis Python function likely initializes a client for interacting with a QDRant vector database. It takes information about the database's location and API key to establish a connection. This functionality is crucial for embedding and retrieving data from the QDRant system.\n\n**Inputs:**\n\n* **`location: str`:**  The hostname or address of the QDRant server (defaults to \"qdrant\").\n* **`api_key: Optional[Secret]`:** An API key used for authentication with the QDRant server (retrieved from environment variable or given directly).\n\n**Output:**\n\n* Initializes an internal state (`self._location` and `self._api_key`) to store the QDRant connection details.  \n\n\n"
    },
    "src__providers__embedder__ollama__OllamaEmbedderProvider__get_text_embedder": {
        "label": "get_text_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 182,
        "endLineNo": 191,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L182-L191&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick Summary]\n\nThis function creates an instance of an `AsyncTextEmbedder` object, which is likely used for asynchronously embedding text into a vector representation. It initializes this embedder using an existing embedding model (`self._embedding_model`) and a provided API URL.  \n\n[Inputs]\n\n*  `self`:  A reference to the current object instance.\n* `model_kwargs: Optional[Dict[str, Any]] = None`:  Keyword arguments that will be passed to the  `AsyncTextEmbedder` constructor, likely to configure its behavior. \n\n[Output]\n\n* An instance of  `AsyncTextEmbedder`.\n\n\n\n\n"
    },
    "src__utils__setup_custom_logger": {
        "label": "setup_custom_logger",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 44,
        "endLineNo": 53,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L44-L53&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "This function configures a logger and returns it.  \n\n[Inputs]:\n* `name` :  The name given to the logger.\n\n* `level`: The logging level to be used (e.g., DEBUG, INFO, WARNING, ERROR, CRITICAL).\n\n[Output]:\n* `logger`:  A configured logging.Logger object that will direct messages to the console (stream).  \n\n\n\n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationResultResponse": {
        "label": "SQLExplanationResultResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 46,
        "endLineNo": 55,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L46-L55&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines a data structure to represent the result of a SQL query explanation process. It indicates the status of the process (understanding, generating, finished, or failed) and optionally includes the generated explanation or an error object.\n\n## Inputs\n\n* **status**: The current state of the SQL explanation process.\n* **response**: An optional list of lists of dictionaries containing the generated SQL explanation.\n* **error**: An optional object of type `SQLExplanationResultError` indicating a problem during the process.\n\n\n## Output\n\n* `response`: A list of lists of dictionaries containing the generated SQL explanation if the process was successful.\n* `error`:  An instance of `SQLExplanationResultError` detailing the issue if the process failed. \n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationService__get_sql_explanation_result": {
        "label": "get_sql_explanation_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 126,
        "endLineNo": 135,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L126-L135&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**Quick Summary:** This function retrieves a previously generated SQL query explanation based on a given query ID. It first checks if the provided query ID exists in an in-memory storage (self.sql_explanation_results), and if found, returns the corresponding explanation. Otherwise, it returns an error indicating the query ID was not found. This code likely manages a cache of SQL query explanations for efficient retrieval. \n\n**Inputs:**\n\n* `sql_explanation_result_request`: An object containing a `query_id` field, which represents the identifier of the SQL query explanation to be retrieved.\n\n**Output:**\n\n* `SQLExplanationResultResponse`: An object containing a `status` field (either \"failed\" or success) and an optional `error` field. \n    * If the query ID is found, the status will be \"success\" and no error will be present.\n    * If the query ID is not found, the status will be \"failed\" and the error field will contain an error message.  \n"
    },
    "src__core__engine__Engine__dry_run_sql": {
        "label": "dry_run_sql",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/engine.py",
        "relativePath": "wren-ai-service/src/core/engine.py",
        "lineNo": 20,
        "endLineNo": 28,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fengine.py%23L20-L28&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**[Quick Summary]**\n\nThis function likely executes a SQL query against a database. It takes a SQL query as input, an aiohttp client session (probably for interacting with a database API), and any additional keyword arguments. The function returns a boolean indicating the success or failure of the query execution, along with an optional dictionary containing the results if the query was successful. \n\n**[Inputs]**\n\n- `sql`: A string containing the SQL query to be executed.\n- `session`: An `aiohttp.ClientSession` object, suggesting an asynchronous connection to a database API.\n- `**kwargs`: Additional keyword arguments that could be specific to the database API or the desired query behavior.\n\n**[Output]**\n\n- `bool`:  True if the SQL query was executed successfully, False otherwise.\n- `Optional[Dict[str, Any]]`: A dictionary containing the results of the query if successful, otherwise None. \n\n\n"
    },
    "src__core__pipeline__BasicPipeline": {
        "label": "BasicPipeline",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/pipeline.py",
        "relativePath": "wren-ai-service/src/core/pipeline.py",
        "lineNo": 9,
        "endLineNo": 17,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fpipeline.py%23L9-L17&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**[Quick summary]**\n\nThis Python code defines an abstract class, likely a base class for running tasks or processes.  It expects an input `pipe` which can be either a `Pipeline` or an `AsyncDriver` object, suggesting it handles data flow and execution. The `run` method is designed to be implemented by subclasses and is responsible for executing the core task logic, taking arbitrary arguments and keyword arguments and returning a dictionary of results.\n\n**[Inputs]**\n\n* `pipe`: An object that represents a data pipeline or an asynchronous driver.\n\n**[Output]**\n\n*  `Dict[str, Any]`: A dictionary containing the results or outcomes of the task execution. \n\n\n\n\n"
    },
    "src__pipelines__common__GenerationPostProcessor___build_cte_query": {
        "label": "_build_cte_query",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/common.py",
        "relativePath": "wren-ai-service/src/pipelines/common.py",
        "lineNo": 74,
        "endLineNo": 82,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fcommon.py%23L74-L82&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown\n\n**Quick Summary:**  This function constructs an SQL query string. If there are Common Table Expressions (CTEs) defined in the `steps` input, it includes them in the query using the `WITH` clause. Otherwise, it directly returns the final step's SQL.\n\n**Inputs:**\n\n* `steps`:  A list of dictionaries, each representing a step in the query construction process.\n* Each dictionary likely contains keys like:\n    * `cte_name`:  The name of the CTE.\n    * `sql`: The SQL statement for the CTE.\n\n**Output:**\n\n* A formatted SQL query string, potentially including CTE definitions. \n"
    },
    "src__pipelines__indexing__indexing__convert_to_ddl": {
        "label": "convert_to_ddl",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 373,
        "endLineNo": 381,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L373-L381&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown \n\n**[Quick Summary]** \n\nThis function `convert_to_ddl` takes a model definition (`mdl`), a Data Definition Language (DDL) converter object (`ddl_converter`), and an optional ID (`id`), and converts the model definition into a DDL representation using the provided converter. \n\nIts purpose is likely to transform data model structures into a format suitable for database schema creation or migration scripts. \n\n**[Inputs]**\n\n* `mdl`: A dictionary representing a data model.\n* `ddl_converter`: An object presumably responsible for converting the model into DDL format.\n* `id`: (Optional) A string identifier, potentially used to differentiate output for multiple models. \n\n**[Output]**\n\n* A dictionary containing the generated DDL representation of the model. \n\n\n"
    },
    "src__pipelines__indexing__indexing__convert_to_view": {
        "label": "convert_to_view",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 401,
        "endLineNo": 409,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L401-L409&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**[Quick Summary]**\n\nThis function `convert_to_view` takes a dictionary representing data (`mdl`), a `ViewConverter` object, and an optional ID. It uses the `ViewConverter` to transform the data into a view format and returns the resulting view. Its purpose is to convert internal data representations into viewable or usable formats for presentation or further processing.\n\n**[Inputs]**\n\n* `mdl`: A dictionary containing the data to be converted.\n* `view_converter`: An object presumably implementing a `ViewConverter` interface, responsible for the actual data transformation.\n* `id`: An optional string identifier, potentially used for personalization or context within the conversion process.\n\n**[Output]**\n\n* A dictionary containing the data in the converted view format.  \n\n\n"
    },
    "src__pipelines__indexing__indexing__embed_ddl": {
        "label": "embed_ddl",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 384,
        "endLineNo": 392,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L384-L392&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**\n\nThis function takes a dictionary containing information about documents (`convert_to_ddl`) and uses an embedding model (`ddl_embedder`) to generate embeddings for those documents.  The purpose is likely to represent the documents in a numerical format suitable for machine learning tasks.\n\n**Inputs:**\n\n* `convert_to_ddl`: A dictionary containing details about the documents, possibly including their text content, metadata, etc.\n* `ddl_embedder`: An instance of a machine learning model capable of generating embeddings for text data.\n\n**Output:** \n\n* A dictionary (likely) containing the generated embeddings for each document in the input. \n\n\n"
    },
    "src__pipelines__indexing__indexing__embed_view": {
        "label": "embed_view",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 412,
        "endLineNo": 420,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L412-L420&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown: `embed_view`\n\n**Quick Summary:** \nThis function takes a dictionary containing documents and uses a `view_embedder` to generate embeddings for these documents. It's likely part of a larger system that processes and understands textual information.\n\n**Inputs:**\n\n* `convert_to_view`: A dictionary containing a \"documents\" key, where the value is a list of documents to be embedded. \n* `view_embedder`: An object (likely a class instance) responsible for generating document embeddings.\n\n**Output:**\n\n* A dictionary (likely) containing the generated document embeddings. \n\n\n\n"
    },
    "src__pipelines__sql_explanation__generation___extract_to_str": {
        "label": "_extract_to_str",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 172,
        "endLineNo": 180,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L172-L180&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick summary:** This function aims to extract a value from potentially structured data. It  prioritizes retrieving the first element of a list or the entire string if input is a string. Otherwise, it returns an empty string.  \n\n**Inputs:**\n* `data`:  The input data, which could be a list or a string.\n\n**Output:**\n* The extracted value, which can be:\n    * The first element of a list\n    * The entire string if `data` is a string\n    * An empty string otherwise \n"
    },
    "src__pipelines__sql_explanation__generation__preprocess": {
        "label": "preprocess",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 395,
        "endLineNo": 403,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L395-L403&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary** \n\nThis function processes the results of a SQL analysis, likely for insights or further action. It takes the raw analysis results and passes them through a preprocessing step, returning a transformed output.  \n\n**Inputs**\n\n* `sql_analysis_results`: A list of dictionaries, presumably containing data extracted from the SQL analysis.\n* `pre_processor`: An object likely representing a class with methods to process and transform the analysis results.\n\n**Output**\n\n* A dictionary, likely containing processed and potentially enriched information derived from the `sql_analysis_results`. \n\n\n"
    },
    "src__providers__document_store__qdrant__AsyncQdrantDocumentStore__count_documents": {
        "label": "count_documents",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 231,
        "endLineNo": 239,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L231-L239&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick Summary] \n\nThis function counts the number of documents in a Qdrant index that meet specific search criteria.  It takes a set of filters, converts them into a Qdrant-compatible format, and then uses the Qdrant client to execute a count query based on these filters.\n\n[Inputs] \n\n*  `filters`:  Likely a dictionary or list of filter criteria to be applied to the search.\n\n* `self.index`:  The name of the Qdrant index to search within. \n* `self.async_client`:  An asynchronous Qdrant client object, allowing for non-blocking operations.\n\n[Output]\n*  An integer representing the number of documents found that satisfy the provided filters. \n\n\n\n\n"
    },
    "src__providers__document_store__qdrant__QdrantProvider__get_retriever": {
        "label": "get_retriever",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/document_store/qdrant.py",
        "relativePath": "wren-ai-service/src/providers/document_store/qdrant.py",
        "lineNo": 381,
        "endLineNo": 389,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fdocument_store%2Fqdrant.py%23L381-L389&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick Summary]\nThis function initializes an `AsyncQdrantEmbeddingRetriever` object, which is designed to retrieve documents from a Qdrant document store based on vector embeddings. It takes a document store and an optional `top_k` parameter, specifying the number of top results to return. \n\n[Inputs]\n\n*  `document_store`: An asynchronous Qdrant document store instance.\n* `top_k`: An integer representing the number of top retrieved documents (defaults to 10).\n\n[Output]\n\n* An instance of `AsyncQdrantEmbeddingRetriever`. \n"
    },
    "src__providers__embedder__ollama__OllamaEmbedderProvider__get_document_embedder": {
        "label": "get_document_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/ollama.py",
        "relativePath": "wren-ai-service/src/providers/embedder/ollama.py",
        "lineNo": 192,
        "endLineNo": 200,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Follama.py%23L192-L200&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown:\n\n**Quick Summary**\n\nThis function (`__init__`) likely sets up an instance of `AsyncDocumentEmbedder`. It creates an asynchronous object designed to generate document embeddings using a specified model. This is probably part of a larger system for processing and understanding text documents.\n\n**Inputs**\n\n*  `self`: The instance of the class itself.\n*  `model_kwargs: Optional[Dict[str, Any]] = None`: This suggests optional keyword arguments related to the embedding model's configuration.\n\n**Output**\n\n*  A new `AsyncDocumentEmbedder` object.   \n\n\nLet me know if you have any more code snippets you'd like analyzed!\n"
    },
    "src__web__v1__services__indexing__SemanticsPreparationStatusResponse": {
        "label": "SemanticsPreparationStatusResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 35,
        "endLineNo": 43,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L35-L43&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick summary:** \n\nThis code defines a data structure representing the status and potential errors of a semantics preparation process. It indicates whether the process is indexing, finished, or failed, and includes an optional error object if the process failed. The purpose is to provide a standardized way to communicate the status and any issues encountered during semantic analysis.\n\n**Inputs:**\n\n*  `status`:  A string indicating the current state of the semantics preparation process (\"indexing\", \"finished\", or \"failed\"). \n*  `error`: An optional `SemanticsPreparationError` object, containing error details if the status is \"failed\".\n\n**Output:**\n\n*   A data structure describing the status of the semantics preparation process. \n\n\n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationService__sql_explanation___task": {
        "label": "_task",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 74,
        "endLineNo": 82,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L74-L82&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis\n\n**[Quick summary]**\n\nThis function takes a user question and a `StepWithAnalysisResult` object containing analysis data from a previous step. It then uses a pre-existing pipeline named \"generation\" to process these inputs and generate a response. This suggests the code is part of a larger question-answering system that leverages analysis from previous steps to provide more informed responses.\n\n**[Inputs]**\n\n* `question`: A string representing the user's question.\n* `step_with_analysis_results`: An object containing analysis results from a preceding step in the process.\n\n**[Output]**\n\n*  The output is generated by the \"generation\" pipeline based on the input question and analysis results. \n* The exact format of the output is not specified, but it is likely a textual response. \n\n\n"
    },
    "src__core__provider__DocumentStoreProvider": {
        "label": "DocumentStoreProvider",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 34,
        "endLineNo": 41,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L34-L41&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines two abstract methods, `get_store` and `get_retriever`, likely part of a class designed to manage document data for a semantic search application.  The methods are intended to be implemented by subclasses to provide specific mechanisms for storing and retrieving documents. \n\nThey aim to abstract away the underlying implementation details of the storage and retrieval systems, allowing for flexibility and interchangeability of different backends.\n\n## Inputs \n\n*  `*args`: Variable number of positional arguments. Their meaning depends on the specific implementation of the subclass.\n\n* `**kwargs`: Variable number of keyword arguments. Similar to `*args`, their meaning depends on the subclass.\n\n## Output\n\n*  `DocumentStore`: An instance of a class responsible for managing document storage.\n\n*  `Retriever`: An instance of a class responsible for retrieving documents based on queries.  \n\n\n"
    },
    "src__pipelines__ask__historical_question__ScoreFilter__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 28,
        "endLineNo": 35,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L28-L35&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**Quick Summary**\n\nThis function filters a list of documents (`documents`), keeping only those with a score (`score`) above a specified threshold. The purpose is to retrieve relevant documents based on their calculated scores. \n\n**Inputs**\n\n* `documents`: A list of documents, presumably each with associated metadata or a `score`.\n* `score`: A numerical threshold used to filter documents. Only documents with a score greater than or equal to this value are considered relevant.\n\n**Output**\n\n* A dictionary containing a key `\"documents\"`. \n* The value associated with `\"documents\"` is a new list containing only the documents whose scores are greater than or equal to the input `score`. \n\n\n"
    },
    "src__pipelines__sql_regeneration__generation__sql_regeneration_prompt": {
        "label": "sql_regeneration_prompt",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_regeneration/generation.py",
        "lineNo": 71,
        "endLineNo": 78,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_regeneration%2Fgeneration.py%23L71-L78&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick Summary]** \nThis function processes data (likely from a database or query) and uses a specialized prompt builder to generate a SQL regeneration prompt. The purpose is to create instructions for regenerating SQL queries based on preprocessed results.\n\n**[Inputs]**\n\n* `preprocess: Dict[str, Any]`: This dictionary likely contains processed query results and metadata.\n* `sql_regeneration_prompt_builder: PromptBuilder`: This is a custom class designed to construct prompts for regenerating SQL queries.\n\n**[Output]**\n\n*  A regenerated SQL prompt, likely formatted for input into another system or tool. \n\n\n"
    },
    "src__providers__embedder__azure_openai__AzureOpenAIEmbedderProvider__get_text_embedder": {
        "label": "get_text_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 219,
        "endLineNo": 226,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L219-L226&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary:** This function creates an instance of an `AsyncTextEmbedder` object. This object likely handles the process of converting text into numerical vector representations (embeddings) using a specified API and model. The purpose is to enable asynchronous text embedding generation for efficient processing.\n\n**Inputs:**\n\n* `self._embedding_api_key`: An API key for accessing the embedding service. \n* `self._embedding_model`: The name or identifier of the chosen embedding model.\n* `self._embedding_api_base`: The base URL of the API endpoint for embedding requests.\n* `self._embedding_api_version`: The API version being used.\n\n**Output:**\n\n* An instance of the `AsyncTextEmbedder` class, ready to perform text embedding tasks. \n\n\n\n\n"
    },
    "src__utils__load_env_vars": {
        "label": "load_env_vars",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 54,
        "endLineNo": 61,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L54-L61&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]**\n\nThis Python function determines the current environment (development or production) by checking for the existence of a \".env.dev\" file. If it exists, it loads environment variables from that file (overriding any existing variables) and returns \"dev\". Otherwise, it returns \"prod\", indicating a production environment. The purpose is to configure application settings differently based on the environment.\n\n**[Inputs]**\n\n* **Path(\".env.dev\")**: This represents a file path object pointing to the \".env.dev\" file.\n\n**[Outputs]**\n\n*  \"dev\" : Returned if a \".env.dev\" file exists. \n*  \"prod\" : Returned if no \".env.dev\" file is found. \n\n\n\n"
    },
    "src__web__v1__routers__get_prepare_semantics_status": {
        "label": "get_prepare_semantics_status",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 61,
        "endLineNo": 68,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L61-L68&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Breakdown\n\n**Quick Summary:**\nThis function fetches the status of semantic preparation for a specific model (identified by its `mdl_hash`). It likely interacts with an indexing service to retrieve this information and provide it to the caller.  This could be part of a larger system monitoring or managing the preparation of models for semantic understanding.\n\n**Inputs:**\n\n*  `mdl_hash`: A unique identifier for the machine learning model in question.\n\n**Output:**\n*  `SemanticsPreparationStatusResponse`: A response object containing information about the semantic preparation status of the model.  This could include details like progress, completion status, and any potential errors. \n\n\n"
    },
    "src__web__v1__routers__get_sql_explanation_result": {
        "label": "get_sql_explanation_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 151,
        "endLineNo": 158,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L151-L158&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis:\n\n**Quick Summary:** \n\nThis function likely retrieves an explanation of a previously executed SQL query using an external SQL explanation service. It takes the unique identifier (query_id) of the query as input and returns a structured response containing the explanation.  \n\n**Inputs:**\n\n*  `query_id`: A string representing the unique identifier of the SQL query for which an explanation is required.\n\n\n**Output:**\n\n*  `SQLExplanationResultResponse`: A structured response containing the explanation of the SQL query, likely including details about the query plan, execution steps, and performance metrics.  \n"
    },
    "src__web__v1__services__ask__AskService___is_stopped": {
        "label": "_is_stopped",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 101,
        "endLineNo": 108,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L101-L108&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**[Quick Summary]**  This function checks if a specific query (identified by `query_id`) has been stopped. It looks up the query's status in a dictionary (`self._ask_results`) and returns `True` if the status is \"stopped,\" otherwise `False`.\n\nThis code likely serves as a part of a larger system managing asynchronous queries, ensuring appropriate handling of stopped queries. \n\n\n**[Inputs]**\n* `query_id`: A unique identifier for the query being checked.\n* `self._ask_results`:  A dictionary likely holding status information about various queries.\n\n**[Output]**\n* `True`: If the query with the given `query_id`  has a status of \"stopped\".\n* `False`: If the query doesn't exist in `self._ask_results` or its status is not \"stopped\".\n\n\n\n\n"
    },
    "src__web__v1__services__ask__AskService__stop_ask": {
        "label": "stop_ask",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 303,
        "endLineNo": 310,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L303-L310&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**\n\nThis function handles the halting of a running \"Ask\" request. It receives a `StopAskRequest` containing information about the request to stop, and it marks that request in its internal storage (`_ask_results`) as \"stopped.\" This likely indicates the system can no longer process that  request and should cease any ongoing computations related to it.\n\n**Inputs:**\n\n*  `self`:  Refers to the instance of the class containing this function.\n*  `stop_ask_request`: An object of type `StopAskRequest`.\n\n**Output:**\n\n*  The function updates the internal dictionary `_ask_results` with a new `AskResultResponse` object for the given `query_id`, setting its `status` to \"stopped\". \n\n\n"
    },
    "src__web__v1__services__indexing__SemanticsPreparationRequest": {
        "label": "SemanticsPreparationRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 14,
        "endLineNo": 21,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L14-L21&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Breakdown\n\n**Quick Summary:** \n\nThis code defines a Pydantic model, likely used for data validation and parsing. It expects data describing an object, possibly a software model,  including (optionally) its project ID. \n\n**Inputs:**\n\n* **mdl:** A string representing the model identifier.\n* **mdl_hash:** An optional, alternative identifier for the model, likely a hash value. \n* **project_id:** An optional string specifying the project associated with the model.\n\n**Output:**\n\n* A structured object conforming to the defined model schema (e.g., a dictionary).\n"
    },
    "src____main____exception_handler": {
        "label": "exception_handler",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/__main__.py",
        "relativePath": "wren-ai-service/src/__main__.py",
        "lineNo": 68,
        "endLineNo": 74,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2F__main__.py%23L68-L74&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick Summary]** This function handles errors by constructing an error response using the ORJSON library. It returns a JSON response with a 500 Internal Server Error status code and a \"detail\" field containing the string representation of an exception (`exc`). This suggests a generic error handling mechanism in a web application.\n\n**[Inputs]**\n\n*  `exc`: An exception object representing an error that occurred during execution.\n\n**[Output]**\n\n*  A JSON response object with:\n    *   `status_code`: 500\n    *   `content`: A dictionary containing a `\"detail\"` field with the string representation of the provided `exc` object. \n\n\n"
    },
    "src____main____request_exception_handler": {
        "label": "request_exception_handler",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/__main__.py",
        "relativePath": "wren-ai-service/src/__main__.py",
        "lineNo": 76,
        "endLineNo": 82,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2F__main__.py%23L76-L82&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown \n\n**[Quick summary]**\n\nThis function is designed to handle errors and return a structured error response. When an exception occurs, it creates a response with a 400 Bad Request status code and a JSON payload containing the exception message. \n\n**[Inputs]**\n\n* `exc`: This represents an exception object that was raised during program execution.\n\n**[Output]** \n\n*  An `ORJSONResponse` object containing:\n    *  `status_code`: Set to 400 (Bad Request)\n    *  `content`: A dictionary with the key \"detail\" holding the string representation of the exception message (`str(exc)`). \n\n\n\n"
    },
    "src__core__engine__remove_limit_statement": {
        "label": "remove_limit_statement",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/engine.py",
        "relativePath": "wren-ai-service/src/core/engine.py",
        "lineNo": 44,
        "endLineNo": 50,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fengine.py%23L44-L50&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown of the code snippet:\n\n**[Quick Summary]**\n\nThis Python function aims to remove `LIMIT` clauses from SQL queries. It leverages regular expressions to identify and replace any lines containing `LIMIT` followed by a number, potentially with trailing comments, effectively stripping the query's row limit.\n\n**[Inputs]**\n\n* `sql`: The input is a string representing the SQL query.\n\n**[Output]**\n\n* `modified_sql`: A modified string containing the original SQL query with any `LIMIT` clauses removed. \n\n\nLet me know if you'd like a deeper dive into how the regular expression works or have any other code snippets you want analyzed.\n"
    },
    "src__pipelines__ask__historical_question__filtered_documents": {
        "label": "filtered_documents",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 75,
        "endLineNo": 81,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L75-L81&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis function processes a \"retrieval\" object, likely containing search results, likely logs debugging information about the retrieval, and then filters the retrieved documents using a score_filter object. The purpose is likely to refine a set of search results based on some scoring criteria.  \n\n## Inputs\n\n*  `retrieval`: An object presumably containing search results, possibly including a \"documents\" key.\n* **`score_filter`**: A filter object (custom or from a library) that takes a list of documents as input and returns a filtered list based on a scoring mechanism.\n\n## Output\n\n* A filtered list of documents from the `retrieval` object.  \n\n\nLet me know if you'd like me to elaborate on any of these points.\n"
    },
    "src__pipelines__indexing__indexing__clean_document_store": {
        "label": "clean_document_store",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 350,
        "endLineNo": 356,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L350-L356&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function `clean_document_store` takes a document string (`mdl_str`), a `DocumentCleaner` object, and an optional document ID (`id`). It then processes the document using the provided cleaner and returns the cleaned result.  This function likely aims to standardize and preprocess documents stored in a system.\n\n## Inputs\n* `mdl_str`: The input document as a string.\n* `cleaner`: An object implementing the `DocumentCleaner` interface, presumably responsible for cleaning and transforming the document.\n* `id`: An optional string identifier for the document being cleaned.\n\n## Output\n* A dictionary (`Dict[str, Any]`) containing the cleaned document and potentially other information. \n"
    },
    "src__pipelines__indexing__indexing__write_view": {
        "label": "write_view",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 423,
        "endLineNo": 429,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L423-L429&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary**  This function takes a dictionary `embed_view` containing embedded document information and passes it to a `view_writer` object. It then executes the `view_writer`'s `run` method, likely generating a final view or representation of the embedded documents. The purpose seems to be to process and display documents in a structured or visualized format.\n\n**Inputs**\n\n* `embed_view`: A dictionary containing information about embedded documents.  This might include:\n    * The documents themselves (perhaps as text strings or numerical representations).\n    * Metadata about the documents (e.g., titles, authors).\n    * Embedding vectors for each document.\n\n* `view_writer`: An object designed to process embedded document information and produce a view.\n\n**Output**\n\n* The result of the `view_writer.run()` method, which could be:\n    * A formatted text output.\n    * A visual representation (e.g., a graph, chart).\n    * A structured data format (e.g., JSON). \n\n\n"
    },
    "src__pipelines__indexing__indexing__DDLConverter___convert_views": {
        "label": "_convert_views",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 293,
        "endLineNo": 299,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L293-L299&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Summary\n\nThis function takes a list of dictionaries, each representing a database view, and formats them into SQL CREATE VIEW statements.  The goal is to generate SQL code to define database views.\n\n## Inputs\n\n* `views`: A list of dictionaries. Each dictionary likely represents a database view and contains fields such as \"name\", \"statement\", and potentially \"properties\".\n\n## Output\n\n* A list of strings. Each string represents a formatted SQL CREATE VIEW statement for a view in the input list. \n\n\n"
    },
    "src__providers__embedder__azure_openai__AzureOpenAIEmbedderProvider__get_document_embedder": {
        "label": "get_document_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/azure_openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/azure_openai.py",
        "lineNo": 227,
        "endLineNo": 233,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fazure_openai.py%23L227-L233&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**[Quick Summary]** This function initializes and returns an `AsyncDocumentEmbedder` object. This object likely interacts with an API to generate textual embeddings for documents. The purpose is to provide a convenient way to incorporate document embedding capabilities into your application.\n\n**[Inputs]** \n\n* `self._embedding_api_key`: Likely a unique API key for accessing the embedding service.\n* `self._embedding_model`:  Specifies the embedding model to use.\n* `self._embedding_api_base`:  The base URL of the embedding API.\n* `self._embedding_api_version`: The API version being used.\n\n**[Output]**\n\n* `AsyncDocumentEmbedder`:  An object capable of asynchronously generating document embeddings. \n\n\n"
    },
    "src__providers__embedder__openai__OpenAIEmbedderProvider__get_text_embedder": {
        "label": "get_text_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 216,
        "endLineNo": 222,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L216-L222&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick Summary:**  This function creates and returns an instance of the `AsyncTextEmbedder` class, which is designed to asynchronously embed text using a specified API key, base URL, and embedding model. Its purpose is to facilitate efficient and parallel text embedding tasks.\n\n**Inputs:**\n\n* `api_key`: An API key used for authentication with the embedding service.\n* `api_base_url`: The base URL of the API endpoint for accessing the embedding service.\n* `embedding_model`:  The name or identifier of the desired embedding model.\n\n**Output:**\n\n* `AsyncTextEmbedder`: An instance of the `AsyncTextEmbedder` class, ready to be used for embedding text asynchronously. \n\n\n"
    },
    "src__providers__loader__get_default_embedding_model_dim": {
        "label": "get_default_embedding_model_dim",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/loader.py",
        "relativePath": "wren-ai-service/src/providers/loader.py",
        "lineNo": 98,
        "endLineNo": 104,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Floader.py%23L98-L104&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**[Quick summary]** This function dynamically imports an embedder provider class and retrieves the dimension of its embedding model. It likely aims to streamline the process of configuring and using different embedding models within a larger application.\n\n**[Inputs]**\n* `embedder_provider`: A string representing the name of the embedder provider class (e.g., 'sentence_transformers_embedder').\n\n**[Output]**\n* An integer representing the embedding dimension of the selected embedder model. \n\n\n\n\n\n"
    },
    "src__web__v1__services__ask__SQLExplanation": {
        "label": "SQLExplanation",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 14,
        "endLineNo": 20,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L14-L20&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze! \ud83d\ude0a  I'm ready to break it down for you. \n\n"
    },
    "src__web__v1__services__ask__AskService____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 94,
        "endLineNo": 100,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L94-L100&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick summary:** This function likely initializes an object designed to manage multiple data processing pipelines.  It stores a dictionary of pipelines by name and appears to have a mechanism for tracking results (`_ask_results`).  This suggests it's used for orchestrating and managing data processing workflows.\n\n**Inputs:** \n\n*  `pipelines`:  A dictionary where keys are pipeline names (strings) and values are instances of `BasicPipeline` objects.\n\n **Output:**\n\n* None (This function likely modifies its own internal state rather than returning a value). \n"
    },
    "src__web__v1__services__ask_details__SQLExplanation": {
        "label": "SQLExplanation",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 14,
        "endLineNo": 20,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L14-L20&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down this likely Python function definition. \n\n**[Quick Summary]**\n\nThis function appears designed to handle requests involving SQL queries within some larger application or data processing framework. It takes SQL code, a textual summary, and a name for the Common Table Expression (CTE) as input.  \n\n**[Inputs]**\n\n*  `sql`: The SQL query string to be executed or processed.\n*  `summary`: A brief description explaining the purpose of the SQL query.\n*  `cte_name`:  The name to be given to a Common Table Expression (CTE) within the provided SQL query. A CTE is a named, temporary result set used within a larger query.\n\n**[Output]**\n\nThe provided snippet doesn't explicitly show a return value. This function might:\n\n*   Modify data or execute the SQL query directly without returning a result.\n*   Store the details (SQL, summary, CTE name) in a database or log for later use. \n*   Construct some output structure (like a dictionary) containing the provided information.\n\n\n\n\nLet me know if you have more code context \u2013 it would help me pinpoint the function's exact actions.\n"
    },
    "src__web__v1__services__ask_details__AskDetailsService____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 63,
        "endLineNo": 69,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L63-L69&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis Python function initializes an object that manages multiple machine learning pipelines. It takes a dictionary of pipelines as input, where each key is a pipeline name and the value is a corresponding pipeline object. The purpose is to store and access these pipelines efficiently, likely for tasks like text classification or natural language processing. \n\n[Inputs]\n* `pipelines`: A dictionary mapping pipeline names (strings) to actual pipeline objects.\n\n[Output]\n*  None (This function likely initializes the object's state and doesn't return a direct value). \n \n\n\n\n"
    },
    "src__web__v1__services__indexing__SemanticsPreparationResponse": {
        "label": "SemanticsPreparationResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 22,
        "endLineNo": 28,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L22-L28&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**Quick Summary**\n\nThis Python code defines a `mdl_hash` field within a data model, handling potential conflicts with standard field naming conventions. The field maps to \"id\" in API serialization, suggesting it represents a unique identifier for a semantic preparation. It's likely part of a larger API definition for managing semantic preparations.\n\n**Inputs**\n\n* `mdl_hash`: A string representing a unique identifier for a semantic preparation (`id` in API context)\n\n\n\n**Output**\n\n\n```python\n    # don't recommend to use id as a field name, but it's used in the API spec\n    # so we need to support as a choice, and will remove it in the future\n    mdl_hash: str = Field(serialization_alias=\"id\")\n\n\n# GET /v1/semantics-preparations/{mdl_hash}/status\n```\n\n\n\n Let me know if you would like more details or have further questions.\n"
    },
    "src__web__v1__services__indexing__IndexingService____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 45,
        "endLineNo": 51,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L45-L51&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown \n\n**Quick summary:** This function initializes an object that manages a collection of pipelines, likely for processing text or other data. It stores the pipelines in a dictionary and keeps track of the \"semantics statuses\" for each pipeline, which suggests ongoing processing or evaluation of semantic meaning. \n\nThe overall purpose is to provide a structured way to handle and utilize multiple processing pipelines, possibly within a larger machine learning or NLP application.\n\n**Inputs:**\n\n* `pipelines`: A dictionary where keys are strings (representing pipeline names) and values are instances of `BasicPipeline`.\n\n**Outputs:**\n\n* None (This function appears to be a constructor, focusing on initialization rather than producing a direct output value). \n\n\n\n\n"
    },
    "src__web__v1__services__sql_regeneration__CorrectionPoint": {
        "label": "CorrectionPoint",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 18,
        "endLineNo": 24,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L18-L24&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Breakdown\n\n**Quick Summary:**  This function likely parses and handles user input for database queries. It expects either a raw SQL expression or a natural language expression representing a desired query.  The function stores the received input as a string for further processing. \n\n**Inputs:**\n* **type:** A string specifying the type of the input value (\"sql_expression\" or \"nl_expression\").\n* **value:** A string containing the actual query expression.\n\n**Output:**\n*  An object containing the \"type\" and \"value\" of the inputted query. \n\n\n"
    },
    "src__web__v1__services__sql_regeneration__SQLExplanationWithUserCorrections": {
        "label": "SQLExplanationWithUserCorrections",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 30,
        "endLineNo": 36,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L30-L36&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:** This function likely processes user-generated SQL queries. It appears designed to handle potential errors, offer suggested corrections (`UserCorrection` objects), and potentially generate alternative query representations (CTE) for analysis or execution.\n\n**Inputs:**\n\n* `summary`: A brief description of the SQL query.\n* `sql`: The actual SQL query string generated by the user.\n* `cte_name`: A potential Common Table Expression (CTE) name to be associated with the query.\n* `corrections`: A list of `UserCorrection` objects, likely suggesting edits to the SQL query.\n\n**Output:**\n\n\nNone explicitly stated. It's likely the function modifies the input data internally, such as refining the `sql` string based on `corrections` and potentially generating a new query representation using the `cte_name`. \n"
    },
    "src__providers__embedder__openai__OpenAIEmbedderProvider__get_document_embedder": {
        "label": "get_document_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 223,
        "endLineNo": 228,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L223-L228&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function creates an instance of the `AsyncDocumentEmbedder` class, which is used to generate vector embeddings for documents asynchronously. It utilizes the provided API key, base URL, and embedding model to achieve this. This allows for efficient and scalable embedding generation for large document collections.\n\n## Inputs\n\n- `self._api_key`: An API key for accessing the embedding service.\n- `self._api_base`: The base URL of the API endpoint.\n- `self._embedding_model`: The name or identifier of the desired embedding model.\n\n## Output\n\n- An instance of the `AsyncDocumentEmbedder` class, ready for use. \n"
    },
    "src__providers__embedder__openai__OpenAIEmbedderProvider____init_____verify_api_key": {
        "label": "_verify_api_key",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/embedder/openai.py",
        "relativePath": "wren-ai-service/src/providers/embedder/openai.py",
        "lineNo": 193,
        "endLineNo": 198,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fembedder%2Fopenai.py%23L193-L198&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:**\n\nThis code snippet is a basic test to ensure the necessary environment variables (`api_key` and `api_base`) for interacting with the OpenAI API are correctly configured. It attempts to list available OpenAI models, signaling success if the connection is established and authentication is valid.\n\n**Inputs:**\n\n* `api_key`: An API key obtained from OpenAI, granting access to its services.\n* `api_base`: The base URL for OpenAI's API endpoint.\n\n**Output:**\n\n*  Successful execution: A list of available OpenAI models.\n*  Failure: Likely raises an error indicating issues with the API key or base URL configuration. \n\n\n"
    },
    "src__providers__llm__openai__OpenAILLMProvider____init_____verify_api_key": {
        "label": "_verify_api_key",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/llm/openai.py",
        "relativePath": "wren-ai-service/src/providers/llm/openai.py",
        "lineNo": 130,
        "endLineNo": 135,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fllm%2Fopenai.py%23L130-L135&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick summary]**\n\nThis code snippet checks if the necessary environment variables `api_key` and `api_base` are correctly set for interacting with the OpenAI API. It does so by attempting to list available OpenAI models using the `OpenAI` library. This verification step ensures the application has the required credentials to access and utilize OpenAI's services.\n\n**[Inputs]**\n\n* `api_key`: An API key provided by OpenAI for authentication and access control.\n* `api_base`: The base URL of the OpenAI API endpoint.\n\n**[Output]**\n\n* If successful: A list of available OpenAI models.\n* If unsuccessful: An error indicating a problem with the API key or base URL.  \n\n\n"
    },
    "src__utils__CustomFormatter__format": {
        "label": "format",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 38,
        "endLineNo": 43,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L38-L43&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**Quick Summary**\n\nThis function formats log messages based on their severity level. It retrieves a predefined format string from a dictionary called `FORMATS` based on the `record.levelno` (log level), creates a `logging.Formatter` instance using that string, and then formats the log `record` according to the chosen format.  \n\n**Inputs**\n\n* `record`: A logging record object containing information about the log message.\n\n**Output**\n\n* A formatted string representation of the log message. \n"
    },
    "src__web__v1__routers__get_ask_details_result": {
        "label": "get_ask_details_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 127,
        "endLineNo": 132,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L127-L132&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This function retrieves detailed information about a specific query by calling a service named `ASK_DETAILS_SERVICE`. It expects a `query_id` to identify the query and returns the corresponding `AskDetailsResult` object. \n\nLikely, this code is part of a larger system that manages and processes user queries.\n\n**Inputs:**\n\n* `query_id`: A unique identifier for a specific user query.\n\n**Output:**\n\n* `AskDetailsResult`: An object containing detailed information about the specified query.  \n"
    },
    "src__web__v1__routers__get_sql_regeneration_result": {
        "label": "get_sql_regeneration_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 177,
        "endLineNo": 182,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L177-L182&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function retrieves the result of a previously executed SQL regeneration task. Given a unique query ID, it interacts with a service (`SQL_REGENERATION_SERVICE`) to fetch the regeneration result.  \n\n## Inputs\n\n* `query_id`: A string representing a unique identifier for the SQL regeneration task.\n\n## Output\n\n* `SQLRegenerationResultResponse`: A data structure containing details about the outcome of the SQL regeneration task, likely including status, messages, and potentially the regenerated SQL code. \n"
    },
    "src__web__v1__services__ask__AskResultResponse__AskError": {
        "label": "AskError",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 80,
        "endLineNo": 85,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L80-L85&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis code defines a function likely used in a question answering system to categorize the reason behind a query failing to produce relevant results. It distinguishes between cases where there's no relevant data, no applicable SQL query, or other unspecified reasons. The \"MISLEADING_QUERY\" category might be reintroduced in future iterations.\n\n## Inputs\n\n*  **code**: A string literal representing a code indicating the reason for the query failure.\n*  **message**: A string providing further context or details about the query failure.\n\n## Output\n\n*  Likely returns nothing explicitly, instead using the provided `code` and `message` for internal processing or logging within the question answering system. \n"
    },
    "src__web__v1__services__indexing__SemanticsPreparationStatusRequest": {
        "label": "SemanticsPreparationStatusRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 29,
        "endLineNo": 34,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L29-L34&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary \n\nThis code defines a field named `mdl_hash` that accepts a string as input. It uses an alias to also allow `id` to be used as an input for this field, although this is deprecated and will be removed later. The purpose is to handle an API requirement while acknowledging its potential issue.\n\n## Inputs\n* `mdl_hash`: a string representing a unique identifier for a model.\n \n* `id`: (deprecated) a string representing a unique identifier for a model, expected to be replaced by `mdl_hash`.\n\n## Output \n* A validated `mdl_hash` string. \n"
    },
    "src__web__v1__services__sql_explanation__StepWithAnalysisResult": {
        "label": "StepWithAnalysisResult",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 14,
        "endLineNo": 19,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L14-L19&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function likely analyzes a given SQL query (`sql`) and provides a summary of its contents (`summary`).  It also returns a detailed list of analysis results (`sql_analysis_results`), potentially including query type, possible vulnerabilities, performance insights, or other relevant information.\n\n## Inputs\n\n* **sql**: The SQL query to be analyzed.\n* **summary**:  A concise description of the SQL query's purpose (likely generated by the function itself).\n* **sql_analysis_results**: A list of dictionaries containing detailed analysis results about the SQL query.\n\n## Output\n\nThe expected output is *not* explicitly defined.  However, based on the function's likely purpose, it could include:\n\n* A summarized description of the SQL query.\n* A list of dictionaries containing specific analysis results about the query,  such as:\n    * Type of query (SELECT, INSERT, UPDATE, DELETE, etc.)\n    * Potential security vulnerabilities\n    * Performance bottlenecks\n    * Data access patterns\n\n\nLet me know if you have any other questions or if you'd like me to elaborate on any of these points.\n"
    },
    "src__web__v1__services__sql_regeneration__SQLExplanation": {
        "label": "SQLExplanation",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 63,
        "endLineNo": 68,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L63-L68&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down this code snippet. You haven't provided any actual code, though! It looks like you're describing a function definition, potentially in Python, with the following elements:\n\n**[Quick Summary]**\n\nThis function appears designed to process SQL queries. It likely takes a SQL statement, a summary of its purpose, and a name for a Common Table Expression (CTE) as input. The function might execute the SQL query, potentially incorporating the CTE or using the summary for documentation or analysis. \n\n**[Inputs]**\n\n*   `sql`: The SQL query to be executed or manipulated.\n*   `summary`: A brief description of the purpose of the SQL query.\n*   `cte_name`: A name to be used for a Common Table Expression within the SQL query.\n\n**[Output]**\n\n\n\nIt's impossible to say for sure without seeing the actual function code.  \n\nPossible outputs could include:\n\n*   A result set generated from the executed SQL query.\n*   A modified SQL statement incorporating the CTE.\n*   A log message indicating successful or unsuccessful query execution. \n\n\nLet me know if you have the actual function code, and I can give you a more precise analysis!\n"
    },
    "src__core__engine__EngineConfig": {
        "label": "EngineConfig",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/engine.py",
        "relativePath": "wren-ai-service/src/core/engine.py",
        "lineNo": 13,
        "endLineNo": 17,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fengine.py%23L13-L17&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n **[Quick summary]** \n\nThis code snippet initializes variables presumably used for configuring an application or system component.  `provider` likely represents the source or origin of data or functionality, here set to \"wren_ui,\" while `config` is a dictionary intended to hold additional settings specific to the provider.  \n\n**[Inputs]**\n\n* `provider`: A string value (set to \"wren_ui\") indicating the provider of some service or data.\n* `config`: An empty dictionary (`{}`) meant to store configuration settings related to the specified provider.\n\n**[Output]**\n\nThe code itself doesn't produce an output in the traditional sense. Instead, it establishes two variables for later use:\n* `provider` will hold the string \"wren_ui.\"\n* `config` will be a dictionary that can be populated with configuration parameters. \n\n\n"
    },
    "src__pipelines__ask__followup_generation__generate": {
        "label": "generate",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/followup_generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/followup_generation.py",
        "lineNo": 155,
        "endLineNo": 159,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Ffollowup_generation.py%23L155-L159&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**[Quick Summary]** \nThis function prepares and sends a prompt to a text generation model (`generator`) and returns the generated output. It uses the `orjson` library for pretty-printing the prompt for debugging purposes.\n\n**[Inputs]**\n\n*  `prompt`:  Likely a dictionary containing the text prompt to be sent to the generator.\n\n*  `generator`: An instance of a text generation model.\n\n**[Outputs]**\n\n* The text generated by the `generator` in response to the provided `prompt`. \n\n\n"
    },
    "src__pipelines__ask__generation__generate": {
        "label": "generate",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/generation.py",
        "lineNo": 117,
        "endLineNo": 121,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fgeneration.py%23L117-L121&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis:\n\n**[Quick Summary]** This function prepares and executes a text generation prompt using an unspecified generator. It first logs the formatted prompt for debugging purposes, then runs the generator with the extracted prompt text and returns the result. The purpose is likely to streamline the interaction with a text generation model.\n\n**[Inputs]**\n\n*  `logger`:  A logging instance used for recording messages.\n*  `prompt`:  A dictionary containing the text generation instructions or context.\n*  `generator`: An object capable of generating text based on a given prompt.\n\n**[Output]** The result of the text generation process from the `generator`. \n\n\n\n"
    },
    "src__pipelines__ask__historical_question__embedding": {
        "label": "embedding",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 61,
        "endLineNo": 65,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L61-L65&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick Summary]** This function takes a user query as input, logs it for debugging purposes, and then uses an `embedder` object (likely a language model) to process the query, returning the result. The purpose appears to be integrating a language model into an application to generate responses based on user input.\n\n**[Inputs]**\n* `query`:  The text input from the user, representing their question or request.\n* `embedder`: An object (presumably a class instance) responsible for processing the query using a language model. \n\n**[Output]**\n* The result of the `embedder.run(query)` call, likely a textual representation of the language model's response to the query. \n\n\n"
    },
    "src__pipelines__ask__historical_question__retrieval": {
        "label": "retrieval",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/historical_question.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/historical_question.py",
        "lineNo": 68,
        "endLineNo": 72,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fhistorical_question.py%23L68-L72&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick Summary:**\n\nThis function retrieves relevant documents based on a given query embedding using a retriever model. It executes the retriever with the provided embedding and returns a dictionary containing the retrieved documents. \n\n**Inputs:**\n\n* `retriever`: Likely an instance of a document retrieval model.\n* `embedding`:  A dictionary containing a \"embedding\" key, representing the numerical representation of the user's query.\n\n**Output:**\n\n* A dictionary with a \"documents\" key, containing a list of retrieved documents.  \n\n\n"
    },
    "src__pipelines__ask__retrieval__embedding": {
        "label": "embedding",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/retrieval.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/retrieval.py",
        "lineNo": 20,
        "endLineNo": 24,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fretrieval.py%23L20-L24&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis \n\n**[Quick Summary]**\n\nThis function takes a query string as input, logs it for debugging purposes, and uses an embedder model (likely a language model) to process it. The processed result is then returned. This suggests the function is part of a system that uses an embedding model to represent text input in a numerical format, which can be used for various tasks like semantic search or clustering.\n\n**[Inputs]**\n* `query`:  A string representing the text input to be processed.\n\n* `embedder`: An object or instance of a class representing the embedding model.\n\n**[Output]**\n* The processed embedding representation of the input query, likely a numerical vector. \n\n\n"
    },
    "src__pipelines__ask__sql_correction__generate": {
        "label": "generate",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/sql_correction.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/sql_correction.py",
        "lineNo": 85,
        "endLineNo": 89,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fsql_correction.py%23L85-L89&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze. I need the text of the function to give you the summary, inputs, and output. \n\n"
    },
    "src__pipelines__ask_details__generation__generate": {
        "label": "generate",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask_details/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask_details/generation.py",
        "lineNo": 59,
        "endLineNo": 63,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask_details%2Fgeneration.py%23L59-L63&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Analysis of Code Snippet \n\n**Quick Summary:** This function takes a `prompt`,  logs it with indentation for debugging, and then uses a generator (`generator`) to process the prompt.  The result from the generator is then likely used for further actions within a larger program.  The purpose is to execute a generative model (likely a language model) using a given prompt and possibly capturing its output.  \n\n**Inputs:**\n\n* `prompt`:  A dictionary likely containing the text input for the generator.\n* `generator`: An object, presumably a class instance, responsible for processing the prompt and generating a response.  \n\n**Output:**\n\n*  The output of the `generator.run` method, which likely contains the generated text or some other data produced by the generator.  \n\n\n"
    },
    "src__pipelines__ask_details__generation__prompt": {
        "label": "prompt",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask_details/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/ask_details/generation.py",
        "lineNo": 52,
        "endLineNo": 56,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask_details%2Fgeneration.py%23L52-L56&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**[Quick Summary]** This function executes an SQL query using a `prompt_builder` object and logs the executed SQL query for debugging purposes. Its purpose is likely to interact with a database and retrieve data based on a dynamically constructed SQL query.\n\n**[Inputs]**\n* `sql`:  A string containing the dynamically generated SQL query.\n\n**[Output]**\n* The result of the `prompt_builder.run()` method, which likely represents the data retrieved from the database based on the executed SQL query. \n\n\n"
    },
    "src__providers__loader__provider__wrapper": {
        "label": "wrapper",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/loader.py",
        "relativePath": "wren-ai-service/src/providers/loader.py",
        "lineNo": 65,
        "endLineNo": 69,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Floader.py%23L65-L69&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\nThis function registers a new provider class with a dictionary named `PROVIDERS` under a given name. The purpose is to establish a registry for provider classes, allowing for dynamic access based on a provided name.\n\n## Inputs\n* `name`: A string representing the unique identifier for the provider class. \n* `cls`: The provider class to be registered.\n\n## Output\n*  Registers the provider class `cls` associated with the name `name` in the `PROVIDERS` dictionary.  \n"
    },
    "src__utils__service_metadata__get_version_from_pyproject": {
        "label": "get_version_from_pyproject",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 222,
        "endLineNo": 226,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L222-L226&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**[Quick summary]**\n\nThis Python function reads the \"pyproject.toml\" file, parses its contents using the \"toml\" library, and extracts the version number defined within the \"tool.poetry\" section. The purpose is likely to determine the currently installed project's version.\n\n**[Inputs]**\n\n* `pyproject_path`:  A string representing the path to the \"pyproject.toml\" file.\n\n**[Output]**\n\n* A string containing the project's version number as defined in the \"pyproject.toml\" file. \n\n\n\n\n"
    },
    "src__web__v1__services__ask__AskResponse": {
        "label": "AskResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 46,
        "endLineNo": 50,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L46-L50&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "**[Quick Summary]**\n\n\nThis code defines an API endpoint for PATCH requests to the `/v1/asks/{query_id}` path. It likely updates an existing \"ask\" with the given `query_id`.  The API version (`v1`) and resource type (`asks`) are indicated in the path.\n\n\n**[Inputs]**\n\n*  `query_id`: A unique identifier string for the specific ask to be updated.\n\n**[Outputs]**\n\n*  The API response will depend on the successful update of the ask. \n    *  This might include a success message, modified ask data, or an error code if the update fails. \n\n\n\n"
    },
    "src__web__v1__services__ask__StopAskResponse": {
        "label": "StopAskResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 64,
        "endLineNo": 68,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L64-L68&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary \n\nThis function likely retrieves the result associated with a specific query ID. Its purpose is to provide access to the outcome of a previously submitted query. \n\n## Inputs\n\n*  `query_id`: A unique identifier for a particular query.\n\n## Output\n\n*   The result of the query identified by the `query_id`, likely in a structured format. \n\n\n"
    },
    "src__web__v1__services__ask__AskRequest__AskResponseDetails": {
        "label": "AskResponseDetails",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 22,
        "endLineNo": 26,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L22-L26&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze.  \n\n"
    },
    "src__web__v1__services__ask__AskService___get_failed_dry_run_results": {
        "label": "_get_failed_dry_run_results",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 109,
        "endLineNo": 113,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L109-L113&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Summary\n\nThis function filters a list of `invalid_generation_results` to return only the items where the \"type\" key is equal to \"DRY_RUN\".  Its purpose is likely to isolate results specifically indicating dry runs from other types of invalid generation outcomes.\n\n## Inputs\n\n*  `invalid_generation_results`: A list of dictionaries.\n\n## Output\n\n* A list of dictionaries, each containing a \"type\" key with the value \"DRY_RUN\". \n"
    },
    "src__web__v1__services__ask_details__AskDetailsResponse": {
        "label": "AskDetailsResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 39,
        "endLineNo": 43,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L39-L43&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Quick Summary\n\nThis function likely retrieves details about a specific query result, given its unique identifier. The purpose is to allow access to information related to a previous query, possibly for auditing, debugging, or analysis purposes. \n\n\n## Inputs\n* `query_id`: A string representing the unique identifier for the query result.\n\n## Outputs\n* Details about the specified query result, possibly including:\n    * Query text\n    * Timestamp of the query\n    * Model used to generate the response\n    * Response generated by the model \n    * Other relevant metadata. \n\n\n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationResponse": {
        "label": "SQLExplanationResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 37,
        "endLineNo": 41,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L37-L41&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down this code snippet:\n\n**[Quick Summary]**\n\nThis function likely retrieves an explanation of the results produced by a specific SQL query. Given a unique identifier (`query_id`), it interacts with an API endpoint (`/v1/sql-explanations/{query_id}/result`) to fetch the explanation associated with that query.  The code aims to provide users with insights into how their SQL queries were processed and the reasoning behind the generated results.\n\n**[Inputs]**\n\n*  `query_id`: A string representing a unique identifier for a previously executed SQL query.\n\n**[Output]**\n\n* An explanation of the results returned by the SQL query identified by the `query_id`. \n   This explanation could include details about the query execution plan, the data sources involved, and any transformations applied to the data. \n\n\nLet me know if you'd like to explore any aspect of this in more detail! \n"
    },
    "src__web__v1__services__sql_regeneration__DecisionPoint": {
        "label": "DecisionPoint",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 13,
        "endLineNo": 17,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L13-L17&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**  This code snippet defines the parameters for a function likely used in data manipulation or querying. It specifies the type of operation the function performs (filtering, selecting, relating, grouping, or sorting) and the name of the operation as a string. \n\n**Inputs:**\n* **type:** A string indicating the specific data operation to be performed.\n* **value:** A string representing the name or identifier associated with the chosen operation type.\n\n**Output:** \n*  The function is likely meant to take these parameters and execute the corresponding data operation. \n* The exact output depends on the specific implementation and the nature of the data being manipulated.  \n\n\n\n\nLet me know if you'd like a more in-depth explanation of any specific part!\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationResponse": {
        "label": "SQLRegenerationResponse",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 54,
        "endLineNo": 58,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L54-L58&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**[Quick Summary]** This code defines a function endpoint \"/v1/sql-regenerations/{query_id}/result\" which likely retrieves the results of a previously executed SQL query that has undergone regeneration. The purpose is to provide access to the regenerated query results.\n\n**[Inputs]**\n* `query_id`: A unique identifier string representing a specific SQL query. \n\n**[Output]**\n*  The regenerated results of the SQL query identified by `query_id`. This could be in various formats (e.g., JSON, text) depending on the system's implementation. \n\n\n"
    },
    "src__web__v1__services__sql_regeneration__UserCorrection": {
        "label": "UserCorrection",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 25,
        "endLineNo": 29,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L25-L29&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:** This code snippet appears to be renaming a variable or constant, likely from \"DecisionPoint\" to \"CorrectionPoint\".  The purpose could be to improve code clarity or to reflect a change in the meaning or function of the variable. \n\n**Inputs:**\n\n*  \"DecisionPoint\" -  The original name of the variable or constant.\n\n**Output:**\n\n* \"CorrectionPoint\" - The new name for the variable or constant. \n\n\n"
    },
    "src____main____health": {
        "label": "health",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/__main__.py",
        "relativePath": "wren-ai-service/src/__main__.py",
        "lineNo": 89,
        "endLineNo": 92,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2F__main__.py%23L89-L92&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**Quick Summary:**  This function returns a simple JSON object indicating success. It's likely part of an API endpoint or a system that needs to communicate a positive outcome.\n\n**Inputs:**  None \n\n**Output:**\n*  A JSON object containing a single key-value pair: \n      * `\"status\": \"ok\"` \n\n\n"
    },
    "src____main____root": {
        "label": "root",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/__main__.py",
        "relativePath": "wren-ai-service/src/__main__.py",
        "lineNo": 84,
        "endLineNo": 87,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2F__main__.py%23L84-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Analysis\n\n**[Quick Summary]** This function generates a redirect response sending the user's browser to the \"/docs\" URL. This suggests a navigation feature within an application, likely directing users to documentation.\n\n\n**[Inputs]**\n\n\n\n*  **Implied:** None explicitly shown.\n\n**[Output]**\n\n*  **RedirectResponse object:** This object instructs the web browser to load the content located at \"/docs\". \n\n\nLet me know if you have any other code snippets you'd like analyzed!\n"
    },
    "src__core__pipeline__async_validate": {
        "label": "async_validate",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/pipeline.py",
        "relativePath": "wren-ai-service/src/core/pipeline.py",
        "lineNo": 18,
        "endLineNo": 21,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fpipeline.py%23L18-L21&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**Quick Summary:** This function runs an asynchronous task using `asyncio.run` and then prints and returns the result of the task.  Its purpose is to execute asynchronous code and handle its result. \n\n**Inputs:**\n\n* `task()`: This is a function that is expected to perform asynchronous operations.  \n\n**Output:**\n\n*  The result returned by the `task()` function.\n"
    },
    "src__core__pipeline__BasicPipeline__run": {
        "label": "run",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/pipeline.py",
        "relativePath": "wren-ai-service/src/core/pipeline.py",
        "lineNo": 14,
        "endLineNo": 17,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fpipeline.py%23L14-L17&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze.  I'm ready to give you the quick summary, inputs, and outputs! \n"
    },
    "src__core__provider__EmbedderProvider__get_dimensions": {
        "label": "get_dimensions",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 30,
        "endLineNo": 33,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L30-L33&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze.  \ud83d\ude04 \n"
    },
    "src__core__provider__LLMProvider__get_model_kwargs": {
        "label": "get_model_kwargs",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 14,
        "endLineNo": 17,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L14-L17&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Here's a breakdown of the code snippet:\n\n**[Quick Summary]**\n\nThis function likely retrieves and returns a dictionary containing keyword arguments (`kwargs`) specifically intended for the instantiation of a machine learning model. These model-specific configurations are probably stored as attributes within the class instance.\n\n**[Inputs]**\n\n* `self`:  A reference to the current instance of the class.\n\n**[Output]**\n\n* `self._model_kwargs`: A dictionary containing keyword arguments (`kwargs`) used to initialize a model. \n\n\nLet me know if you'd like a deeper explanation of any specific aspect!\n"
    },
    "src__pipelines__indexing__indexing__write_ddl": {
        "label": "write_ddl",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 395,
        "endLineNo": 398,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L395-L398&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis\n\n**Quick summary:** This function executes a DDL (Data Definition Language) script using a tool called `ddl_writer`. It takes a dictionary `embed_ddl` containing DDL documents as input and likely performs database schema operations like creating tables, altering columns, etc. The purpose is to automate the management and modification of database schema definitions. \n\n**Inputs:**\n\n* `embed_ddl`: A dictionary, likely containing a key named \"documents\" that holds the DDL scripts as a list of strings or objects.\n\n**Output:**\n\n* Awaitable result from `ddl_writer.run()`:  This likely indicates the success or failure of the DDL script execution. \n\n\n"
    },
    "src__pipelines__indexing__indexing__DDLConverter___convert_views___format": {
        "label": "_format",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 294,
        "endLineNo": 297,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L294-L297&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary\n\nThis function generates a SQL CREATE VIEW statement from a dictionary representing the view's definition. It includes any specified properties and the view's name and underlying query statement. The purpose is likely to dynamically create view definitions from configuration data.\n\n## Inputs \n\n*  `view`: A dictionary containing the following keys:\n    * `\"name\"`: The name of the view.\n    * `\"statement\"`: The SQL statement defining the view's data selection.\n    * `\"properties\"`: (Optional) A string containing view properties.\n\n## Output\n\n* A string containing a SQL `CREATE VIEW` statement formatted with the provided view information. \n"
    },
    "src__providers__engine__wren__WrenEngine____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 90,
        "endLineNo": 93,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L90-L93&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This code snippet appears to be initializing an object or instance of some class related to a \"wren_engine\". It sets the  internal \"_endpoint\" attribute to a provided value and logs a message indicating the engine being used. The purpose is likely to configure and prepare this engine for use.\n\n**Inputs:**\n*  `endpoint`: This is likely a string representing a URL or address where the `wren_engine` will connect or operate.\n*  `logger`: This is likely a logging object or function used to record informational messages about the engine's initialization.\n\n\n**Output:**\n\n* The code doesn't directly produce any output, but it sets up the `wren_engine` object and logs the message: \"Using Engine: wren_engine\".  "
    },
    "src__providers__engine__wren__WrenUI____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/providers/engine/wren.py",
        "relativePath": "wren-ai-service/src/providers/engine/wren.py",
        "lineNo": 17,
        "endLineNo": 20,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fproviders%2Fengine%2Fwren.py%23L17-L20&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick summary]\nThis code snippet initializes a component or object called `self` with an `endpoint` attribute and logs a message indicating the engine being used is \"wren_ui\". It likely sets up a connection or interface to a service or API named \"wren_ui\". \n\n[Inputs]\n* `endpoint`: A string representing the address or URL of the \"wren_ui\" service.\n* `logger`: An object (possibly a logging module) used to record information about the program's execution.\n\n[Output]\n* No explicit output is shown. \n\n\n"
    },
    "src__utils__remove_trailing_slash": {
        "label": "remove_trailing_slash",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 124,
        "endLineNo": 127,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L124-L127&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function ensures an endpoint string ends with a forward slash (\"/\"), removing any trailing slash if present. \n\nIt's likely used to standardize endpoint formats for API interactions or URL generation.\n\n## Inputs\n\n* **endpoint**: A string representing an URL or API endpoint.\n\n## Output\n\n* A string representing the endpoint: \n    *  With a trailing slash if the original input ended with one.\n    *  Without a trailing slash if the original input did not end with one. \n"
    },
    "src__utils__async_timer__process": {
        "label": "process",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/utils.py",
        "relativePath": "wren-ai-service/src/utils.py",
        "lineNo": 101,
        "endLineNo": 104,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Futils.py%23L101-L104&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Code Analysis \n\n**[Quick Summary]** This function is designed to execute an asynchronous coroutine function. It first checks if the provided function `func` is a valid coroutine using `asyncio.iscoroutinefunction`. Then, it utilizes the `await` keyword to asynchronously execute the coroutine with the given `*args` and `**kwargs`, returning the result. The purpose is to simplify the calling of asynchronous functions within a coroutine environment.\n\n**[Inputs]**\n* `func`: The function to be executed, expected to be an asynchronous coroutine.\n* `*args`: Positional arguments to be passed to the coroutine function.\n* `**kwargs`: Keyword arguments to be passed to the coroutine function.\n\n**[Output]**\n\n* The result returned by the executed coroutine function. \n\n\n"
    },
    "src__web__v1__routers__get_ask_result": {
        "label": "get_ask_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/routers.py",
        "relativePath": "wren-ai-service/src/web/v1/routers.py",
        "lineNo": 102,
        "endLineNo": 105,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Frouters.py%23L102-L105&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:** \n\nThis function retrieves the result of an ask query from a service named `container.ASK_SERVICE`. It uses a `query_id` to identify the specific query and returns the corresponding `AskResult`. \n\n**Inputs:**\n\n* `query_id`: A unique identifier for the specific ask query.\n\n**Output:**\n\n* An object containing the result of the ask query. \n"
    },
    "src__web__v1__services__ask__AskResultRequest": {
        "label": "AskResultRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 69,
        "endLineNo": 72,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L69-L72&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze.  \n\n"
    },
    "src__web__v1__services__ask__AskResultResponse__AskResult": {
        "label": "AskResult",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 69,
        "endLineNo": 72,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L69-L72&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze. \n\n"
    },
    "src__web__v1__services__ask_details__AskDetailsResultRequest": {
        "label": "AskDetailsResultRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 44,
        "endLineNo": 47,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L44-L47&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down the provided code snippet! \n\n\n## Summary \n\nThis function likely processes a user query. It takes a unique identifier for the query ( `query_id`) and likely performs some action based on this identifier, potentially retrieving information or performing a task associated with that specific query. \n\n## Inputs\n\n*  `query_id`: A string representing a unique identifier for a particular user query.\n\n\n## Output\n\nThe expected output is not provided in the snippet.  It could be:\n\n*  Information related to the query (text, data, etc.). \n*  A confirmation message or code indicating successful processing.\n* A  flag or value indicating the outcome of the query processing. \n\n\n\nLet me know if you have more code or context! \n"
    },
    "src__web__v1__services__ask_details__AskDetailsResultResponse__AskDetailsError": {
        "label": "AskDetailsError",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 53,
        "endLineNo": 56,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L53-L56&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "[Quick Summary]\nThis function likely determines and returns a reason why a given SQL query might not be relevant to a specific task or database schema. The `code` input signals the type of irrelevance, while the `message`  explains the specific reason. \n\n[Inputs]\n* `code`:  A string representing a code indicating the reason for SQL irrelevance. \n*  `message`: A string providing a detailed explanation of why the SQL query is irrelevant.\n\n[Output]\n* A combination of a code and a message indicating the irrelevance of a SQL query. \n\n\n"
    },
    "src__web__v1__services__ask_details__AskDetailsResultResponse__AskDetailsResponseDetails": {
        "label": "AskDetailsResponseDetails",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 49,
        "endLineNo": 52,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L49-L52&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection that you would like me to analyze.  I need the actual code to give you a summary, inputs, and output. \ud83d\ude0a \n"
    },
    "src__web__v1__services__indexing__SemanticsPreparationStatusResponse__SemanticsPreparationError": {
        "label": "SemanticsPreparationError",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/indexing.py",
        "relativePath": "wren-ai-service/src/web/v1/services/indexing.py",
        "lineNo": 36,
        "endLineNo": 39,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Findexing.py%23L36-L39&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown:\n\n**[Quick Summary]**\n\nThis function likely defines a simple error handling mechanism, specifically for situations where the input doesn't match any predefined categories.  It returns a predefined \"OTHERS\" code along with a message string describing the unexpected input.\n\n**[Inputs]**\n* `code`: A string literal with the value  `\"OTHERS\"`. This suggests a fixed code indicating an unspecified or out-of-range input.\n* `message`: A string variable containing a description of the unexpected input.\n\n**[Output]**\n* This function likely doesn't explicitly return a value. The `code` and `message` may be used internally to flag an error or be passed to another function for further processing. \n\n\n\nLet me know if you have any other code snippets you'd like analyzed!\n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationResultRequest": {
        "label": "SQLExplanationResultRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 42,
        "endLineNo": 45,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L42-L45&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze.  I need the code to give you a summary, inputs, and output. \ud83d\ude0a  \n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationResultResponse__SQLExplanationResultError": {
        "label": "SQLExplanationResultError",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 47,
        "endLineNo": 50,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L47-L50&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**[Quick summary]** This code likely defines a function that handles handling cases when a certain condition isn't met. It returns the literal string \"OTHERS\" and an error message. The purpose is to signal that the input doesn't fall under predefined categories.\n\n**[Inputs]**\n* `code`: A string literal that is expected to be \"OTHERS\". This suggests a classification system where \"OTHERS\" signifies a catch-all category.\n* `message`: A string containing an error message.\n\n**[Output]**\n * Probably None, since the function likely serves as an indication rather than producing a calculated result. \n\n\n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationService____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 57,
        "endLineNo": 60,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L57-L60&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "##  Function Breakdown \n\n**Quick summary:**  This code snippet likely initializes an object that manages a collection of pipelines and stores results from SQL explanation requests.  It appears to be part of a system for analyzing and understanding SQL queries.\n\n**Inputs:**\n\n*  `pipelines`: A collection (likely a list or dictionary) of pre-defined pipelines used for processing SQL queries.\n*  `sql_explanation_results`: An empty dictionary that will store the results of SQL explanation requests, keyed by a unique identifier (likely the SQL query itself).\n\n**Output:**\n\n*  An object with two attributes:\n    * `_pipelines`: Stores the input collection of pipelines.\n    * `sql_explanation_results`: A dictionary containing SQL explanation results for various queries.  \n\n\n\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationResultRequest": {
        "label": "SQLRegenerationResultRequest",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 59,
        "endLineNo": 62,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L59-L62&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the function code so I can analyze it and give you the summary, inputs, and output.  \n\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationResultResponse__SQLRegenerationError": {
        "label": "SQLRegenerationError",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 74,
        "endLineNo": 77,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L74-L77&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Breakdown\n\n**Quick Summary:**\n\nThis function likely classifies SQL queries or code snippets. It returns a code indicating whether the input contains no relevant SQL or if it's something else (\"OTHERS\"). The `message` variable might hold additional information about the classification.  \n\n**Inputs:**\n\n* `code`: A string literal, presumably representing a classification code:\n\n   *   \"NO_RELEVANT_SQL\": Indicates the input doesn't contain any relevant SQL.\n   *   \"OTHERS\":  Indicates the input contains SQL or something else besides the mentioned case.\n\n* `message`: A string that might provide further details about the classification.\n\n**Output:**\n\n*  `code`: The classification string (\"NO_RELEVANT_SQL\" or \"OTHERS\"). \n\n\n\nLet me know if you have more code snippets you'd like me to analyze! \n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationResultResponse__SQLRegenerationResponseDetails": {
        "label": "SQLRegenerationResponseDetails",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 70,
        "endLineNo": 73,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L70-L73&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze. I need the code to determine the function's purpose, inputs, and output. \ud83d\ude0a  \n\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationService____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 84,
        "endLineNo": 87,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L84-L87&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Function Summary\n\nThis code snippet likely initializes an object responsible for managing SQL regeneration pipelines and storing results. It assigns a list of pipelines to the `_pipelines` attribute and creates an empty dictionary `sql_regeneration_results` to hold results for individual regeneration processes.\n\n## Inputs\n\n* `pipelines`: A list of SQL regeneration pipelines.\n\n**\n## Output\n\n* `self.sql_regeneration_results`: A dictionary storing `SQLRegenerationResultResponse` objects for each regeneration process.  \n\n\n"
    },
    "src__core__engine__clean_generation_result___normalize_whitespace": {
        "label": "_normalize_whitespace",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/engine.py",
        "relativePath": "wren-ai-service/src/core/engine.py",
        "lineNo": 30,
        "endLineNo": 32,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fengine.py%23L30-L32&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**[Quick Summary]**\n\nThis function takes a string as input and cleans it up by replacing any sequences of whitespace characters with a single space, then removing any leading or trailing spaces. Its purpose is to normalize whitespace within a string, ensuring consistent spacing.\n\n**[Inputs]**\n* `s`: A string that may contain various whitespace characters (spaces, tabs, newlines, etc.).\n\n\n**[Output]**\n* A cleaned string with a single space separating words and no extra spaces at the beginning or end. \n"
    },
    "src__core__pipeline__BasicPipeline____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/pipeline.py",
        "relativePath": "wren-ai-service/src/core/pipeline.py",
        "lineNo": 10,
        "endLineNo": 12,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fpipeline.py%23L10-L12&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis:\n\n**[Quick Summary]**\n\nThis line of code initializes a private attribute called \"_pipe\"  within an object. It likely sets up a communication channel or data pipeline within the object's functionality.  The purpose is to  manage the flow of data  or instructions between different parts of the object.\n\n**[Inputs]**\n\n* `pipe`: \n    *  This  is the input variable, presumably an object or data structure representing a pipeline or communication channel.\n\n**[Output]**\n\n* The output is the initialization of the private attribute \"_pipe\" within the object. \n    * This attribute will store the `pipe` object or data structure, making it accessible and usable within the object's methods.  \n\n\n\n\nLet me know if you'd like a deeper dive into any specific aspect!\n"
    },
    "src__core__provider__DocumentStoreProvider__get_store": {
        "label": "get_store",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 36,
        "endLineNo": 38,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L36-L38&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze.  \n\n"
    },
    "src__core__provider__EmbedderProvider__get_document_embedder": {
        "label": "get_document_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 24,
        "endLineNo": 26,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L24-L26&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze.  I'm ready to give you a quick summary, list the inputs and expected outputs! \n"
    },
    "src__core__provider__EmbedderProvider__get_model": {
        "label": "get_model",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 27,
        "endLineNo": 29,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L27-L29&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide me with the code selection you'd like me to analyze.  \n\n"
    },
    "src__core__provider__EmbedderProvider__get_text_embedder": {
        "label": "get_text_embedder",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 20,
        "endLineNo": 22,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L20-L22&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze. I'm ready to provide a quick summary, list the inputs and expected output!  \n\n"
    },
    "src__core__provider__LLMProvider__get_generator": {
        "label": "get_generator",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 8,
        "endLineNo": 10,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L8-L10&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze. I'm ready to summarize it, list the inputs and outputs, and give you a concise explanation.  \n\n"
    },
    "src__core__provider__LLMProvider__get_model": {
        "label": "get_model",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 11,
        "endLineNo": 13,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L11-L13&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Summary\n\nThis function, likely part of a larger class, retrieves and returns an instance of a `generation_model`.  The purpose is to provide access to a pre-defined or instantiated model used for text generation tasks.\n\n## Inputs\n* `self`: A reference to the current instance of the class.\n\n## Output\n* `self._generation_model`: An object representing a text generation model. \n\n\n"
    },
    "src__pipelines__ask__components__post_processors__GenerationPostProcessor____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "relativePath": "wren-ai-service/src/pipelines/ask/components/post_processors.py",
        "lineNo": 20,
        "endLineNo": 22,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fask%2Fcomponents%2Fpost_processors.py%23L20-L22&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze.  \n\n"
    },
    "src__pipelines__common__GenerationPostProcessor____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/common.py",
        "relativePath": "wren-ai-service/src/pipelines/common.py",
        "lineNo": 20,
        "endLineNo": 22,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fcommon.py%23L20-L22&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze.  I need the actual code snippet to give you a summary, inputs, and output. \n\n"
    },
    "src__pipelines__indexing__indexing__DocumentCleaner____init__": {
        "label": "__init__",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/indexing/indexing.py",
        "relativePath": "wren-ai-service/src/pipelines/indexing/indexing.py",
        "lineNo": 35,
        "endLineNo": 37,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Findexing%2Findexing.py%23L35-L37&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you would like me to analyze. \ud83d\ude0a I'm ready to break it down for you!  \n\n"
    },
    "src__pipelines__sql_explanation__generation__generates___task": {
        "label": "_task",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "relativePath": "wren-ai-service/src/pipelines/sql_explanation/generation.py",
        "lineNo": 477,
        "endLineNo": 479,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fpipelines%2Fsql_explanation%2Fgeneration.py%23L477-L479&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis \n\n**Quick Summary:** This function executes a text generation task using a generator object. It takes a prompt as input and returns the generated text produced by the generator. The purpose is to harness the power of a text generation model to create new textual content based on a given prompt.\n\n**Inputs:**\n\n* **generator:** An object representing a text generation model.\n* **prompt:** A dictionary containing a \"prompt\" key, which holds the text input used to guide the generation process.\n\n**Output:**\n\n* The generated text produced by the `generator` in response to the provided `prompt`. \n"
    },
    "src__web__v1__services__ask__AskRequest__query_id": {
        "label": "query_id",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 38,
        "endLineNo": 40,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L38-L40&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Python Code Analysis\n\n**Summary:** This function likely belongs to a class representing a database query. Its purpose is to provide access to a unique identifier (`_query_id`) associated with a specific query instance. \n\n**Inputs:**\n\n*  No explicit inputs are shown in the code snippet.\n\n**Output:**\n\n*  The function returns `self._query_id`, which presumably is a unique identifier for the query object. \n\n\n\n"
    },
    "src__web__v1__services__ask__StopAskRequest__query_id": {
        "label": "query_id",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask.py",
        "lineNo": 56,
        "endLineNo": 58,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask.py%23L56-L58&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the function selection you'd like me to analyze.  \n\nI need the code snippet to give you a summary, inputs, and outputs. \ud83d\ude04  \n"
    },
    "src__web__v1__services__ask_details__AskDetailsRequest__query_id": {
        "label": "query_id",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/ask_details.py",
        "relativePath": "wren-ai-service/src/web/v1/services/ask_details.py",
        "lineNo": 31,
        "endLineNo": 33,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fask_details.py%23L31-L33&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This function, likely part of a larger class, retrieves and returns a value stored as `_query_id`.  The purpose is to provide access to this identifier associated with a specific query.  \n\n\n**Inputs:** \n\n*  None. The function appears to only access an internal attribute.\n\n**Output:**\n\n* `self._query_id`: This is the value stored in the private attribute `_query_id` within the object. \n"
    },
    "src__web__v1__services__sql_explanation__SQLExplanationRequest__query_id": {
        "label": "query_id",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_explanation.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_explanation.py",
        "lineNo": 29,
        "endLineNo": 31,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_explanation.py%23L29-L31&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down this Python code snippet. \n\n[**Quick Summary**]\n\nThis function seems to be designed to retrieve a unique identifier, likely associated with a database query or operation.  The  `self._query_id` suggests this is part of a larger class, and the underscore prefix indicates it's intended for internal use within the class.\n\n\n[**Inputs**]\n\n* There are no explicit inputs to this function.\n* It likely relies on the value stored in `self._query_id` which is set elsewhere within the class.\n\n[**Output**]\n\n*  The function returns the value stored in `self._query_id`.   \n\n\nLet me know if you'd like to explore any specific aspect of this code further!\n"
    },
    "src__web__v1__services__sql_regeneration__SQLRegenerationRequest__query_id": {
        "label": "query_id",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "relativePath": "wren-ai-service/src/web/v1/services/sql_regeneration.py",
        "lineNo": 46,
        "endLineNo": 48,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fv1%2Fservices%2Fsql_regeneration.py%23L46-L48&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Let's break down this code snippet.\n\n**[Quick Summary]**\n\nThis function likely belongs to a class designed to manage queries.  Its purpose is to retrieve a unique identifier (`query_id`) associated with a specific query object.\n\n**[Inputs]**\n\n*  There aren't any explicitly listed inputs to this function.\n\n\n**[Output]**\n\n* A value representing a unique query identifier (`query_id`)\n\n\n\nLet me know if you have any more code snippets you'd like analyzed!\n"
    },
    "src__core__provider__DocumentStoreProvider__get_retriever": {
        "label": "get_retriever",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/core/provider.py",
        "relativePath": "wren-ai-service/src/core/provider.py",
        "lineNo": 40,
        "endLineNo": 41,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fcore%2Fprovider.py%23L40-L41&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "Please provide the code selection you'd like me to analyze. I'm ready to break down the function for you! \n"
    },
    "src__web__development__get_dummy_ask_result": {
        "label": "get_dummy_ask_result",
        "systemPath": "/home/sanjay/Development/explore/WrenAI/wren-ai-service/src/web/development.py",
        "relativePath": "wren-ai-service/src/web/development.py",
        "lineNo": 102,
        "endLineNo": 103,
        "emgithubIframeLink": "https://emgithub.com/iframe.html?target=https%3A%2F%2Fgithub.com%2FCanner%2FWrenAI%2Fblob%2Fmain%2Fwren-ai-service%2Fsrc%2Fweb%2Fdevelopment.py%23L102-L103&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on",
        "description": "## Code Analysis\n\n**Quick Summary:** This function simulates a task result for an ask request. It takes a query ID as input and returns a dummy result using `get_dummy_ask_task_result` function. The purpose is likely for testing or development where a placeholder ask result is needed.\n\n**Inputs:**\n\n* `query_id`: A unique identifier for the ask request being processed.\n\n**Output:**\n\n* A dummy `AskResultRequest` object. \n"
    }
}